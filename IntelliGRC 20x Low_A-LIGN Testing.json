[
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-CED-01",
        "Control ID":"KSI-CED-01",
        "Control Description":"Ensure all employees receive security awareness training",
        "Testing Notes":"\nCED-01-Annual Security and Awareness Training v2025-08.csv:\nThe training status report indicates that 19 out of 21 employees have completed the 'Annual Security and Awareness Training v2025-08'. The report includes completion dates for those who finished the training, demonstrating that a majority of employees have received the required security awareness training. Two employees, Benjamin Martindell and Jeremy Lyles, have the training assigned but have not yet completed it.\n\nCED-01-Q3 2025 Training report (July 2025).csv:\nThe training completion report from intelligrc.com shows that most employees completed the assigned security awareness training modules (Insider Threats, Unintentional Insider Threat, and Smishing) in July and August of 2025. The report details the completion dates for each module per employee. One employee, Benjamin Martindell, has all three training modules listed as 'Assigned' with no completion dates. All other employees listed in the report have completed all three training modules.\n\nCED-01-Cybersecurity Education Training Records.PNG:\nTesting Notes:\n\nEvidence indicates that the Security Team is responsible for documenting and monitoring all security and privacy training activities (AT-04a). This includes both general awareness and role-based training. Evidence also shows that training records are stored on the company's SharePoint site as required by AT-04a. Additionally, the Security Team is responsible for retaining individual training records for at least 1 year (AT-04b), demonstrating adherence to the retention policy.\n\n\n\nCED-01-Cybersecuirty Education Insider Threat.PNG:\nThe evidence provided demonstrates that IntelliGRC has established a comprehensive security awareness training program. Key aspects include:\n\n*   Annual training for all staff with access to the FedRAMP environment (AT-02b).\n*   Mandatory onboarding briefings for new personnel covering security and privacy responsibilities, completed within 5 days of system access (AT-02b).\n*   A defined process for updating training content at least annually and in response to triggering events such as security incidents, organizational changes, or regulatory updates (AT-02c).\n*   Designated roles and responsibilities for the Security Team and CISO in developing, delivering, and maintaining the training program (AT-02b, AT-02c, AT-02d).\n*   Specific training modules addressing insider threats (AT-2(2)) and social engineering (AT-2(3)).\n*   Tracking of training completion via a SharePoint spreadsheet (AT-02b).\n*   Storage of training materials on the company's SharePoint portal (AT-02b).\n*   Use of internal communication channels for reminders and alerts (AT-02b).\n\nThe documented policies and procedures outline a structured approach to ensuring all employees receive security awareness training, thus satisfying the control requirement.\n\nCED-01-Cybersecurity Education Annual Training.PNG:\nBased on the provided document summary, here are testing notes for the control 'Ensure all employees receive security awareness training':\n\n*   **Annual Security Literacy Training (AT-02a.01[01][03]):** The document explicitly states that the Security Team provides annual security literacy training to all system users, including managers, senior executives, and contractors. This satisfies the requirement for regular security awareness training.\n*   **Annual Privacy Literacy Training (AT-02a.01[02][04]):** The document also confirms annual privacy literacy training for the same audience, further demonstrating a commitment to comprehensive security awareness.\n*   **Onboarding Training:** Both security and privacy literacy training are mandatory during the initial onboarding process, ensuring new employees receive security awareness training from the start.\n*   **Event-Driven Training (AT-02a.02):** The document includes provisions for event-driven training, triggered by system changes, security incidents, organizational restructuring, new system deployments, or changes in regulations. This ensures that training is updated and relevant to current threats and the organization's environment.\n\nThese notes indicate that the evidence (AT-2, Literacy Training and Awareness document) demonstrates adherence to the control 'Ensure all employees receive security awareness training' through annual training, onboarding procedures, and event-triggered updates.\n\n",
        "Test Instructions":"Review training records and course materials to confirm all employees receive security awareness training.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-CED-01, SSP-1",
        "Linked Evidence":"CED-01-AnnualSecurityTrainingv2025-08_CompletionRecordsWithUserRoleAssignments.xlsm,CED-01-Cybersecuirty Education Insider Threat.PNG,CED-01-Cybersecurity Education Annual Training.PNG,CED-01-Cybersecurity Education Training Records.PNG,CED-01-Q3 2025 Training report (July 2025).csv,CED-01-Training records and policy requirements.json"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-CED-02",
        "Control ID":"KSI-CED-02",
        "Control Description":"Require role-specific training for high risk roles, including at least roles with privileged access",
        "Testing Notes":"CED-02-Awareness_Training_Slides.pptx:\nThe Security Awareness Training presentation by IntelliGRC includes role-based training for both developers and Super Admins, who would both be considered high-risk roles with privileged access. The developer training covers secure coding practices, authorized remote access methods, and incident awareness. The Super Admin training details responsibilities, secure practices, and customer data handling procedures specific to that role. The training content addresses the need for role-specific training for high-risk roles, including those with privileged access.\n\nCED-01-AnnualSecurityTrainingv2025-08_CompletionRecordsWithUserRoleAssignments.xlsm:\nTesting Notes: The control requires role-specific training for high-risk roles, including those with privileged access. While all users, including the 10 identified as having privileged access, were assigned the Annual Security and Awareness Training v2025-08, this training appears to be a general security awareness module rather than specific to high-risk roles. Furthermore, one user with privileged access, Benjamin Martindell (QA Lead - Super Admin), has not completed this assigned training but it is noted that this person is currently on paternity leave. \n\nCED-02-Cybersecurity Education Role Based Training.PNG:\nThe evidence provided outlines the security and training policies of IntelliGRC, specifically focusing on role-based training. It details the Security Team's responsibilities for designating, updating, and improving role-based security and privacy training, including designating initial and annual training for system administrators, developers, cloud operations personnel, and any other staff with elevated privileges or compliance-related responsibilities. The training must be completed before personnel are authorized to access the system or perform their duties, and must be repeated at least annually. The evidence also states that the Security Team must update the role-based training content at least annually and following specific events, such as significant changes, security incidents, major organizational restructuring, deployment of new systems, or regulatory changes. Furthermore, the Security Team is responsible for incorporating lessons learned from security incidents or breaches into the role-based training materials. This evidence demonstrates that IntelliGRC has defined role-specific training for high-risk roles, including those with privileged access.\n\nCED-02-Cybersecurity Education Role Based Training.PNG:\nTesting Notes: The provided document, IntelliGRC Security and Training Policies, specifically addresses the requirement for role-specific training for high-risk roles. Section AT-3, Role-Based Training, designates system administrators, developers, cloud operations personnel, and any other staff with elevated privileges or compliance-related responsibilities as the target audience for role-based security and privacy training. This directly aligns with the control's focus on high-risk roles, including those with privileged access. The policy further mandates that this training be completed before personnel are authorized to access the system or perform their duties, and must be repeated at least annually (AT-03a.01), ensuring that individuals in high-risk roles receive appropriate and timely role-specific training.\n\nCED-02-Awareness_Training_Slides.pptx:\nThe evidence provided, specifically the Security Awareness Training presentation by IntelliGRC, directly supports the control requirement for role-specific training for high-risk and privileged access roles. The training explicitly includes dedicated sections for Developer Role-Based Training (Slides 29-35) and IntelliGRC Super Admin Role-Based Training (Slides 36-41).\n\n*   **Developer Role-Based Training:** This section outlines secure coding practices, authorized remote access methods, and incident awareness pertinent to developers, who are considered high-risk due to their ability to introduce or remediate vulnerabilities within the system.\n*   **Super Admin Role-Based Training:** This section addresses the highest privileged user role within IntelliGRC, detailing responsibilities, secure practices (e.g., mandatory MFA, not sharing credentials, using the account only for Super Admin duties), and explicit customer data handling protocols. This directly covers training for roles with privileged access.\n\nThis demonstrates that IntelliGRC requires and provides specific training tailored to the unique security responsibilities and risks associated with these roles, meeting the control's intent.\n\n\nCED-01-AnnualSecurityTrainingv2025-08_CompletionRecordsWithUserRoleAssignments.xlsm:\nTesting Notes: The control requires role-specific training for high-risk roles, including those with privileged access. While all users, including the 10 identified as having privileged access, were assigned the Annual Security and Awareness Training v2025-08, this training appears to be a general security awareness module rather than specific to high-risk roles. Furthermore, one user with privileged access, Benjamin Martindell (QA Lead - Super Admin), has not completed this assigned training but it is noted that this person is currently on paternity leave. \n\nCED-02-Cybersecurity Education Role Based Training.PNG:\nTesting Notes: The provided document, IntelliGRC Security and Training Policies, specifically addresses the requirement for role-specific training for high-risk roles. Section AT-3, Role-Based Training, designates system administrators, developers, cloud operations personnel, and any other staff with elevated privileges or compliance-related responsibilities as the target audience for role-based security and privacy training. This directly aligns with the control's focus on high-risk roles, including those with privileged access. The policy further mandates that this training be completed before personnel are authorized to access the system or perform their duties, and must be repeated at least annually (AT-03a.01), ensuring that individuals in high-risk roles receive appropriate and timely role-specific training.\n\nCED-02-Awareness_Training_Slides.pptx:\nThe evidence provided, specifically the Security Awareness Training presentation by IntelliGRC, directly supports the control requirement for role-specific training for high-risk and privileged access roles. The training explicitly includes dedicated sections for Developer Role-Based Training (Slides 29-35) and IntelliGRC Super Admin Role-Based Training (Slides 36-41).\n\n*   **Developer Role-Based Training:** This section outlines secure coding practices, authorized remote access methods, and incident awareness pertinent to developers, who are considered high-risk due to their ability to introduce or remediate vulnerabilities within the system.\n*   **Super Admin Role-Based Training:** This section addresses the highest privileged user role within IntelliGRC, detailing responsibilities, secure practices (e.g., mandatory MFA, not sharing credentials, using the account only for Super Admin duties), and explicit customer data handling protocols. This directly covers training for roles with privileged access.\n\nThis demonstrates that IntelliGRC requires and provides specific training tailored to the unique security responsibilities and risks associated with these roles, meeting the control's intent.\n\n",
        "Test Instructions":"Review training records and job descriptions to confirm role-specific training for high-risk roles, especially those with privileged access.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-CED-02, SSP-1",
        "Linked Evidence":"CED-01-AnnualSecurityTrainingv2025-08_CompletionRecordsWithUserRoleAssignments.xlsm,CED-02-Awareness_Training_Slides.pptx,CED-02-Cybersecurity Education Role Based Training.PNG"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-CMT-01",
        "Control ID":"KSI-CMT-01",
        "Control Description":"Log and monitor system modifications",
        "Testing Notes":"\nCMT-01-Pull requests change history.png:\nThe evidence provided shows completed pull requests in Azure DevOps for the IntelliGRC project, specifically the alz-mgmt repository. These pull requests, created by Matthew Duval, target the main branch and include modifications related to system hardening, configuration, and security. Titles such as 'disable password auth in jump 1', 'final jumpbox config', and 'enable sentinel threat intelligence data connector' demonstrate changes to system configurations. The pull request history indicates that system modifications are logged and monitored through the Azure DevOps pull request system.\n\nCMT-01-Event Logging Policy Excert.png:\nBased on the evidence provided, the procedure AU-2 sufficiently describes the process for logging and monitoring system modifications. The document details the process for selecting, configuring, and reviewing audit events. Specifically, the procedure outlines the steps for identifying auditable events, coordinating with stakeholders, configuring logging parameters, validating event logging adequacy, and reviewingupdating events. The procedure also specifies what security-relevant events must be logged, including authentication attempts, privileged access use, file access, and configuration changes, which directly addresses the control objective of logging system modifications.\n\nCMT-01-Sentinel Logs - System Modifications.png:\nEvidence confirms logging of system modifications through Azure AD audit logs, specifically tracking operations like 'Update device,' 'Update user,' and password reset activities. The Kusto query demonstrates the ability to retrieve and review these logs, including details on the time of modification, resource affected, operation performed, and the identity involved. The presence of logs related to device password updates and user self-service password resets indicates that system modifications are being captured and are auditable.\n\n",
        "Test Instructions":"Review system logs and monitoring dashboards to confirm that system modifications are logged and monitored.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-CMT-01, SSP-1",
        "Linked Evidence":"CMT-01-Event Logging Policy Excert.png,CMT-01-Pull requests change history.json,CMT-01-Pull requests change history.png,CMT-01-Sentinel Logs - System Modifications.json,CMT-01-Sentinel Logs - System Modifications.png,intelligrc-fedramp-20x-main.zip"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-CMT-02",
        "Control ID":"KSI-CMT-02",
        "Control Description":"Execute changes though redeployment of version controlled immutable resources rather than direct modification wherever possible",
        "Testing Notes":"\nCMT-02-intelli-appset.yml.txt:\nBased on the provided evidence, changes are executed through redeployment of version-controlled immutable resources. The Argo CD ApplicationSet uses Helm templates to define application deployments. Changes to the application configurations are managed through updates to the Git repository, which are then automatically synchronized to the cluster by Argo CD. The automated sync policy with prune and selfHeal options ensures that the deployed resources remain consistent with the definitions in the Git repository, effectively enforcing immutable infrastructure principles.\n\nCNA-04-alz-mgmt terraform configuration identities.tf.png:\nBased on the evidence provided, the `identities.tf` file uses Terraform to define and manage Azure resources through Infrastructure as Code (IaC). This aligns with the control objective of executing changes through redeployment of version-controlled, immutable resources. The file defines managed identities for Storage Accounts, Container Registries, and Firewall Policies, all within a dedicated resource group. The use of Terraform, stored in a version-controlled repository (`alz-mgmt`), ensures that changes to these identities are applied through redeployment of the infrastructure, rather than direct modification. The presence of CICD pipelines and modular design further supports this control.\n\n",
        "Test Instructions":"Examine change management procedures and deployment pipelines to verify that changes are executed through redeployment of version-controlled immutable resources rather than direct modification.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-CMT-02, SSP-1",
        "Linked Evidence":"CMT-02-intelli-appset.yml.txt,CNA-04-alz-mgmt terraform configuration identities.tf.png"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-CMT-03",
        "Control ID":"KSI-CMT-03",
        "Control Description":"Implement automated testing and validation of changes prior to deployment",
        "Testing Notes":"\nCMT-03-Testing&validation of Changes.png:\nEvidence demonstrates that the Development Team and CloudOps Team are responsible for testing and validating changes to the system before implementation (CM-03(02)). The Security Team analyzes changes for security and privacy impacts before implementation (CM-04). Post-change, the Security Team verifies that impacted controls are correctly implemented and operating as intended (CM-04(02)).\n\nCMT-03-Automated tests run.png:\nEvidence shows that automated tests are implemented and passing within the Azure DevOps pipeline 'actionplan'. Specifically, run #20250805.8 demonstrates 8 tests were executed with a 100% pass rate in 20 seconds. This indicates automated testing and validation of changes prior to deployment.\n\nCMT-03-Code Scanning Logs.txt:\nThe provided CodeQL analysis report confirms automated testing and validation of changes before deployment. The report details a successful scan using a comprehensive suite of 68 security-focused queries (csharp-security-extended.qls) that target common vulnerabilities (e.g., CWE-079, CWE-089, CWE-022). The scan covered 282 C# files, and the results were exported to a SARIF file and submitted to the Advanced Security service, demonstrating an automated validation process. The successful completion of the task, without detecting violations, indicates that the current codebase passed the automated security testing prior to deployment.\n\nCNA-04-message-scheduler-v0.1.3-results.xml:\nBased on the evidence provided, here are testing notes for the control Implement automated testing and validation of changes prior to deployment:\n\nThe provided XCCDF scan results demonstrate automated testing and validation of the container image `intelliacr.azurecr.iomessage-scheduler:v0.1.3` against a defined security benchmark. The scan, performed by OpenSCAP, automatically assessed the container image against a comprehensive set of security rules. The 'pass' results indicate successful validation of specific security requirements, while the 'notapplicable' results highlight the validation of inherited controls from the host system. The final score of 100100 confirms that the container image passed all applicable security checks within the benchmark, demonstrating automated validation prior to deployment. This automated scan provides evidence that changes to the container image are tested and validated before deployment, satisfying the control requirement.\n\n",
        "Test Instructions":"Request documentation of automated testing and validation processes within CI\/CD pipelines and review recent test results prior to deployment.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-CMT-03, SSP-1",
        "Linked Evidence":"CMT-03-Automated tests run.png,CMT-03-Automated tests run.xml,CMT-03-Code Scanning Logs.txt,CMT-03-Testing&validation of Changes.png,CNA-04-message-scheduler-v0.1.3-results.xml"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-CMT-04",
        "Control ID":"KSI-CMT-04",
        "Control Description":"Have a documented change management procedure",
        "Testing Notes":"\nCMT-05-CM Plan.pdf:\nThe IntelliGRC Configuration Management Plan explicitly documents the change management procedure. The plan details the roles and responsibilities involved in change management, including the Idea Review Board (IRB), System Owner (CISO), Configuration Manager (Cloud Operations Team), and Change Requesters. The plan outlines the change request process, approval mechanisms (including peer reviews and CISO sign-off), and testingvalidation requirements.  The plan also specifies version control using Git, branching strategies, and promotion processes, demonstrating a documented and enforced change management procedure.\n\nCMT-05- CM - Configuration Management.pdf:\nThe provided Configuration Management Policies document serves as the documented change management procedure. The document details the process for managing and controlling changes to IntelliGRC's information systems. Key aspects that demonstrate this include:  *   Section 3 outlines the scope, applying the policy to all systems and components. *   Section 7 clearly defines roles and responsibilities for change management. *   Section 8 details specific change control processes in CM-3, including documentation, review, approval, and the use of a Configuration Control Board (CCB).\n\n",
        "Test Instructions":"Obtain and review the documented change management procedure.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-CMT-04, SSP-1",
        "Linked Evidence":"CMT-05- CM - Configuration Management.pdf,CMT-05-CM Plan.pdf"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-CMT-05",
        "Control ID":"KSI-CMT-05",
        "Control Description":"Evaluate the risk and potential impact of any change",
        "Testing Notes":"\nCMT-05-Change Management Impact Analysis.PNG:\nTesting Notes:\n\nThe Security Team, in coordination with the Cloud Ops team, is responsible for analyzing changes to the system prior to implementation.\n\nThe analysis identifies and determines potential security and privacy impacts.\n\nThis collaborative effort between the Security Team and Cloud Ops ensures a proactive approach to managing risk by analyzing changes before implementation, as required by CM-4.\n\nImpact Analysis_Add Caleb and James's SA accounts to Sentinel_7.29.22025.png:\nThe evidence demonstrates a change management process where approvals are required. Roberto Qui\u00f1ones' approval comment explicitly includes a 'Security Impact analysis' where he states there is no relevant impact to the system by granting access, because permissions are assigned in line with the users roles and responsibilities. This demonstrates that the risk and potential impact of the change (granting access) was evaluated prior to approval.\n\nCMT-05-Change Management Teams Sentinel Change Approval.pdf:\nThe Change Management Request demonstrates an evaluation of risk and potential impact through its detailed review process. The request includes a justification for the change, outlining the need for access to Microsoft Sentinel for FedRAMP compliance, indicating consideration of the potential impact of not granting the access. The approval workflow, involving multiple stakeholders like Matthew DuVal, Steven Molter, James Watson, Roberto Quinones, Caleb Harrison, Phillip Donald, and Jeremy Lyles, suggests a review of the potential impact. Furthermore, the identification of 'Labor' costs associated with the change implies a consideration of resource impact. The defined back-out plan to revert to the previous Terraform configuration in case of issues shows that potential negative impacts were considered and a mitigation strategy was prepared.\n\n",
        "Test Instructions":"Review recent change requests and their associated risk assessments or impact analyses to confirm evaluation of risk and potential impact.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-CMT-05, SSP-1",
        "Linked Evidence":"CMT-05-Change Management Impact Analysis.PNG,CMT-05-Change Management Teams Sentinel Change Approval.pdf,Impact Analysis_Add Caleb and James's SA accounts to Sentinel_7.29.22025.png"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-CNA-01",
        "Control ID":"KSI-CNA-01",
        "Control Description":"Configure ALL information resources to limit inbound and outbound traffic",
        "Testing Notes":"CNA-01-firewall.tf:\nThe Terraform configuration effectively limits inbound and outbound traffic through the implementation of an Azure Firewall. The configuration includes a dedicated subnet for the firewall, ensuring that all traffic passes through it. A route table is configured to route all outbound internet traffic (0.0.0.00) through the Azure Firewall. The firewall rules themselves are managed in a separate module, allowing for modularity and separation of concerns. Diagnostic settings are enabled to monitor the firewall's activity, including threat intelligence, application rule hits, and DNS queries.\n\nCNA-01-acr-nw.tf:\nThe Terraform configuration effectively limits both inbound and outbound traffic for the Azure Container Registry (ACR) subnet. Inbound traffic is restricted to specific subnets (AKS, JumpBox, Build Agent) on port 443 (HTTPS), while all other inbound traffic is denied. Outbound traffic is limited to Azure Container Registry and Microsoft Entra ID, with all other outbound traffic denied. The association of the subnet with a route table further suggests that traffic is routed through a central firewall for inspection, adding an extra layer of security.\n\nCNA-01-build-agents-fw.tf:\nThe provided Terraform configuration configures an Azure Firewall Policy Rule Collection Group named build_agent_fw_group_premium with a priority of 230, associated with the firewall policy intelli_fw_policy. Within this group, the build_agent_fw_network_rules network rule collection (priority 240) allows outbound HTTPS (port 443), HTTP (port 80), and SSH (port 22) traffic from the source subnet defined by the variable var.build_agent_subnet_address_space to any destination. The rules explicitly allow traffic required for build agents to download distro updates (HTTP) and for Terraform to download module plugins from Azure DevOps (SSH), in addition to standard secure web traffic (HTTPS). This demonstrates a configuration that limits outbound traffic to specific ports and protocols for a defined subnet, as required by the control.\n\nCNA-01-jumpbox-fw.tf:\nThe Terraform configuration file defines firewall rules for a Jumpbox, limiting inbound and outbound traffic as follows:\n\n*   **Network Rule Collection:**\n    *   Allows outbound HTTPS (port 443) and HTTP (port 80) traffic from the Jumpbox subnet to any destination.\n    *   Allows outbound proxy traffic (ports 8080 and 8443) from subnet 10.0.4.024 to the firewall's private IP.\n*   **Application Rule Collection:**\n    *   Allows outbound traffic to specific FQDNs related to Azure portal management, Ubuntu package repositories, Microsoft package repositories, Ubuntu ESM, and additional Ubuntu mirrors and CDNs from the Jumpbox subnet.\n\nThese rules limit both inbound and outbound traffic for the Jumpbox.\n\nCNA-01_CNA-03-jumpbox-nw.tf:\n\nThe provided Terraform configuration file for the Azure jumpbox subnet effectively demonstrates the implementation of traffic limitation for an information resource. The evidence shows that both inbound and outbound traffic are strictly controlled through the application of a Network Security Group (NSG) and a route table.\n\n**Inbound Traffic Limitation:**\n*   The `azurerm_network_security_group` named jump-nsg is configured with a `Deny-All-Inbound` rule (Priority 200). This rule ensures that, by default, all inbound traffic to the `jumpboxSubnet` is blocked.\n*   Specific Allow rules are defined only for essential services: `AllowSshInbound` (TCP22) and `AllowSquidInbound` (TCP3128). Crucially, the source of this allowed inbound traffic is restricted exclusively to the `var.bastion_subnet_address_space`, meaning only connections originating from the designated Bastion subnet are permitted. This implements a least-privilege access model for inbound connectivity.\n\n**Outbound Traffic Limitation:**\n*   Similarly, the jump-nsg includes a `Deny-All-Outbound` rule (Priority 200), ensuring that all outbound traffic from the subnet is blocked by default.\n*   Explicit Allow rules are configured for necessary outbound communications: `Allow-Outbound-DNS` (UDP53), `Allow-Outbound-Https` (TCP443), `Allow-Outbound-Http` (TCP80 for updates), and `Allow-Outbound-Microsoft-Entra` (using the `AzureActiveDirectory` service tag for authentication). This creates an allow-list for permitted outbound connections.\n*   Furthermore, the `azurerm_subnet_route_table_association` named jumpbox-rt forces all outbound traffic from the `jumpboxSubnet` through a specific route table (`azurerm_route_table.fw-route_table.id`). This forced tunneling mechanism ensures that traffic egresses via a central network appliance (e.g., an Azure Firewall) for additional inspection and filtering, thereby providing an extra layer of outbound traffic control.\n\n**Conclusion:** The Terraform configuration demonstrates that the `jumpboxSubnet` is configured to limit both inbound and outbound traffic effectively through the principle of least privilege, allowing only explicitly defined and necessary communication flows, thereby meeting the control objective.\n\nCNA-01-aks-fw.tf:\nBased on the Terraform configuration, the Azure Firewall Policy Rule Collection Group aks-fw-rcg is configured to limit both inbound and outbound traffic. The configuration defines both Application and Network Rule Collections. The Application Rule Collection aks_fw_app_rules allows outbound HTTPS traffic on port 443 from the production, test, and development virtual networks (defined by the variables var.prod_vnet_address_space, var.test_vnet_address_space, and var.dev_vnet_address_space) to the AzureKubernetesService FQDN Tag, limiting traffic to only the necessary AKS management endpoints. The Network Rule Collection aks_fw_network_rules allows outbound traffic on TCP ports 443, 465, and 53 from the same virtual networks to any destination. While the destination addresses are broad, the configuration limits the traffic based on specific ports and protocols, contributing to the control objective of limiting inbound and outbound traffic.\n\nCNA-01-openai.tf:\nThe Terraform configuration effectively limits both inbound and outbound traffic for the OpenAPI subnet. The `azurerm_network_security_group.openapi_nsg` resource defines a strict set of security rules. Inbound traffic is limited to port 443 (HTTPS) from specific subnets (AKS, JumpBox, BuildAgent), with a Deny-All-Inbound rule blocking all other traffic. Outbound traffic is restricted to the AzureActiveDirectory service tag, with a Deny-All-Outbound rule in place. The `azurerm_subnet_network_security_group_association.openapi_nsg_assoc` resource ensures that these rules are applied to the `openapi-sn` subnet. Additionally, the `azurerm_subnet_route_table_association.openapi_sn_rt_association` resource associates a route table with the subnet, providing further control over outbound traffic by directing it through a defined path.\n\n\nCNA-01-bastion.tf:\nTesting Notes:\n\nThe Terraform configuration effectively configures network security to limit both inbound and outbound traffic for the Azure Bastion service. The configuration uses a Network Security Group (NSG) with specific rules to control traffic to and from the Bastion subnet.\n\n*   Inbound Traffic:\n    *   The NSG allows inbound HTTPS traffic (port 443) from the internet, enabling users to connect to the Bastion service.\n    *   It permits traffic from Azure services like Gateway Manager and Azure Load Balancer, which are necessary for management and health probes.\n    *   Internal communication within the virtual network is allowed for Bastion service components.\n    *   A deny-all rule blocks any other inbound traffic.\n*   Outbound Traffic:\n    *   The NSG allows outbound SSH (port 22) and RDP (port 3389) traffic to virtual machines within the virtual network.\n    *   It permits traffic to AzureCloud (port 443) for logging and other Azure services.\n    *   Internal communication within the virtual network is allowed for Bastion service components.\n    *   Traffic to the internet (port 80) is allowed for session management and certificate validation.\n    *   A deny-all rule blocks any other outbound traffic.\n*   Subnet Association:\n    *   The NSG is associated with the AzureBastionSubnet, ensuring that the defined rules are enforced.",
        "Test Instructions":"Verify network security group (NSG) rules, firewall configurations, or equivalent cloud controls to confirm all inbound and outbound traffic is explicitly limited to necessary ports and protocols.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-CNA-01, SSP-1",
        "Linked Evidence":"CNA-01-acr-nw.tf,CNA-01-aks-fw.tf,CNA-01-bastion.tf,CNA-01-build-agents-fw.tf,CNA-01_CNA-03-jumpbox-nw.tf,CNA-01-firewall.tf,CNA-01-jumpbox-fw.tf,CNA-01-openai.tf"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-CNA-02",
        "Control ID":"KSI-CNA-02",
        "Control Description":"Design systems to minimize the attack surface and minimize lateral movement if compromised",
        "Testing Notes":"\nCNA-02-meshauthentication.yaml:\nBased on the evidence provided, the Kubernetes manifest uses a Linkerd service mesh to define a `MeshTLSAuthentication` resource. This resource limits the attack surface by specifying which client identities (Kubernetes ServiceAccounts) are permitted to establish mTLS connections. The use of `identityRefs` in the manifest allows administrators to define a list of allowed ServiceAccounts, effectively minimizing lateral movement by restricting which services can communicate with each other. The `linkerd.enabled` flag ensures that Linkerd integration is optional, providing flexibility while maintaining a secure posture when enabled.\n\nCNA-02-authorizationpolicy.yaml:\nTesting notes:\n\nThe AuthorizationPolicy enforces mutual TLS (mTLS) authentication for the target service, ensuring that only connections from other trusted services within the Linkerd service mesh are accepted. The policy is dynamically named and deployed into the same Kubernetes namespace as the Helm release. The targetRef specifies the Linkerd Server resource to which the policy applies, and the requiredAuthenticationRefs mandate MeshTLSAuthentication, verifying that the client is part of the Linkerd service mesh and has completed a mutual TLS handshake. The policy is only created if Linkerd is enabled, allowing for optional integration.\n\nCNA-02-server.yaml:\nThe Linkerd Server resource, when enabled via the `.Values.linkerd.enabled` flag, restricts traffic to specific pods based on labels defined in the `actionplan.selectorLabels` template, limiting the attack surface.  The `accessPolicy` setting, configured via `.Values.linkerd.accessPolicy`, further restricts connections to the server, minimizing potential lateral movement by controlling which clients can connect. The resource is deployed in the release's namespace, isolating it from other deployments.\n\nCNA-02-app-allowedservices.yaml:\nThe provided configuration snippet demonstrates a robust access control policy that effectively minimizes the attack surface and restricts lateral movement. The configuration explicitly defines a whitelist of seven service accounts authorized to communicate with the target application.  This approach adheres to the principle of least privilege, limiting the potential impact of a compromised service account. The enforcement of this policy within a service mesh further enhances security by isolating the application and restricting connections to only services within the mesh. Only the service accounts explicitly listed are permitted, effectively preventing unauthorized access and limiting lateral movement in the event of a successful attack on a non-whitelisted service.\n\nCNA-02-values.yaml:\nThe `values.yaml` file demonstrates several security-focused configurations that align with minimizing the attack surface and lateral movement:\n\n*   **Azure Workload Identity:** The `podLabels` section includes `azure.workload.identityuse: true`, indicating the application uses Azure Workload Identity for secure authentication, reducing the risk of exposed credentials.\n*   **Principle of Least Privilege:** The `securityContext` drops all Linux capabilities (`capabilities.drop: ALL`), sets `readOnlyRootFilesystem: true`, disables privilege escalation (`allowPrivilegeEscalation: false`), and runs the container as a non-root user (`runAsNonRoot: true`, `runAsUser: 1000`). These settings limit the potential impact of a compromised container.\n*   **Service Mesh (Linkerd):** The `linkerd.enabled: true` setting enables Linkerd, a service mesh, which provides features like mutual TLS, traffic encryption, and improved observability, further limiting lateral movement.\n*   **Image Pull Policy:** The `image.pullPolicy: Always` setting ensures that the latest image is always pulled. While not directly related to attack surface, it assists in ensuring the application is running the most up-to-date version with the latest security patches.\n*   **Network Segmentation:** The `service.type: ClusterIP` setting restricts access to the service from within the Kubernetes cluster, limiting external exposure.\n*   **Security Profiles:** Usage of `appArmorProfile` and `seccompProfile` set to `RuntimeDefault` to enforce security policies at the container runtime level.\n\n\nCNA-02-log-analytics.tf:\nTesting Notes:\n\nThis Terraform configuration hardens the system against attacks and limits lateral movement by implementing the following:\n\n*   **Least Privilege Access:** The configuration uses Azure Privileged Identity Management (PIM) to enforce just-in-time (JIT) access for sensitive roles like Microsoft Sentinel Contributor, Microsoft Sentinel Reader, Log Analytics Contributor, and Log Analytics Reader. This ensures that users only have the necessary permissions when they need them, reducing the window of opportunity for attackers to exploit compromised accounts.\n*   **Role Assignment to Groups:** PIM roles are assigned to Azure AD groups (e.g., security team, cloud ops team) instead of individual users. This simplifies access management and reduces the risk of orphaned accounts with excessive privileges.\n*   **Mandatory Justification:** Activation of PIM roles requires users to provide a justification, creating an audit trail and promoting accountability.\n*   **Limited Activation Duration:** PIM roles can only be activated for a maximum of 8 hours, further limiting the potential impact of compromised accounts.\n*   **Comprehensive Logging:** Security-related logs from various Azure services (e.g., Azure Active Directory, Azure Diagnostics, Security Center) are exported to a dedicated Storage Account. This allows for centralized monitoring and analysis of security events, enabling early detection of suspicious activity and potentially limiting the impact of lateral movement. The use of `ignore_changes = [table_names]` allows flexibility.\n*   **Segregation of Duties:** The configuration separates the management of Azure AD groups (identities) from the role assignments. This promotes a separation of duties and reduces the risk of unauthorized access.\n*   **Centralized Access Management:** By using Terraform and PIM, access management is centralized and automated, ensuring consistent enforcement of security policies across the Azure environment. This reduces the risk of manual errors and misconfigurations that could lead to security vulnerabilities.\n\n\n\n",
        "Test Instructions":"Review system architecture diagrams and network segmentation policies to assess how attack surface is minimized and lateral movement is restricted (e.g., micro-segmentation, jump boxes).",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-CNA-02, SSP-1",
        "Linked Evidence":"CNA-02-app-allowedservices.yaml,CNA-02-authorizationpolicy.yaml,CNA-02-log-analytics.tf,CNA-02-meshauthentication.yaml,CNA-02-server.yaml,CNA-02-values.yaml"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-CNA-03",
        "Control ID":"KSI-CNA-03",
        "Control Description":"Use logical networking and related capabilities to enforce traffic flow controls",
        "Testing Notes":"CNA-03-build-agents-fw.tf:\nThe Terraform code configures an Azure Firewall Policy with a rule collection group named 'build-agent-fw-group-premium'. This group contains a network rule collection ('build_agent_fw_network_rules') that allows outbound HTTPS (port 443), HTTP (port 80), and SSH (port 22) traffic from the build agent subnet (defined by the variable `var.build_agent_subnet_address_space`) to any destination. The firewall rules explicitly control network traffic based on source, destination, and port, demonstrating the use of logical networking capabilities to enforce traffic flow controls. The configuration uses a firewall policy to define and enforce these rules. By defining rules based on subnet and port, the configuration ensures that only authorized traffic flows from the build agent subnet, thus satisfying the control requirement.\n\nCNA-03-jumpbox-fw.tf:\nThe provided Terraform configuration enforces traffic flow controls using Azure Firewall Policy rules. The configuration defines a rule collection group with network and application rule collections. The network rule collection allows outbound HTTPHTTPS traffic from the jumpbox subnet to any IP address and allows proxy traffic from the 10.0.4.024 subnet to the firewall's private IP address on ports 8080 and 8443. The application rule collection allows outbound traffic from the jumpbox subnet to specific FQDNs related to Azure management, Ubuntu package repositories, and Microsoft package repositories. This configuration restricts traffic to only necessary destinations, implementing logical networking controls to limit the jumpbox's network access.\n\nCNA-03-aks-fw.tf:\nBased on the Terraform configuration, the Azure Firewall Policy Rule Collection Group 'aks_fw_rules' enforces traffic flow controls using logical networking. The 'aks_fw_app_rules' collection allows outbound HTTPS traffic from specified virtual network address spaces (prod, test, dev) to the 'AzureKubernetesService' FQDN tag, restricting AKS traffic to necessary endpoints. The 'aks_fw_network_rules' collection further refines control by allowing HTTPS (443), SMTPS (465), and DNS (53) traffic from the same virtual networks, demonstrating granular control over network traffic based on protocol and port. This configuration utilizes network rules and application rules to logically segment and control traffic flow, satisfying the control objective.\n\nCNA-03-openai.tf:\nThe Terraform configuration effectively uses logical networking capabilities in Azure to enforce traffic flow controls for the OpenAPI subnet. The configuration creates a dedicated subnet for OpenAPI private endpoints and enforces a strict 'deny-by-default' posture using a Network Security Group (NSG). The NSG allows only specific inbound traffic from authorized subnets (AKS, JumpBox, BuildAgent) on port 443 (HTTPS) and outbound traffic to Azure Active Directory, denying all other traffic. This ensures that only authorized traffic can reach the OpenAPI endpoints, and outbound communication is restricted to Microsoft Entra ID. Furthermore, the association of a route table allows for centralized traffic routing, likely enforcing additional traffic flow controls. The explicit enabling of private endpoint network policies on the subnet ensures NSG rules are enforced on private endpoints. These configurations demonstrate a layered approach to network security, effectively limiting network access and enforcing traffic flow controls as required by the control description.\n\nCNA-03-bastion.tf:\nThe Terraform configuration script effectively uses logical networking capabilities to enforce traffic flow controls for an Azure Bastion host. The script defines a dedicated subnet for the Bastion host and associates it with a Network Security Group (NSG). The NSG contains a comprehensive set of rules that control both inbound and outbound traffic. Specific rules like `AllowHttpsInbound`, `AllowAzureGatewayManagerInbound`, and `AllowAzureLoadBalancerInbound` explicitly permit necessary inbound traffic, while `AllowSshOutbound` and `AllowAzureCloudOutbound` control outbound traffic. The use of service tags like `GatewayManager`, `AzureLoadBalancer`, `VirtualNetwork`, `AzureCloud`, and `Internet` in the NSG rules demonstrates the use of logical grouping to define network access, and the final DenyAll rules for both inbound and outbound traffic ensures that only explicitly permitted traffic is allowed, thus enforcing traffic flow controls.\n\nCNA-03-acr-nw.tf:\nBased on the provided Terraform code summary, the control 'Use logical networking and related capabilities to enforce traffic flow controls' is met as follows:\n\n*   **Subnet Creation:** A dedicated subnet (`acrSubnet`) is created for Azure Container Registry (ACR) private endpoints, isolating this service from other network traffic.\n*   **Network Security Group (NSG):** An NSG (`acr_nsg`) is implemented with specific inbound and outbound rules to control traffic flow. The NSG uses a deny-by-default approach, only allowing explicitly permitted traffic.\n*   **Inbound Rules:** Inbound traffic is restricted to HTTPS (port 443) from specific, known subnets (AKS Prod, Dev, Test, JumpBox, BuildAgent subnets), limiting access to the ACR.\n*   **Outbound Rules:** Outbound traffic is restricted to AzureContainerRegistry (port 443) and AzureActiveDirectory service tags, ensuring that the ACR can only communicate with necessary Azure services.\n*   **Route Table Association:** The subnet is associated with a route table (`azurerm_route_table.fw-route_table.id`), forcing all outbound traffic through a central firewall for inspection and centralized egress policy enforcement. This ensures all traffic is inspected.\n*   **NSG Association:** The NSG is associated with the subnet (`azurerm_subnet_network_security_group_association.acr_nsg_assoc`), enforcing the defined security rules on the subnet.\n\nThese configurations demonstrate the use of logical networking (subnets, route tables) and network security capabilities (NSGs, firewall) to enforce strict traffic flow controls, aligning with the stated control objective.\n\nCNA-01_CNA-03-jumpbox-nw.tf:\nTesting Notes: The provided Terraform configuration demonstrates the effective use of logical networking capabilities to enforce traffic flow controls within the Azure environment. This is evidenced by: \n\n1.  **Network Segmentation:** The creation of a dedicated `jumpboxSubnet` isolates the jumpbox resources, establishing a defined boundary for traffic management. This logical segmentation is fundamental to applying targeted controls.\n\n2.  **Forced Egress Routing:** The `azurerm_subnet_route_table_association` explicitly routes all outbound traffic from the `jumpboxSubnet` through a central `fw-route-table`. This force egress through the firewall mechanism ensures that all external communication is subjected to inspection and control, directly enforcing traffic flow by preventing uncontrolled direct outbound connections.\n\n3.  **Granular Network Security Group (NSG) Rules:** The `azurerm_network_security_group` (`jump-nsg`), which is associated with the `jumpboxSubnet`, implements a highly controlled traffic policy based on the principle of least privilege. \n    *   **Inbound Traffic Controls:** Inbound access is strictly limited. For instance, SSH (port 22) and Squid proxy (port 3128) connections are only permitted from the `bastion_subnet_address_space`. A high-priority `Deny-All-Inbound` rule ensures that any traffic not explicitly allowed is blocked, preventing unauthorized access. \n    *   **Outbound Traffic Controls:** Outbound communication is similarly restricted. Only essential services like DNS (port 53), HTTPS (port 443), HTTP (port 80, for updates), and traffic specifically to Microsoft Entra ID (using the `AzureActiveDirectory` service tag) are explicitly permitted. A `Deny-All-Outbound` rule serves as a catch-all, blocking any outbound traffic not explicitly whitelisted, thereby ensuring tight control over external communications. \n\nCollectively, these configurations leverage Azure's logical networking constructs (subnets, route tables, and NSGs with detailed rules) to rigorously define, limit, and enforce acceptable traffic flows, thereby meeting the control objective.\n\n\nCNA-03-firewall.tf:\nBased on the evidence provided, the Terraform code enforces traffic flow controls through several key mechanisms:\n\n*   **Azure Firewall Deployment:** The code deploys an Azure Firewall, a managed network security service that inspects traffic and enforces rules.\n*   **Subnet Isolation:** A dedicated subnet (`AzureFirewallSubnet`) is created for the firewall, isolating it from other resources and ensuring all traffic passes through it.\n*   **Egress Routing:** A route table (`fw-route_table`) is configured to route all outbound traffic from other subnets through the firewall. This is achieved by setting the `address_prefix` to `0.0.0.00` and the `next_hop_type` to `VirtualAppliance` with the `next_hop_in_ip_address` pointing to the firewall's private IP address.\n*   **Firewall Rules and Policies:** The firewall is associated with a Firewall Policy (defined in the `firewall_rules` module), which contains the specific rules governing allowed and denied traffic. The code passes subnet address spaces (jumpbox, build_agent, test_vnet, prod_vnet, dev_vnet, and bastion) to the module, which are likely used in the rules.\n*   **Diagnostic Logging:**  Firewall logs are enabled and sent to a Log Analytics Workspace, providing visibility into traffic patterns and security events, which can be used to refine traffic flow controls.\n\nTesting should verify that the route table is correctly associated with the relevant subnets and that the firewall policy contains rules that appropriately restrict traffic based on the organization's security requirements. Also verify the logs are being generated and ingested into the Log Analytics Workspace. Finally, confirm that the address spaces passed to the `firewall_rules` module are accurate and reflect the current network configuration.",
        "Test Instructions":"Examine network configurations (VLANs, subnets, routing tables, security groups) to confirm logical traffic flow controls are in place and enforced.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-CNA-03, SSP-1",
        "Linked Evidence":"CNA-01_CNA-03-jumpbox-nw.tf,CNA-03-acr-nw.tf,CNA-03-aks-fw.tf,CNA-03-bastion.tf,CNA-03-build-agents-fw.tf,CNA-03-firewall.tf,CNA-03-jumpbox-fw.tf,CNA-03-openai.tf"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-CNA-04",
        "Control ID":"KSI-CNA-04",
        "Control Description":"Use immutable infrastructure with strictly defined functionality and privileges by default",
        "Testing Notes":"CNA-04-values.yaml:\nThe provided evidence demonstrates the use of immutable infrastructure with strictly defined functionality and privileges by default. The `securityContext` settings within the `values.yaml` file explicitly enforce several security measures: `readOnlyRootFilesystem: true` ensures that the container's root filesystem is immutable, preventing unauthorized modifications at runtime. `runAsNonRoot: true` and `runAsUser: 1000` mandate that the container runs as a non-root user, limiting the potential damage from security breaches. `capabilities.drop: [ALL]` drops all default Linux capabilities, further reducing the attack surface. These configurations align with the control objective of using immutable infrastructure with strictly defined privileges.\n\nCNA-04-Entra ID Group - Azure App Config Read Only (Prod).png:\nBased on the provided evidence, the 'Azure App Config Read-Only (Prod)' group in Azure contains 31 service principals, all of which are managed identities. These identities adhere to a strict naming convention (prod-<service-name>-mi), indicating a deliberate and consistent approach to service principal naming. The use of managed identities, which are inherently immutable, ensures that applications and services access the App Configuration with predefined read-only privileges, aligning with the control objective of immutable infrastructure with strictly defined functionality and privileges by default. The PIM configuration enforces least privilege.\n\nCNA-04-alz-mgmt terraform configuration identities.tf.png:\nBased on the evidence provided in `identities.tf`, the Terraform configuration file defines User-Assigned Managed Identities for Azure services, representing an immutable infrastructure approach. Each identity is created with a specific purpose and assigned strictly defined privileges. For example, `connectivity-storage-accounts-mi` is explicitly created for use by storage accounts. The use of Terraform to define these resources as code ensures that the infrastructure is consistently deployed and configured, while also allowing for version control and automated deployments. The file also creates a resource group `connectivity-mi-infra-rg` to contain the identities, demonstrating a clear separation of concerns. This aligns with the control objective of using immutable infrastructure with strictly defined functionality and privileges by default.\n\nCNA-04-Entra ID - App registration - intelli-prod-fr-appconfig.png:\nBased on the evidence provided, the Azure App Configuration resource 'intelli-prod-fr-appconfig' utilizes role-based access control (RBAC) with Azure Active Directory groups to manage permissions. Specifically, the 'Azure App Config Read-Write (Prod)' group is assigned the 'App Configuration Data Owner' role, granting it full control, while the 'Azure App Config Read-Only (Prod)' group has the 'App Configuration Data Reader' role, providing read-only access. This aligns with the control by strictly defining functionality and privileges through role assignments and leveraging groups for access management, which helps ensure immutability by limiting who can modify the configuration and what actions they can perform. The scope of these assignments is limited to 'This resource', preventing privilege escalation to other resources.\n\nCNA-04-message-scheduler-v0.1.3-results.xml:\nBased on the provided XCCDF scan results, the container image `intelliacr.azurecr.iomessage-scheduler:v0.1.3` demonstrates adherence to the principle of immutable infrastructure with strictly defined functionality and privileges in the following ways:\n\n*   **Absence of Unnecessary Services:** The scan results show `pass` for rules checking the absence of insecure or unnecessary packages (e.g., `telnet`, `tigervnc`, `vsftpd`). This indicates a minimal image, reducing the attack surface and adhering to the principle of strictly defined functionality. No additional software or services beyond the intended purpose are present.\n*   **Inherited Host Controls:** The prevalence of `not\/applicable` results reinforces the concept of containers inheriting security controls from the host. This aligns with immutable infrastructure, where the container's security posture is largely pre-defined and managed by the underlying host environment, limiting modifications within the container itself.\n*   **Passing Applicable Security Checks:** The scan achieved a perfect score (100\/100 and 87\/87), indicating that all security checks applicable to the container image were passed. This confirms that the container image, within its defined scope, meets the security requirements of the benchmark.\n*   **Limited Privileges:** The `rationale` for rule `V-203695 (High)` notes that Chainguard images (the likely context for this file) contain minimal software, reducing the risk of non-privileged users executing privileged functions. This suggests an effort to minimize potential privilege escalation vectors within the container.\n\nIn summary, the evidence demonstrates that the container image is built with a minimal set of functions, relies on host-level security controls, and passes all applicable security checks, which collectively supports the assertion that it adheres to the principle of immutable infrastructure with strictly defined functionality and privileges by default. The XCCDF report provides a structured and automated means of verifying these aspects of the control.",
        "Test Instructions":"Inspect deployment pipelines and configuration management tools to verify that infrastructure components are deployed as immutable resources with strictly defined functionality and least privilege.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-CNA-04, SSP-1",
        "Linked Evidence":"CNA-04-alz-mgmt terraform configuration identities.tf,CNA-04-alz-mgmt terraform configuration identities.tf.png,CNA-04-Entra ID - App registration - intelli-prod-fr-appconfig.png,CNA-04-Entra ID - App registration - intelli-prod-fr-appconfig.tf,CNA-04-Entra ID Group - Azure App Config Read Only (Prod).json,CNA-04-Entra ID Group - Azure App Config Read Only (Prod).png,CNA-04-message-scheduler-v0.1.3-results.xml,CNA-04-values.yaml"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-CNA-05",
        "Control ID":"KSI-CNA-05",
        "Control Description":"Have denial of service protection",
        "Testing Notes":"CNA-05-AzureFirewall_SubnetZoneVariables.tf:\nThe Terraform variables file defines network address spaces for jumpbox, build agent, bastion, production, test, and development environments. It also specifies a private IP address for a firewall. While the variables configure network infrastructure, the file itself doesn't demonstrate active denial-of-service (DoS) protection mechanisms. Further evidence is required to confirm DoS protection measures are in place.\n\nCNA-05-AzureFirewall_PremiumFWPolicy_IDS.tf:\nThe Terraform configuration defines an Azure Firewall Policy with the Premium SKU, which includes denial of service (DoS) protection capabilities.  The configuration explicitly sets `sku = Premium`, confirming that the deployed firewall has DoS protection enabled by default.  This meets the control requirement for having denial of service protection.\n\nCNA-05-AzureFirewall.tf:\nBased on the evidence provided, the Azure Firewall is implemented to provide denial of service protection. The terraform code deploys an Azure Firewall with a public IP address and configures a route table to direct all outbound traffic through the firewall. Diagnostic logging is enabled to monitor and analyze traffic patterns, which can help identify and mitigate denial-of-service attacks. The firewall rules, managed in a separate module, define the specific traffic filtering and security policies. However, the route table contains a hardcoded IP address for the firewall, which should be dynamically assigned to ensure proper routing. \n\nCNA-05-AzureKubenetesService_FirewallRules.tf:\nBased on the provided Terraform configuration, the Azure Firewall Policy includes network rule collections that allow TCP traffic on ports 443, 465, and 53 from the defined virtual network address spaces (prod, test, and dev) to any destination. While not explicitly labeled as denial-of-service protection, the ruleset limits the allowed protocols and ports, which reduces the attack surface and potential for certain types of denial-of-service attacks. The inclusion of the AzureKubernetesService Service Tag also ensures that only traffic destined for the AKS service is allowed, further limiting potential attack vectors.\n\nCNA-05-AzureFrontDoorWAF.tf:\nThe Terraform configuration file demonstrates denial of service protection through the use of Azure Front Door's Web Application Firewall (WAF) capabilities. Specifically, the configuration includes rate limiting rules that are applied to both production and developmenttest environments. These rules are designed to block requests exceeding defined thresholds within a one-minute duration, mitigating potential denial-of-service attacks. The use of the Premium_AzureFrontDoor SKU enables these advanced WAF features. Furthermore, the configuration utilizes managed rulesets, specifically the Microsoft_DefaultRuleSet and Microsoft_BotManagerRuleSet, to provide additional layers of protection against common attack patterns and bot traffic, enhancing the overall DoS protection strategy.\n\nCNA-05-AzureBastion_Jumpbox_FirewallRules.tf:\nThe provided Terraform configuration file defines an Azure Firewall Policy Rule Collection Group named `jumpbox-fw-rcg` which contains network and application rule collections. While the configuration does not explicitly state denial-of-service (DoS) protection, the firewall configuration limits outbound traffic from the jumpbox subnet to specific ports and FQDNs. Specifically, the network rule collection allows outbound TCP traffic on ports 443 and 80, and the application rule collection allows traffic to a defined list of FQDNs, including those required for Azure and Ubuntu management. This restriction of allowed traffic reduces the attack surface and limits potential vectors for DoS attacks. However, there are no configurations for rate limiting or specific DoS mitigation techniques. Deeper inspection of actual traffic flow and volume would be needed to confirm DoS protection is adequate.\n\nCNA-05-front-door.tf:\nThe Azure Front Door Premium profile, along with its associated Web Application Firewall (WAF) policies, confirms the existence of denial-of-service protection. The WAF policies for both production and development environments include custom rate-limiting rules that block requests exceeding defined thresholds, mitigating potential DoS attacks. Specific rate limits are configured for different application endpoints (domains), controlling the number of requests per minute. Furthermore, the use of managed rulesets, such as the Microsoft Bot Manager RuleSet, helps identify and manage malicious bot traffic, adding another layer of DoS protection. The configuration's 'Prevention' mode ensures that the WAF actively blocks malicious requests, preventing them from reaching the application.\n\nCNA-05-AzureBuildAgents_FirewallRules.tf:\nThe provided Azure Firewall configuration implements denial-of-service (DoS) protection by controlling the build agent's outbound traffic. The configuration limits traffic based on source (build agent subnet), protocol (TCP), and destination ports (80, 443, and 22), effectively reducing the attack surface. While not explicitly labeled as DoS protection, the firewall rules inherently mitigate certain DoS attack vectors by restricting the build agent's ability to initiate connections to arbitrary ports and services on the internet. This control ensures that the build agent can only access the necessary services, reducing the potential for DoS attacks originating from or targeting the build agent.\n\nKSI-CNA-05-Azure-front-door.tf:\n\n\nThe provided Terraform configuration for Azure Front Door Premium demonstrates the implementation of denial of service (DoS) protection through Web Application Firewall (WAF) policies and granular rate-limiting rules.\n\n**Evidence Meeting Control Requirements:**\n\n1.  **Azure Front Door Premium:** The use of Azure Front Door Premium, a global, scalable entry-point, inherently provides a layer of DoS protection by distributing traffic and absorbing large volumes of requests before they reach backend services. Its architecture is designed to withstand common network-layer attacks.\n\n2.  **Web Application Firewall (WAF) Policies:**\n    *   Separate WAF policies (`prod_waf_policy` and `dev_waf_policy`) are defined for production and developmenttest environments, both configured in `Prevention` mode. This indicates active blocking of malicious traffic.\n    *   Both policies include `Microsoft_DefaultRuleSet` (v2.1) and `Microsoft_BotManagerRuleSet` (v1.0), which are comprehensive managed rule sets designed to detect and mitigate common web vulnerabilities and bot attacks. While currently configured in `Log` mode, their presence signifies the capability and intention to identify and potentially block such traffic, contributing to overall DoS resilience.\n\n3.  **Custom Rate-Limiting Rules:** This is a primary mechanism for DoS protection against volumetric attacks or abuse.\n    *   **Granular Throttling:** The configuration defines multiple custom rate-limiting rules with specific thresholds (e.g., 200, 2000 requests per minute for production; 100, 1000 requests per minute for devtest) and applies them to specific hostnamesdomains (e.g., `login.intelligrc.app`, `api.intelligrc.app`, `intelligrc.app`, `dev-core-apigw.intelligrc.app`).\n    *   **Automated Blocking:** Requests exceeding these predefined thresholds within a 1-minute duration are automatically `Block`ed, preventing a single source or a distributed attack from overwhelming the application endpoints.\n    *   **Environment-Specific Thresholds:** The differentiation in thresholds between production (higher tolerance) and developmenttest (lower tolerance) reflects an understanding of expected traffic patterns and tailored protection strategies.\n    *   **Host-Based Application:** The rules are applied based on the `Host` header, ensuring that specific application components or APIs can have their own rate limits, providing targeted protection.\n\nIn summary, the presence of Azure Front Door Premium, coupled with WAF policies operating in `Prevention` mode, and critically, the detailed and active rate-limiting rules, collectively demonstrate that effective denial of service protection mechanisms are in place and configured within the environment. These controls are designed to mitigate the impact of excessive or malicious traffic, safeguarding the availability of the applications.",
        "Test Instructions":"Request documentation or demonstration of DDoS protection mechanisms (e.g., WAF, CDN, cloud DDoS services) and their configuration.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-CNA-05, SSP-1",
        "Linked Evidence":"CNA-05-AzureBuildAgents_FirewallRules.tf,CNA-05-AzureFirewall_PremiumFWPolicy_IDS.tf,CNA-05-AzureFirewall.tf,CNA-05-azure-frontdoor.pdf,CNA-05-AzureFrontDoorWAF.tf,CNA-05-AzureKubenetesService_FirewallRules.tf,CNA-05-front-door.tf,KSI-CNA-05-Azure-front-door.tf"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-CNA-06",
        "Control ID":"KSI-CNA-06",
        "Control Description":"Design systems for high availability and rapid recovery",
        "Testing Notes":"\nCNA-06-aks.tf:\nBased on the Terraform code, the AKS cluster is designed for high availability through several key features. It is deployed across Azure Availability Zones 1 and 3, providing resilience against single-zone failures. The cluster also utilizes autoscaling for both system and user node pools, allowing it to dynamically adjust resources based on demand, ensuring continuous operation during peak loads. Furthermore, the configuration includes a comprehensive backup and recovery solution using Azure Backup for AKS, with backups performed every 4 hours and retained for 7 days. This setup enables rapid recovery in case of failures or data loss. The integration with Azure Key Vault and Disk Encryption Sets with customer-managed keys adds an extra layer of security and control over the encryption of the AKS node disks. Finally, the use of a private DNS zone for the API server enhances security by preventing public exposure.\n\nCNA-06-backup-vault.tf:\nThe Terraform configuration file demonstrates designing systems for high availability and rapid recovery by implementing Azure Backup resources. The configuration creates a backup vault within a dedicated resource group (`azurerm_resource_group.backup_vault_rg`) ensuring organizational control and isolation. The use of a custom module (`backup_vault`) sourced from a version-controlled repository (`git::ssh:git@ssh.dev.azure.comv3intelligrcIntelliGRCinfra-modules?ref=backup-vaultv0.5.0`) promotes standardization and reusability of the backup vault deployment. The configuration of soft delete with a 90-day retention period (`soft_delete_retention_days = 90`) allows for rapid recovery from accidental deletions or data corruption. The inclusion of a Data Protection Resource Guard (`azurerm_data_protection_resource_guard`) provides multi-user authorization, adding an extra layer of security for critical backup operations. The `depends_on` attribute ensures that the backup vault is created only after the networking module and resource guard are successfully deployed, establishing a proper dependency order. All resources are deployed within a spoke environment using the `azurerm.spoke` provider, aligning with a hub-and-spoke architecture, which is a common practice for scalable and resilient deployments.\n\nCNA-06-blob-storage.tf:\nThe Terraform configuration provides several key features that contribute to high availability and rapid recovery for the Azure Storage Account:\n\n*   **Replication:** The storage account uses a `Standard` tier with `StorageV2` kind, and the `account_replication_type` is configurable via variables, offering options for redundancy (e.g., GRS, LRS, ZRS) to ensure data availability in case of failures.\n*   **Backup and Restore:**\n    *   **Blob Service Properties:** The configuration enables soft delete and point-in-time restore features for blobs (conditionally based on variables), allowing for recovery from accidental deletions or data corruption.\n    *   **Azure Backup Integration:** If `var.enable_backups` is set to `true`, the configuration provisions Azure Backup resources for the storage account's blob data.\n        *   It assigns the Storage Account Backup Contributor role to the Backup Vault's managed identity, granting the vault necessary permissions.\n        *   It defines a backup policy with a GFS (Grandfather-Father-Son) retention scheme, creating daily backups with weekly, monthly, and yearly retention rules. This comprehensive backup strategy enables recovery from various data loss scenarios.\n*   **Networking:** The configuration includes an option to configure a private endpoint if `var.public_network_access_enabled` is set to `false`. This restricts network access to the storage account, limiting the attack surface and ensuring that only authorized network resources can access the storage account. By restricting access to the storage account, the private endpoint assists in protecting the storage account against unauthorized access that could impact the availability of the system.\n\nThese features collectively demonstrate a design focused on both preventing data loss (through replication, soft delete, and point-in-time restore) and enabling rapid recovery in case of failures (through Azure Backup with defined retention policies).\n\n",
        "Test Instructions":"Review system design documentation, disaster recovery plans, and recent recovery test results to assess high availability architecture and rapid recovery capabilities (e.g., failover, auto-scaling).",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-CNA-06, SSP-1",
        "Linked Evidence":"CNA-06-aks.tf,CNA-06-backup-vault.tf,CNA-06-blob-storage.tf"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-CNA-07",
        "Control ID":"KSI-CNA-07",
        "Control Description":"Ensure cloud-native information resources are implemented based on host provider\u2019s best practices and documented guidance",
        "Testing Notes":"\nCNA-07-policy_assignment_fedramp_moderate.json:\nBased on the evidence provided, the Azure Policy Assignment 'FedRAMP-Moderate' enforces several best practices for cloud-native information resources. The policy set definition ID points to the built-in FedRAMP Moderate initiative in Azure, ensuring alignment with a documented guidance. Specifically, the configuration restricts container images to those originating from 'intelliacr', limits memory and CPU resources, restricts network ports, and defines allowed security profiles and capabilities. These configurations demonstrate an implementation of host provider's best practices for securing containerized workloads.\n\nCNA-07-Terraform Azure Landing Zone Documentation.txt:\nTesting Notes:\n\nEvidence indicates that IntelliGRC implements cloud-native information resources based on Microsoft's Azure Cloud Adoption Framework (CAF) enterprise-scale architecture. The provided URL links to the official Terraform module for Azure, confirming adherence to the host provider's (Microsoft Azure) documented guidance and best practices for implementing cloud resources. The use of the 'latest' version of the module suggests an effort to stay current with recommended practices.\n\nCNA-7_IntelliGRC_Azure_Well-Architected-Framework.tf:\nThe provided Terraform code demonstrates the implementation of cloud-native information resources in Azure following the host provider's (Microsoft's) best practices and documented guidance (Cloud Adoption Framework). The `enterprise_scale` module configures core infrastructure and governance based on CAF, while the `hubnetworking` module deploys a hub-and-spoke network topology. Specific best practices implemented include: foundational landing zone deployment, network segmentation, Azure Firewall, managed identities, and centralized logging. The code explicitly defines network address spaces and configures Azure Firewall with a Premium tier, demonstrating adherence to security best practices. The use of Terraform for infrastructure as code enables consistent and repeatable deployments, aligning with documented guidance for infrastructure management.\n\nCNA-07-intelligrc_landing_zones.drawio.png:\nThe Azure architecture for IntelliGRC adheres to cloud-native best practices through a well-defined Hub-and-Spoke model and Azure Landing Zones. Evidences of this include:The Management Group structure organizes resources logically under a Tenant root group, with functional divisions for Platform, Landing Zones, Decommissioned, and Sandboxes.Subscriptions are separated by concerns, such as Management, Connectivity, and application-specific environments (intelligrc-dev, intelligrc-prod).IAM is centrally managed via Microsoft Entra ID, with Privileged Identity Management (PIM) controlling elevated role access using approval workflows, MFA, and audit reports.Azure DevOps and Git repositories are used for Infrastructure as Code (IaC), automating deployments and enforcing governance through role provisioning and policy deployment.A dedicated Management subscription centralizes security and monitoring with Log Analytics, Microsoft Sentinel, and Defender for Cloud.The Connectivity subscription hosts a central Hub network with secure inbound management access via Azure Bastion, centralized egress control via Azure Firewall, and private endpoints for shared PaaS services.The Intelli-prod subscription hosts the production application in a Spoke network, with application ingress secured by Azure Front Door and WAF, and backend services accessed via private endpoints. All outbound traffic from the Spoke is routed through the central Azure Firewall.\n\n",
        "Test Instructions":"Obtain documentation of cloud-native resource implementations and compare against the host provider's best practices and documented guidance.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-CNA-07, SSP-1",
        "Linked Evidence":"CNA-07-intelligrc_landing_zones.drawio.png,CNA-07-policy_assignment_fedramp_moderate.json,CNA-07-Terraform Azure Landing Zone Documentation.txt,CNA-7_IntelliGRC_Azure_Well-Architected-Framework.tf"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-IAM-01",
        "Control ID":"KSI-IAM-01",
        "Control Description":"Enforce multi-factor authentication (MFA) using methods that are difficult to intercept or impersonate (phishing-resistant MFA) for all user authentication",
        "Testing Notes":"\nIAM-01-Entra ID Conditional Access - CMMC - Require multifactor authentication for all users.png:\nBased on the evidence provided, the CMMC - Require multifactor authentication for all users Conditional Access policy enforces multi-factor authentication (MFA) for all users, excluding specific exceptions. This is achieved by applying the policy to all users and all cloud resources. The policy grants access only when the 'Require multifactor authentication' control is met. The policy is enabled and actively enforced.\n\nIAM-01-Entra ID Conditional Access - FedRAMP - Require passkeys for those touching FedRAMP Boundary.png:\nBased on the evidence provided, the Conditional Access policy named FedRAMP - Require passkeys for those touching FedRAMP Boundary is configured to enforce phishing-resistant MFA for specific users accessing all resources within the tenant. The policy is active and requires Phishing-resistant MFA via the Require authentication strength control. This control necessitates the use of methods like FIDO2 security keys (including passkeys) or Windows Hello for Business, which aligns with the control objective of enforcing MFA using methods difficult to intercept or impersonate. The policy is targeted at a manually defined group of users\n\nIAM-01-jumpbox.tf:\nBased on the evidence provided, the jumpbox solution enforces multi-factor authentication (MFA) using Entra ID (Azure AD) login via the `AADSSHLoginForLinux` virtual machine extension. This extension allows users to authenticate via SSH using their Entra ID credentials, which can be configured to require phishing-resistant MFA methods. Additionally, role assignments are configured to grant login permissions using the Virtual Machine Administrator Login and Virtual Machine User Login roles, assigned to Azure AD groups, further enforcing centralized identity management and MFA policies.\n\n",
        "Test Instructions":"Verify MFA enforcement for all user authentication, specifically confirming the use of phishing-resistant methods (e.g., FIDO2, smart cards, certificate-based authentication).",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-IAM-01, SSP-1",
        "Linked Evidence":"IAM-01-Entra ID Conditional Access - CMMC - Require multifactor authentication for all users.png,IAM-01-Entra ID Conditional Access - FedRAMP - Require passkeys for those touching FedRAMP Boundary.png,IAM-01-jumpbox.tf,IAM-01-Require_multifactor_authentication_for_all_users.json,IAM-01-Require_passkeys_for_those_touching_FedRAMP_Boundary.json"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-IAM-02",
        "Control ID":"KSI-IAM-02",
        "Control Description":"Use secure passwordless methods for user authentication and authorization when feasible, otherwise enforce strong passwords with MFA",
        "Testing Notes":"\nIAM-02-Rules-of-Behavior Password Requirements with MFA.png:\nBased on the evidence provided, the password policy enforces strong passwords. Specifically, it mandates a minimum password length of 16 characters and complexity requirements including the use of three of four character sets (uppercase, lowercase, numbers, and special characters). The policy explicitly prohibits the inclusion of personal or company-related information within passwords. Furthermore, the policy mandates MFA for users accessing sensitive systems or data. Finally, privileged accounts accessing sensitive systems or data MUST use FIDO2 as their primary authentication method. These controls collectively meet the requirement for strong passwords with MFA, and the use of passwordless methods where feasible.\n\nIAM-02-Entra ID Conditional Access - CMMC - Require multifactor authentication for all users.png:\nThe evidence provided demonstrates that the organization is enforcing multi-factor authentication (MFA) for all users when accessing cloud applications. The Microsoft Entra Conditional Access policy, named CMMC - Require multifactor authentication for all users, is enabled and configured to require MFA for all users, with the option to exclude specific users. The policy applies to all cloud applications integrated with the AzureEntra ID tenant. This configuration aligns with the control requirement to enforce strong passwords with MFA when passwordless methods are not feasible. The policy does not appear to have any session controls configured.\n\nIAM-02-Windows Hello For Business Global.png:\nTesting Notes:\n\nThe provided evidence details a Windows Hello for Business configuration policy that supports secure passwordless authentication where feasible, and enforces strong passwords with MFA. Specifically:\n\n*   The policy enables Windows Hello for Business, allowing for passwordless authentication using biometrics.\n*   Biometric authentication is explicitly allowed.\n*   When a PIN is used (as an alternative or fallback), the policy enforces strong PIN complexity requirements, including minimum length (14 characters), and requirements for lowercase, uppercase, and special characters.\n*   The system remembers PIN history, preventing reuse of recent PINs.\n\nThese configurations align with the control requirements for secure passwordless methods and strong passwords with MFA.\n\n",
        "Test Instructions":"Review authentication policies to confirm the use of secure passwordless methods where feasible, or strong password policies combined with MFA.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-IAM-02, SSP-1",
        "Linked Evidence":"IAM-02-Entra ID Conditional Access - CMMC - Require multifactor authentication for all users.png,IAM-02-Require_multifactor_authentication_for_all_users.json,IAM-02-Rules-of-Behavior Password Requirements with MFA.png,IAM-02-Windows Hello For Business Global.json,IAM-02-Windows Hello For Business Global.png"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-IAM-03",
        "Control ID":"KSI-IAM-03",
        "Control Description":"Enforce appropriately secure authentication methods for non-user accounts and services",
        "Testing Notes":"\nIAM-03-identities-services.tf:\nThe Terraform configuration effectively enforces secure authentication methods for non-user accounts and services by implementing Azure Workload Identity. This is achieved through the creation of User-Assigned Managed Identities (UAMIs) and Federated Identity Credentials (FICs) for each service. The FICs establish a trust relationship between Kubernetes Service Accounts and Azure Managed Identities, enabling passwordless authentication. The configuration ensures each service has its own dedicated identity, adhering to the principle of least privilege. The naming conventions and dependencies within the code also contribute to the overall security and maintainability of the authentication infrastructure.\n\n",
        "Test Instructions":"Inspect authentication configurations for non-user accounts and services (e.g., API keys, service accounts, machine identities) to ensure appropriately secure methods are used (e.g., OAuth, mTLS, short-lived credentials).",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-IAM-03, SSP-1",
        "Linked Evidence":"IAM-03-identities-services.tf"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-IAM-04",
        "Control ID":"KSI-IAM-04",
        "Control Description":"Use a least-privileged, role and attribute-based, and just-in-time security authorization model for all user and non-user accounts and services",
        "Testing Notes":"PIY-06-IntelliGRC FedRAMP RBAC Matrix.xlsx:\nThe evidence demonstrates adherence to the principle of least privilege through Role-Based Access Control (RBAC) at multiple levels. At the infrastructure level, Azure RBAC is implemented using Entra ID groups with assigned permissions aligning to job duties. Access to the IntelliGRC application is also governed by RBAC, with clearly defined roles (Super Admin, Users) and associated permissions. Furthermore, separation of duties is enforced, such as the Marketing Team being separate from the Marketing Lead for content posting. The use of built-in Azure roles provides a standardized and auditable approach to access management. The documentation explicitly defines which teams and individuals are assigned to each role, ensuring accountability and facilitating access reviews.\n\nIAM-04-Privileged Access granting using PIM.png:\nBased on the evidence provided, the control objective is met. The evidence demonstrates the use of Privileged Identity Management (PIM) within Microsoft Azure to enforce least-privilege, role-based access control, and just-in-time authorization.  Specifically:\n\n*   **Least Privilege:** The user Roberto is assigned granular roles such as Log Analytics Contributor and Logic App Contributor instead of broad roles like Owner, limiting permissions to only what is necessary.\n*   **Role-Based Access Control:**  Permissions are assigned based on roles relevant to the user's function, with four of the five roles assigned via group membership, streamlining access management.\n*   **Just-in-Time (JIT) Access:** The user must activate eligible roles to gain access, and some roles have defined end times, ensuring temporary elevation of privileges only when required. This is facilitated through the Eligible assignments feature of Azure PIM.\n*   **Attribute-Based Access Control (ABAC):** While not explicitly detailed, the 'Conditions' column being 'None' suggests the potential for ABAC, where access could be further refined based on attributes. Further investigation may be required to confirm the active use of ABAC.\n*   **Scope Limitation:** Access is primarily scoped to a specific resource group (rg-management), further restricting the user's access to specific resources instead of the entire subscription.\n\n\nIAM-04-log-analytics.tf:\nBased on the Terraform configuration, the following observations support the control objective of using a least-privileged, role and attribute-based, and just-in-time security authorization model:\n\n*   **Role-Based Access Control (RBAC):** The configuration uses Azure's built-in roles (e.g., `Microsoft Sentinel Contributor`, `Log Analytics Reader`) to define permissions. These roles are assigned to security groups, enabling role-based access control.\n*   **Least Privilege:** The configuration assigns specific roles (Contributor, Reader) relevant to the tasks performed by different teams (security, cloud ops), adhering to the principle of least privilege.\n*   **Just-In-Time (JIT) Access:** The use of `azurerm_pim_eligible_role_assignment` and `azurerm_role_management_policy` implements a Privileged Identity Management (PIM) system. Users are not granted permanent access. Instead, they are *eligible* for roles and must activate them when needed, providing a justification. The activation duration is limited (8 hours).\n*   **Attribute-Based Access Control (ABAC):** While not explicitly ABAC, the use of PIM policies allows for attribute-based considerations during role activation. The requirement for justification allows approvers (if enabled) to consider attributes of the request (e.g., business need, time of day) before granting access.\n",
        "Test Instructions":"Examine access control policies, role definitions, and audit logs to confirm a least-privileged, role\/attribute-based, and just-in-time security authorization model for all accounts.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-IAM-04, SSP-1",
        "Linked Evidence":"IAM-04-log-analytics.tf,IAM-04-Privileged Access granting using PIM.json,IAM-04-Privileged Access granting using PIM.png,PIY-06-IntelliGRC FedRAMP RBAC Matrix.xlsx"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-IAM-05",
        "Control ID":"KSI-IAM-05",
        "Control Description":"Apply zero trust design principles",
        "Testing Notes":"IAM-05-AzureFirewall_SubnetZoneVariables.tf:\nEvidence of zero trust design principles includes the implementation of subnetting forJumpbox, Build agents and Bastion services. Evidence also includes the use of a user assigned managed identity for policy enforcement. Also, network architecture supports multiple environments: development, test, and production.\n\nIAM-05-Entra ID Conditional Access - FedRAMP - Require passkeys for access to FedRAMP Boundary.png:\nBased on the evidence, the Conditional Access policy named FedRAMP - Require passkeys for those touching FedRAMP Boundary enforces zero trust principles by requiring phishing-resistant MFA for specific users accessing all resources. This aligns with zero trust by verifying the user's identity with a high degree of certainty before granting access. The policy is actively enforced ('On' state) and ensures that only authenticated and authorized users can access FedRAMP-related resources.\n\nIAM-05-Azure_app-allowedservices.yaml:\nBased on the provided YAML configuration snippet, the application enforces zero trust principles by explicitly defining an allowlist of service accounts permitted to communicate with it. The `allowedServiceAccountNames` key specifies the following service accounts: `intellicore-coreagg-sa`, `intellicore-adminagg-sa`, `intellicore-scannerapi-sa`, `intellicore-actionplanapi-sa`, `intellicore-reports-sa`, `intellicore-publicagg-sa`, and `intellicore-mcp-sa`. This configuration operates within a service mesh, restricting connections to only services within the mesh and explicitly listed in the allowlist. The consistent naming convention (`intellicore-*`) suggests these service accounts belong to a single system, further strengthening the zero trust implementation by limiting the scope of allowed communication.\n\nIAM-05 Entra ID Conditional Access - Require compliant devices to access FedRAMP boundary.png:\nThe Conditional Access policy named Require compliant devices to access FedRAMP boundary enforces zero trust principles by requiring both multi-factor authentication (MFA) and device compliance for specific users accessing all resources within the FedRAMP boundary. The policy ensures that only trusted users on trusted devices can access sensitive resources. By requiring 'all the selected controls', the policy adheres to the zero trust principle of least privilege and explicit verification, enhancing security posture.\n\nIAM-05-AzureJumpboxFirewall.tf:\nThe Terraform configuration implements zero trust principles by limiting network access to the Jumpbox based on the defined subnet and specific ports (80, 443, 8080, 8443). Access to external resources is restricted to a list of approved FQDNs, including Azure management, Ubuntu package repositories, and Microsoft package repositories, minimizing the attack surface. The use of network and application rule collections allows for granular control over both network and application-level traffic, further enforcing zero trust by default-deny and least-privilege access.\n\nIAM-05-AzureFrontDoorWAF.tf:\nThe Terraform code implements zero trust principles by utilizing Azure Front Door with Web Application Firewall (WAF) policies for both production and non-production environments. The WAF policies are configured in 'Prevention' mode, actively blocking malicious requests. Custom rules implement rate limiting based on host headers, restricting the number of requests per minute to protect against denial-of-service attacks. Separate policies exist for production and developmenttest environments, each tailored to their specific risk profiles and traffic patterns. Managed rulesets, specifically the Microsoft_DefaultRuleSet and Microsoft_BotManagerRuleSet, are enabled to log potential threats, providing visibility into malicious activity without disrupting legitimate traffic. The use of a premium Azure Front Door SKU enables advanced WAF capabilities. Finally, the custom block response provides a standardized 'Unauthorized' message, enhancing security awareness.\n\nIAM-05-IntelliGRC_Azure_Well-Architected-Framework.tf:\nThe Terraform code applies zero trust principles by deploying an Azure environment with a hub-and-spoke network topology. The `enterprise_scale` module establishes a governance structure with policies and role assignments, and the `hubnetworking` module deploys a central hub network in a dedicated connectivity subscription. The hub network includes subnets for Azure Firewall (Premium SKU), Key Vault, and other services, with explicitly defined IP address ranges. This segmentation and centralized control of network traffic aligns with zero trust principles by minimizing the attack surface and limiting the blast radius of potential security incidents.\n\nIAM-05-Defender for Cloud Hardened Containers.png:\nThe Microsoft Defender for Cloud dashboard provides a centralized view of security findings for the `aks-intelli-prod` Kubernetes cluster. The dashboard highlights vulnerabilities, misconfigurations, and compliance issues, giving a consolidated view of the cluster's security posture. The presence of vulnerability scanning and reporting mechanisms aligns with zero trust principles by providing visibility into potential weaknesses. The assignment of owners to vulnerabilities, such as `matthew.duval@intelligrc.com`, demonstrates a clear line of responsibility for remediation efforts. The ability to filter vulnerabilities by risk level, namespace, and status allows for focused attention on the most critical issues. The ability to download a CSV report enables further analysis and tracking of vulnerabilities. The integration with Microsoft Copilot can assist with security investigations and remediation guidance.\n\nIAM-05-Azure_log-analytics.tf:\nThe Terraform code implements zero trust principles by enforcing least privilege through Privileged Identity Management (PIM) for access to the Log Analytics workspace. Specifically, it grants eligible access to security groups for Sentinel Contributor, Sentinel Reader, Log Analytics Contributor, and Log Analytics Reader roles, requiring justification for activation and limiting the maximum activation duration to 8 hours.  This ensures that users only have the necessary permissions when needed and for a limited time, aligning with the zero-trust principle of 'never trust, always verify.' Additionally, comprehensive logging is enabled via the data export rule, which continuously archives security and diagnostic logs to a storage account. This supports the zero-trust pillar of continuous monitoring and threat detection by providing a centralized repository of logs for analysis.\n\nIAM-05-AzureBuildAgents_FirewallRules.tf:\nThe Terraform configuration demonstrates the application of zero-trust principles by explicitly defining and limiting network access for the build agent. The firewall policy uses a rule collection group with a defined priority to manage outbound traffic. Each rule within the collection specifies the protocol, destination port, and source (build agent subnet), adhering to the principle of least privilege. The rules explicitly allow HTTPS (443), HTTP (80), and SSH (22) traffic, which are required for build agent functions such as secure web traffic, OS updates, and downloading Terraform modules. The configuration defines the source as the build agent subnet and limits the destination to only necessary IP addresses, further restricting the blast radius. By implementing these restrictions, the configuration minimizes the potential impact of a security breach.\n\nIAM-05-AzureServerConfig.yaml:\nThe Linkerd `Server` resource applies zero trust principles by defining specific access policies for application pods. The `podSelector` ensures that the policy is applied only to the intended pods based on labels, limiting the scope of access. The `proxyProtocol` setting ensures that only expected traffic types are allowed, preventing protocol-based attacks. The `accessPolicy` setting explicitly defines which traffic is permitted (e.g., authenticated, unauthenticated, deny), enforcing a strict access control regime. Furthermore, the conditional block ensures that Linkerd is explicitly enabled, preventing unintended exposure. These configurations, managed through Helm, allow for a configurable and repeatable application of zero trust principles.\n\nIAM-05-AzureContainerRegistryNetwork-acr-nw.tf:\nTesting Notes:\n\n*   The `azurerm_subnet` resource configures `private_endpoint_network_policies` to `Enabled`, ensuring that the Network Security Group (NSG) rules are enforced on private endpoints within the subnet, supporting zero trust principles.\n*   The `azurerm_network_security_group` resource defines explicit allow rules for inbound traffic from specific subnets (Production AKS, Development AKS, Test AKS, JumpBox, Build Agent) on port 443, followed by a deny-all rule. This demonstrates a zero-trust approach by only permitting explicitly authorized traffic.\n*   The `azurerm_network_security_group` resource defines explicit allow rules for outbound traffic to AzureContainerRegistry and AzureActiveDirectory service tags on specific ports, followed by a deny-all rule. This demonstrates a zero-trust approach by only permitting explicitly authorized traffic.\n*   The `azurerm_subnet_route_table_association` resource associates a route table with the subnet, enforcing that all traffic from the subnet is routed through a central firewall. This supports zero trust by ensuring all traffic is inspected.\n\n\nIAM-05-AzureSecurityCenterFedRAMPModerateBaselineScan.pdf:\nThe Microsoft Defender for Cloud compliance report provides evidence of a strong implementation of zero-trust principles across the assessed environment. The report indicates that 287 out of 288 FedRAMP M controls are passing, demonstrating a comprehensive approach to security. The detailed breakdown of control families shows consistent compliance across various areas such as Access Control, Identification and Authentication, and System and Communications Protection. The high volume of passed assessments for controls like AC.4.* (Information Flow Enforcement) and SC.7.* (Boundary Protection) suggests robust enforcement of security policies and principles aligned with zero trust. While one control (SC.12.*) has failing assessments, the overall high compliance rate provides assurance that zero-trust design principles are widely adopted and effectively implemented within the environment.\n\nIAM-05-AzureKubernetesMeshAuthentication_LinkerDEnterprise.yaml:\nThe Kubernetes manifest template applies zero trust principles by enforcing mutual TLS (mTLS) for connections within the Linkerd service mesh. The `MeshTLSAuthentication` resource restricts inbound connections to workloads to only those originating from explicitly allowed `ServiceAccounts`, effectively implementing a 'deny-by-default' approach. The list of allowed `ServiceAccounts` is dynamically configured through the Helm chart's `values.yaml` file, which allows for centralized management and updates to the allowed identities. By using `identityRefs` with `kind: ServiceAccount`, the policy explicitly defines trusted sources, limiting the blast radius of potential compromises. The ability to specify `ServiceAccounts` from different namespaces further enhances zero trust by enabling fine-grained control over cross-namespace communication. The entire policy is conditionally applied based on the `linkerd.enabled` value, allowing for easy disabling of the zero trust configuration if needed.\n\nIAM-05-AzureKubenetesService_FirewallRules.tf:\nThe Terraform configuration implements zero trust principles by limiting network access based on source and destination. The Azure Firewall Policy Rule Collection Group `aks_fw_rules` restricts traffic from defined virtual networks (prod, test, dev) to specific destinations and ports. The `aks_service` application rule only allows HTTPS traffic to the `AzureKubernetesService` FQDN tag, ensuring that AKS cluster communication is limited to necessary services. The network rules further refine this by allowing HTTPS, SMTPS, and DNS traffic from the same VNETs, but the comments indicate these are for specific purposes (email notifications and certificate renewal), demonstrating a least-privilege approach by restricting the scope of allowed traffic. The use of priority numbers ensures that the network rule collection is evaluated before the application rule collection, providing an order of operations for traffic filtering.\n\nIAM-05-Azure_authorizationpolicy.yaml:\nThe provided evidence demonstrates the application of zero trust principles through the implementation of a Linkerd AuthorizationPolicy.  Specifically, the policy enforces mutual TLS (mTLS) authentication for traffic to a designated server within the service mesh. This ensures that only authenticated and authorized workloads within the mesh can communicate with the targeted resource. The use of mTLS aligns with zero trust by verifying the identity of both the client and server before granting access. The policy is conditionally applied based on the `linkerd.enabled` value, allowing for controlled activation of the zero trust enforcement. The `targetRef` and `requiredAuthenticationRefs` specifications precisely define the resource being protected and the authentication method required, ensuring granular control over access. This prevents unauthorized access and enforces the principle of least privilege.\n\nIAM-05-AzureBastion_Jumpbox_FirewallRules.tf:\nThe Terraform configuration implements zero trust principles by explicitly defining and limiting network and application access from the jumpbox subnet. The network rules collection allows outbound HTTPS (port 443) and HTTP (port 80) traffic to any destination, but only from the defined jumpbox subnet, restricting lateral movement. It also restricts proxy traffic to the firewall's private IP on ports 8080 and 8443 from a specific IP range. The application rule collection whitelists specific FQDNs required for Azure portal management, Ubuntu package repositories, and Microsoft package repositories, further limiting the attack surface by preventing connections to arbitrary destinations. The use of a firewall policy and rule collections allows for centralized management and enforcement of these zero trust rules.\n\nIAM-05-AzureFirewall_PremiumFWPolicy_IDS.tf:\nBased on the evidence provided, the Terraform code configures an Azure Firewall Policy with premium features, aligning with zero trust principles by implementing advanced security measures. The policy includes Intrusion Detection and Prevention System (IDPS) set to 'Alert' mode, which enables detection and logging of suspicious network activity. Threat intelligence is also enabled in 'Alert' mode, generating alerts for traffic matching known malicious IPs, FQDNs, or URLs. The explicit proxy feature is enabled, allowing the firewall to act as a secure web proxy. A user-assigned managed identity is configured, enabling the firewall policy to access other Azure resources securely. The premium SKU enables TLS inspection and URL filtering, further enhancing security. These configurations demonstrate the application of zero trust design principles by implementing strict access controls, continuous monitoring, and advanced threat protection measures.\n\nIAM-05-AzureJumpboxNetwork.tf:\nThe Terraform code implements several aspects of zero trust principles: 1.  Network Segmentation: The creation of a dedicated jumpbox subnet isolates administrative access from other parts of the network. 2.  Least Privilege: The NSG rules strictly control inbound and outbound traffic, allowing only necessary ports and protocols. Inbound access is limited to SSH and Squid from the Bastion subnet. Outbound access is limited to HTTPS, HTTP (for updates), and Microsoft Entra ID. 3.  Traffic Inspection:  Routing all egress traffic through a firewall enables inspection of traffic.  4.  Microsegmentation: NSG applied to Jumpbox subnet. However, the 'Deny-All-Outbound' rule, which is actually configured to ALLOW all traffic, contradicts the zero trust principle of default deny. This needs to be corrected to DENY all outbound traffic by default and only allow explicitly authorized traffic. The use of Azure Bastion as the entry point enforces authentication and authorization before access to the jumpbox subnet is granted. The code explicitly defines allowed traffic to Entra ID, enforcing least privilege access to authorized services. \n\nIAM-05-IntelliGRCMsGraphUserExportM365Only_20250703_1650.csv:\nBased on the provided user account data, the following observations support the application of zero trust principles:  1.  Granular Access Control: The detailed group memberships (e.g., `Postgres Read-Only (Prod)`, `Azure Storage Account Contributors (DevTestProd)`) indicate a degree of least privilege implementation, aligning users to specific resources based on their roles.  2.  Identity Verification: The presence of timestamps such as `LastSignInTime` and `LastPasswordChangeDateTime` suggests mechanisms for tracking user activity and enforcing password policies, contributing to continuous authentication and authorization.  3.  Segmentation: The separation of duties is apparent with dedicated admin accounts (e.g., `Caleb.Harrison.SA@intelligrc.com`) and role-based access control within Entra ID, limiting the blast radius of potential breaches.  4.  Monitoring and Logging: The existence of shared mailboxes for security alerts (`security-alerts-prod@intelligrc.com`) implies a focus on proactive threat detection and incident response.  \n\nIAM-05-AzureKubernetesServiceFirewall_aks-fw.tf:\nThe Terraform configuration demonstrates the application of zero trust principles by implementing a firewall policy with specific rules governing network traffic. The configuration uses an Azure Firewall Policy to control outbound traffic from different virtual networks (production, test, and development) to the internet. It adheres to zero trust by explicitly allowing only necessary traffic based on source, destination, port, and protocol, rather than implicitly trusting all internal traffic. The application rule collection allows HTTPS traffic to Azure Kubernetes Service based on the 'AzureKubernetesService' FQDN tag, ensuring that only traffic destined for AKS services is permitted. The network rule collection allows HTTPS, SMTPS, and DNS traffic from the specified virtual networks to any destination, but only on specific ports (443, 465, and 53, respectively). This granular control limits the blast radius of potential security incidents and enforces the principle of least privilege by only allowing the traffic necessary for specific applications and services to function. The use of different rules for different types of traffic (application vs. network) further refines the control and reduces the attack surface. \n\nIAM-05-AzureFirewall.tf:\nBased on the Terraform code, the Azure Firewall is implemented following zero trust principles through several key configurations: \n\n*   **Network Segmentation:** The firewall is deployed in a dedicated `AzureFirewallSubnet`, isolating it from other network resources.  This enforces network segmentation, a core tenet of zero trust, by controlling traffic flow between segments.\n*   **Egress Traffic Inspection:**  A route table (`fw-route_table`) is configured to route all outbound traffic through the Azure Firewall. This ensures that all egress traffic is inspected, adhering to the zero trust principle of inspecting all traffic, even within the network.\n*   **Centralized Firewall Policy:** The firewall utilizes a Firewall Policy (`module.firewall_rules`) for rule management. This allows for a centralized and consistent approach to security policy enforcement, aligning with the zero trust concept of least privilege access.\n*   **Detailed Logging:**  Diagnostic logging is enabled (`azurerm_monitor_diagnostic_setting.firewall_diagnostics`) to capture `AZFWThreatIntel`, `AZFWApplicationRule`, and `AZFWDnsQuery` logs. This provides visibility into network traffic and potential threats, supporting the zero trust principle of continuous monitoring and threat detection.\n*   **Static Public IP:** By assigning a static public IP (`azurerm_public_ip.firewall`) ensures a consistent and reliable entry point for external traffic, making it easier to manage and monitor inbound connections which aligns with zero trust principles.\n*   **Firewall Rules Module:** The use of firewall rules module ensures granular control over network traffic. The parameters passed to the module, such as address spaces and the firewall's private IP, enable the configuration of specific rules based on the environment's requirements.\n\n\n\nIAM-05-intelligrc_Azure_landing_zones_BoundryDiagram.png:\nThe architecture implements zero trust principles through several key mechanisms:\n\n*   **Segmentation:** The hub-and-spoke network model isolates workloads into separate subscriptions (Management, Connectivity, Development, Production), limiting the blast radius of potential incidents.\n*   **Least Privilege Access:** Microsoft Entra ID, PIM, and standard IAM practices enforce role-based access control with just-in-time privileges, approval workflows, MFA, and regular access reviews.\n*   **Continuous Verification:** Azure Firewall inspects all outbound traffic. Microsoft Defender for Cloud provides continuous threat protection and security posture management. Log Analytics and Microsoft Sentinel provide security monitoring, alerting, and incident management.\n*   **Microsegmentation:** Private Endpoints are utilized extensively to secure PaaS services (databases, storage, messaging) within the production environment, restricting access to only authorized resources.\n*   **Secure DevOps:** Azure DevOps with Git repositories, automated pipelines, and dedicated build agents ensure secure code management, deployment, and infrastructure-as-code practices.\n*   **Network Access Control:** Azure Bastion is used for secure administrative access to jump boxes, limiting direct exposure of VMs to the internet. Network Security Groups (NSGs) can further restrict traffic flow within subnets.\n*   **Application Security:** Azure Front Door with WAF protects the application from common web exploits.\n\n\nIAM-05-InteractiveSignIns_2025-08-05_2025-08-06.csv:\nBased on the provided Microsoft Entra ID sign-in logs, the following observations support the application of zero trust principles:\n\n*   **Principle of Least Privilege:** The logs differentiate between standard users and users with administrative accounts (e.g., Caleb Harrison, Roberto Quinones), indicating an effort to limit administrative privileges to only those who require them. The presence of service accounts (e.g., Automation) further supports this principle by using non-personal accounts for automated tasks.\n*   **Verify Explicitly:** The logs show that multi-factor authentication (MFA) is being enforced, as evidenced by the numerous entries showing MFA requirement satisfied by claim in the token. This indicates that users are being explicitly verified before being granted access to resources.\n*   **Assume Breach:** The presence of failed sign-in attempts due to invalid credentials or cross-tenant access policy failures suggests that the system is actively detecting and preventing unauthorized access. The logging of these events demonstrates a proactive approach to identifying and responding to potential security incidents.\n*   **Continuous Monitoring:** The detailed logging of sign-in activities, including user identities, locations, applications accessed, and device information, provides a basis for continuous monitoring and analysis of user behavior. This allows for the detection of anomalies and potential security threats.\n*   **Conditional Access:** The interrupted sign-in events due to Strong Authentication is required demonstrate the use of Conditional Access policies to enforce MFA based on specific conditions. The cross-tenant access policy failures further illustrate the use of policies to restrict access based on organizational boundaries.\n\nThese testing notes demonstrate how the evidence supports the implementation of zero trust design principles through access controls, authentication mechanisms, and continuous monitoring.\n\nIAM-05-AzureManagedIdentities.tf:\nBased on the provided Terraform configuration file, the following observations support the application of zero trust principles:\n\n*   **Least Privilege:** The configuration defines multiple user-assigned managed identities, each specifically designated for a particular service (Storage Accounts, Container Registries, Firewall Policy). This separation of identities adheres to the principle of least privilege, granting each service only the necessary permissions to perform its intended function, rather than a single, overly permissive identity.\n*   **Segmentation (Implicit):** By creating separate managed identities for different services and associating them with a specific resource group (`connectivity-mi-infra-rg`), the configuration implicitly segments access and control. Each identity operates within its defined scope, limiting the potential blast radius of a compromised identity.\n*   **Identity-Based Access Control:** The use of managed identities enables identity-based access control, where access to Azure resources is granted based on the identity of the service or application, rather than relying solely on network-based controls.  These identities can be used in Azure's RBAC system to grant fine-grained permissions.\n*   **Explicit Provider Configuration:** The explicit declaration of `provider = azurerm.connectivity` for each resource suggests a deliberate segmentation of Azure subscriptions or management scopes. This aligns with zero trust by isolating connectivity-related resources and applying specific policies to them.\n*   **Resource Grouping:** Grouping all identities within the `connectivity-mi-infra-rg` resource group aids in the organization and management of these identities, allowing for consistent application of policies and monitoring within that boundary. While not directly a zero-trust principle, it facilitates the implementation of other principles.\n\n\nIAM-05-AzureFrontDoor.tf:\nBased on the provided Terraform configuration, the implementation aligns with zero trust principles through several key aspects:\n\n*   **Segmentation:** The configuration distinctly separates production and developmenttesting environments with dedicated WAF policies (`intelliprodwafpolicy` and `intellidevwafpolicy`). This segmentation limits the blast radius of potential security incidents.\n*   **Least Privilege:** The rate limiting rules are configured with varying thresholds based on the specific domains and their expected traffic patterns. This helps to prevent abuse and ensures that resources are only accessible to authorized users and services. For example, production domains have higher rate limits (2002000 requests per minute) compared to developmenttesting domains (1001000 requests per minute).\n*   **Continuous Monitoring:** While the managed rulesets (`Microsoft_DefaultRuleSet` and `Microsoft_BotManagerRuleSet`) are configured in Log mode, this allows for continuous monitoring of potential threats and vulnerabilities without immediately blocking traffic. This enables security teams to analyze traffic patterns and identify potential security incidents.\n*   **Explicit Verification:** The use of Web Application Firewall (WAF) policies with custom rate limiting rules and managed rulesets demonstrates a mechanism for explicitly verifying each request before granting access to resources. The WAF policies analyze incoming traffic and apply predefined rules to identify and mitigate potential threats.\n*   **Microsegmentation:** Rate limiting rules are applied to specific subdomains (e.g., `login.intelligrc.app`, `admin.intelligrc.app`) which ensures different parts of the application are subject to different levels of scrutiny based on their risk profile.\nThese configurations demonstrate an application of zero trust principles by implementing granular access controls, continuous monitoring, and explicit verification mechanisms within the Azure Front Door setup.\n\nIAM-05-EntraAuditLogs_2025-08-06.csv:\nBased on the provided Azure AD activity logs, here are testing notes focusing on how the evidence supports the application of zero trust principles:\n\n*   **User Authentication:** The logs show successful user authentications with details like source IP addresses and user agents. The validation of user authentication via tokens aligns with zero trust by continuously verifying user identity.\n*   **Device Management:** The registration and Intune management of devices (e.g., `DESKTOP-HQ8FLIN`, `TIBERLP1174`) demonstrate device identity and health are being assessed. The setting of `IsManaged` and `IsCompliant` properties to `true` indicates adherence to organizational policies, a key aspect of zero trust.\n*   **Multi-Factor Authentication (MFA) Updates:** Logs of users updating their MFA details confirm that strong authentication methods are being enforced. This aligns with zero trust by adding a layer of security beyond just usernamepassword.\n*   **Policy Management (Conditional Access):** The updates to Conditional Access policies, such as the Require compliant devices to access FedRAMP boundary policy, directly support zero trust. This policy enforces MFA and device compliance before granting access to resources within the FedRAMP boundary. The configuration of conditions and controls demonstrates granular access control based on device and user context.\n*   **Privileged Identity Management (PIM):** The activation and expiration of privileged roles via PIM, along with justifications, reflect the principle of least privilege. Users are granted elevated access only when needed and for a limited time, reducing the attack surface.\n*   **Group Management:** Adding devices to management groups (e.g., `Intune_Autopilot_Windows_Devices`) enables targeted policy enforcement and management. This aligns with zero trust by segmenting access based on group membership and device posture.\n\nOverall, the activity logs provide evidence of several zero trust principles being implemented within the IntelliGRC environment, including strong authentication, device compliance, least privilege, and granular access control.",
        "Test Instructions":"Review system architecture and access control policies to confirm the application of zero trust design principles (e.g., verify every access request, least privilege, micro-segmentation).",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-IAM-05, SSP-1",
        "Linked Evidence":"IAM-05-Azure_app-allowedservices.yaml,IAM-05-Azure_authorizationpolicy.yaml,IAM-05-AzureBastion_Jumpbox_FirewallRules.tf,IAM-05-AzureBuildAgents_FirewallRules.tf,IAM-05-AzureContainerRegistryNetwork-acr-nw.tf,IAM-05-AzureFirewall_PremiumFWPolicy_IDS.tf,IAM-05-AzureFirewall_SubnetZoneVariables.tf,IAM-05-AzureFirewall.tf,IAM-05-AzureFrontDoor.tf,IAM-05-AzureFrontDoorWAF.tf,IAM-05-AzureJumpboxFirewall.tf,IAM-05-AzureJumpboxNetwork.tf,IAM-05-AzureKubenetesService_FirewallRules.tf,IAM-05-AzureKubernetesMeshAuthentication_LinkerDEnterprise.yaml,IAM-05-AzureKubernetesServiceFirewall_aks-fw.tf,IAM-05-Azure_log-analytics.tf,IAM-05-AzureManagedIdentities.tf,IAM-05-AzureSecurityCenterFedRAMPModerateBaselineScan.pdf,IAM-05-AzureServerConfig.yaml,IAM-05-Defender for Cloud - Container Kubernetes Weekly Security Report.pdf,IAM-05-Defender for Cloud Hardened Containers.png,IAM-05-EmailNotificationPIMEvent.pdf,IAM-05-EntraAuditLogs_2025-08-06.csv,IAM-05-Entra ID Conditional Access - FedRAMP - Require passkeys for access to FedRAMP Boundary.json,IAM-05-Entra ID Conditional Access - FedRAMP - Require passkeys for access to FedRAMP Boundary.png,IAM-05 Entra ID Conditional Access - Require compliant devices to access FedRAMP boundary.json,IAM-05 Entra ID Conditional Access - Require compliant devices to access FedRAMP boundary.png,IAM-05-intelligrc_Azure_landing_zones_BoundryDiagram.png,IAM-05-IntelliGRC_Azure_Well-Architected-Framework.tf,IAM-05-IntelliGRCMsGraphUserExportM365Only_20250703_1650.csv,IAM-05-InteractiveSignIns_2025-08-05_2025-08-06.csv,IAM-05-SCAP_Scan_ContainerHardening.xml"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-IAM-06",
        "Control ID":"KSI-IAM-06",
        "Control Description":"Automatically disable or otherwise secure accounts with privileged access in response to suspicious activity",
        "Testing Notes":"\nIAM-06 Entra ID Conditional Access - Risky Sign-in Sign out of compromised sessions.png:\nThe Risky Sign-in: Sign out of compromised sessions Conditional Access policy automatically disables access to privileged accounts by forcing a re-authentication every time a user access a resource under risky conditions, effectively invalidating any existing session tokens when a High or Medium level of sign-in risk is detected. This policy applies to all users and all cloud applications, ensuring comprehensive coverage.\n\nIAM-06 Entra ID Conditional Access - Risky Sign-In - Require Password Change.png:\nTesting Notes:\n\nThe Risky Sign-In: Require Password Change Conditional Access policy automatically forces users to change their passwords when a high or medium risk is detected, effectively disabling access until the password is changed. The policy applies to all users and cloud applications. The User risk condition is configured to trigger on High and Medium risk levels, and the Grant control is set to Require password change. The sign-in frequency is set to Every time which ensures continuous enforcement.\n\n",
        "Test Instructions":"Request demonstration or documentation of automated mechanisms that disable or secure privileged accounts in response to suspicious activity.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-IAM-06, SSP-1",
        "Linked Evidence":"IAM-06 Entra ID Conditional Access - Risky Sign-In - Require Password Change.json,IAM-06 Entra ID Conditional Access - Risky Sign-In - Require Password Change.png,IAM-06 Entra ID Conditional Access - Risky Sign-in Sign out of compromised sessions.json,IAM-06 Entra ID Conditional Access - Risky Sign-in Sign out of compromised sessions.png"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-INR-01",
        "Control ID":"KSI-INR-01",
        "Control Description":"Report incidents according to FedRAMP requirements and cloud service provider policies",
        "Testing Notes":"RPL-04-Tabletop_Exercise_Malicious_CustomerData_Deletion.pdf:\nThe tabletop exercise demonstrates testing of incident reporting procedures. The exercise scenario involved a data deletion incident requiring notification. The action items include clarifying and documenting legalFedRAMP notification requirements, indicating a commitment to meeting reporting obligations. However, the exercise revealed deficiencies in the existing incident response plan, specifically regarding clarity and actionable steps. The lack of a defined incident coordinator and unclear responsibilities for contacting external authorities suggest that incident reporting may not consistently meet FedRAMP requirements and cloud service provider policies. Further testing is needed to validate that incidents are reported according to the required timelines and procedures.\n\nINR-01-SSP-Appendix-G_InteliGRC-Information-System-Contingency-Plan-(ISCP).pdf:\nThe provided ISCP outlines incident reporting procedures that align with FedRAMP requirements and cloud service provider policies. The plan details notification procedures, including timelines (1 hour for major outages, 24 hours for data integrity issues) and methods (email, phone, Microsoft Teams). It specifies recipients, including internal teams, leadership, and affected customers. The ISCP also includes contact lists (Appendix A & B) for key personnel and external vendors, ensuring proper communication during incident reporting. The level of detail included in the ISCP demonstrates a commitment to meeting the control requirements.\n\nINR-01-Incident Reporting.png:\nThe evidence provided outlines a mandatory four-step incident response and reporting procedure, aligning with FedRAMP requirements. Step 1 requires notification to FedRAMP within one hour of incident detection. Step 2 mandates a preliminary report within four hours, including incident category, impact assessment, and initial mitigation steps. Step 3 requires a full incident report within 72 hours, containing root cause analysis and corrective actions. Step 4 involves coordination with US-CERT or CISA as required, including submitting IR reports through designated channels. This evidence demonstrates adherence to the control by establishing clear timelines and procedures for incident reporting, encompassing notification, preliminary reporting, full incident reporting, and external agency coordination.\n\nINR-01-IR Plan.pdf:\nEvidence File Summary: The Incident Response Plan (IRP) outlines the procedures and responsibilities for managing security incidents in compliance with FedRAMP requirements and cloud service provider policies.\n\nTesting Notes:\n*   The IRP explicitly addresses FedRAMP compliance, stating alignment with FedRAMP Incident Communications Procedures.\n*   The plan details external reporting requirements and timelines for FedRAMP, requiring notification to the PMOAO within 1 hour.\n*   The document includes procedures for forensic evidence retention for a minimum of 90 days post-incident, as required by FedRAMP and DFARS.",
        "Test Instructions":"Review incident reporting procedures and recent incident reports to confirm adherence to FedRAMP requirements and cloud service provider policies.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"PARTIAL",
        "Finding":"RPL-04-Tabletop_Exercise_Malicious_CustomerData_Deletion.pdf:\nThe tabletop exercise demonstrates testing of incident reporting procedures. The exercise scenario involved a data deletion incident requiring notification. The action items include clarifying and documenting legal FedRAMP notification requirements, indicating a commitment to meeting reporting obligations. However, the exercise revealed deficiencies in the existing incident response plan, specifically regarding clarity and actionable steps. The lack of a defined incident coordinator and unclear responsibilities for contacting external authorities suggest that incident reporting may not consistently meet FedRAMP requirements and cloud service provider policies. ",
        "Finding Status":"Unresolved",
        "Linked Requests":"KSI-INR-01, SSP-1",
        "Linked Evidence":"INR-01-Incident Reporting.png,INR-01-IR Plan.pdf,INR-01-SSP-Appendix-G_InteliGRC-Information-System-Contingency-Plan-(ISCP).pdf,RPL-04-Tabletop_Exercise_Malicious_CustomerData_Deletion.pdf"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-INR-02",
        "Control ID":"KSI-INR-02",
        "Control Description":"Maintain a log of incidents and periodically review past incidents for patterns or vulnerabilities",
        "Testing Notes":"\nINR-02-Incident Reporting.PNG:\nTesting notes:\n\nEvidence confirms the existence of a maintained incident log within the support ticketing system, jointly managed by the CISO and the IntelliGRC Operations Team. The monthly security report includes details of all tracked incidents and incorporates a trends analysis. Security weaknesses discovered from incidents are added to the IntelliGRC POA&M. This demonstrates that the organization maintains a log of incidents and periodically reviews past incidents for patterns or vulnerabilities.\n\nINR-02-Security Operations Efficiency - log-management - Microsoft Azure.pdf:\nThe provided Security Operations Efficiency report from Microsoft Azure demonstrates a log of security incidents is maintained. The report, generated on August 5th, 2025, summarizes 4 incidents created within the last 7 days in the `log-management` workspace. The 'Incident Timeline' section shows incident creation activity on August 2nd. The report also contains a 'Recent Activities Log' which details specific actions taken on incidents, including the time and incident number. This log and the incident summaries indicate that incidents are being tracked and reviewed.\n\nINR-02-Sentinel Analytic Rules.png:\nThe Microsoft Sentinel Analytics interface shows a list of 37 active analytic rules.  The rules are categorized by severity (High, Medium, Low) and include details such as name, rule type (Scheduled or Near-Real-Time), status (Enabled), MITRE ATT&CK tactics and techniques, source name, and last modified date. The presence of these active rules, along with their associated details, demonstrates an ongoing effort to monitor for and log potential security incidents. The ability to review these rules and their historical performance supports the periodic review of past incidents for patterns or vulnerabilities, as the rules themselves are designed to detect such patterns. The 'Last modified' field indicates that the rules are actively maintained and updated.\n\n",
        "Test Instructions":"Request access to the incident log and review it for completeness, periodic review, and identification of patterns or vulnerabilities.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-INR-02, SSP-1",
        "Linked Evidence":"INR-02-Incident Reporting.PNG,INR-02-Security Operations Efficiency - log-management - Microsoft Azure.pdf,INR-02-Sentinel Analytic Rules.json,INR-02-Sentinel Analytic Rules.png"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-INR-03",
        "Control ID":"KSI-INR-03",
        "Control Description":"Generate after action reports and regularly incorporate lessons learned into operations",
        "Testing Notes":"\nINR-03-After Action Report 2.png:\nEvidence confirms the generation of after-action reports, detailing incident impact, root cause analysis, response actions, lessons learned, and recommendations. The 'Lessons Learned' section explicitly reflects on the organization's security posture, and the 'Recommendations' section provides actionable steps for preventing future incidents. This demonstrates a process for incorporating lessons learned into operations.\n\nINR-03-After Action Report 3.png:\nEvidence of after-action reports is demonstrated by the Sentinel incident report. Incorporation of lessons learned is shown via audit log extracts, email notifications to AOFedRAMP PMO, and screenshotsoutputs from response tools.\n\nINR-03-After Action Report 1.png:\nThe After-Action Report (AAR) template includes sections for documenting key details of security incidents, such as the incident date, affected systems, impact level, and downtime. The template includes a timeline of events, from detection to recovery, to capture the incident lifecycle. The template explicitly includes a section for documenting lessons learned and recommendations for future improvement, demonstrating a commitment to incorporating feedback into operations.\n\nRPL-04-Tabletop_Exercise_Malicious_CustomerData_Deletion.pdf:\nBased on the evidence provided from the tabletop exercise, specifically the 'Recommendations & Proposed Solutions' section, the exercise identified the need to incorporate lessons learned into operations through a plan overhaul. This includes simplifying the Incident Response Plan (IRP) and Information System Contingency Plan (ISCP) to be more actionable and easier to follow. The action items assigned to James and Ozzie, which involve consolidating lessons learned and generating improvement instructions, further demonstrate steps taken to incorporate lessons learned. The team-wide action item to review and update the IRPISCP also contributes to meeting the control requirement.\n\n",
        "Test Instructions":"Review recent after-action reports and evidence of lessons learned being incorporated into operations.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-INR-03, SSP-1",
        "Linked Evidence":"INR-03-After Action Report 1.png,INR-03-After Action Report 2.png,INR-03-After Action Report 3.png,RPL-04-Tabletop_Exercise_Malicious_CustomerData_Deletion.pdf"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-MLA-01",
        "Control ID":"KSI-MLA-01",
        "Control Description":"Operate a Security Information and Event Management (SIEM) or similar system(s) for centralized, tamper-resistent logging of events, activities, and changes",
        "Testing Notes":"\nMLA-01-AzureLogAnalytics.tf:\nThe Terraform code configures centralized logging of events, activities, and changes to meet the control requirements, by exporting a comprehensive set of logs, including Azure Active Directory, security, device, and general service logs, from a Log Analytics Workspace to a tamper-resistant Azure Storage Account. The use of PIM ensures activities and changes are logged and auditable, and that elevated permissions are used only when justified.\n\nMLA-01-AzureSentinel.tf:\nBased on the evidence provided, the Terraform code configures Microsoft Sentinel to collect logs from an Azure Log Analytics Workspace. Specifically, the Terraform code first retrieves the resource ID of the Log Analytics Workspace named management created by the module enterprise_scale, and then uses the resource ID to onboard the Log Analytics Workspace to Microsoft Sentinel. This ensures centralized logging of events, activities, and changes within the specified workspace, and contributes to meeting the control objective.\n\nMLA-01-Audit Logs deletion prevention.png:\nTesting Notes:\n\nThe provided evidence demonstrates that the organization utilizes Azure Log Analytics as a Security Information and Event Management (SIEM) system. The screenshot confirms the existence of a centralized logging solution ('log-management' workspace) within Azure. The presence of tables such as `AADNonInteractiveUserSignInLogs` and `AADUserRiskEvents` indicates that the SIEM captures relevant security events and activities. The retention policy is set to 90 days. Critically, the evidence shows that a member of the security team (Roberto Quinones) does not have the ability to delete log data, which supports the tamper-resistance aspect of the control. The disabled Delete button, combined with the annotation, provides visual confirmation that security personnel are restricted from deleting audit logs, thus ensuring the integrity and availability of the logs for auditing and investigation purposes.\n\n\n\nMLA-01-Sentinel - Multiple tables in use.png:\nThe Microsoft Sentinel logs interface provides centralized logging of events, activities, and changes within the Azure environment.\n\nThe evidence demonstrates this through:\n\n*   **Centralized Logging:** The 'log-management' workspace in Microsoft Sentinel acts as a central repository for log data from various Azure services.\n*   **Event Logging:** Tables like `AuditLogs`, `AzureActivity`, `SigninLogs`, and `MicrosoftGraphActivityLogs` capture a wide range of events, including user sign-ins, resource management activities, and application usage.\n*   **Activity Logging:** The `OperationName` column in the query results displays specific activities performed, such as addingremoving members from roles, updating devicesusers, and querying group data.\n*   **Change Logging:** Logs track changes to resources, as indicated by activities like 'Update device', 'Update service principal', and 'Update user'.\n*   **Tamper-Resistance:** While not explicitly visible in the image, Microsoft Sentinel is designed with tamper-resistance features. Audit logs within Azure, which Sentinel collects, are generally immutable. Further testing would be required to validate the tamper-resistance of the specific Sentinel configuration.\n\nThe presence of detailed logs within Microsoft Sentinel confirms that the organization is operating a SIEM-like system for centralized logging of events, activities, and changes. \n\nMLA-01-Sentinel Data Connectors.png:\nTesting Notes:\n\nBased on the provided evidence, the Microsoft Sentinel service, specifically the 'log-management' workspace, is configured to act as a Security Information and Event Management (SIEM) system.\n\n*   **Centralized Logging:** The Azure Sentinel Data Connectors page demonstrates the ability to connect to various data sources, including Azure Activity, Azure Firewall, Azure Key Vault, and others. The large number of connectors (17 total, with 11 connected) indicates a centralized logging approach, consolidating security-related events and activities from multiple systems into a single platform.\n*   **Tamper-Resistant Logging:** While the screenshot doesn't explicitly confirm tamper-resistance, Azure Sentinel, as a cloud-based SIEM, inherently provides tamper-resistant logging capabilities. The underlying Azure platform offers security features that protect log data integrity. Further testing can confirm specific configurations related to immutability and access controls for logs.\n*   **Event, Activity, and Change Logging:** The connected data connectors (e.g., Azure Activity, Microsoft Entra ID) capture a wide range of events, user activities, and configuration changes within the Azure environment. This confirms the system's capability to log various types of security-relevant information.\n\n\n\n",
        "Test Instructions":"Verify the operation of a SIEM or similar centralized logging system, reviewing its configuration for tamper-resistance and comprehensive event collection.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-MLA-01, SSP-1",
        "Linked Evidence":"MLA-01-Audit Logs deletion prevention.png,MLA-01-AzureLogAnalytics.tf,MLA-01-AzureSentinel.tf,MLA-01-Sentinel Data Connectors.png,MLA-01-sentinel_data_connectors_report.json,MLA-01-Sentinel - Multiple tables in use.json,MLA-01-Sentinel - Multiple tables in use.png"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-MLA-02",
        "Control ID":"KSI-MLA-02",
        "Control Description":"Regularly review and audit logs",
        "Testing Notes":"\nMLA-02-Service Ticket 45_ SIEM and Sentinel Log review week 32_2025.pdf:\nService Ticket #451 provides evidence of regular log reviews and audits. The ticket details a weekly review of Sentinel logs, covering Azure Activity Logs, Security Events (WindowsLinux), Microsoft 365 Defender Alerts, Firewall Logs, Network Logs, and Device Logs. The review, conducted by Roberto Quinones on 08072025, confirms the absence of new incidents, anomalies, or suspicious activities, and verifies the operational status of data sources and Sentinel workbooks. The ticket also documents the time spent on the review (30 minutes). This demonstrates adherence to the control requirement for regularly reviewing and auditing logs.\n\nMLA-02-Sentinel Workbook Screenshot.png:\nBased on the provided IntelliGRC External Boundary WAF Monitoring dashboard summary, the evidence supports the 'Regularly review and audit logs' control as follows:\n\n*   **Dashboard Provides Overview:** The dashboard itself, configured within Microsoft Sentinel, provides a centralized view of WAF activity, demonstrating regular log review.\n*   **Attack Type Analysis:** The 'Top 10 Detected Attack Types' section shows a clear analysis of attack patterns (primarily SQLi), confirming that logs are reviewed to identify security threats.\n*   **Source IP Blocking:** The 'Top 10 Blocked Source IP Addresses' table indicates that logs are analyzed to identify and block malicious sources, with a specific IP address (`204.111.212.211`) being blocked 520 times.\n*   **Targeted URI Identification:** The 'Most Targeted URIs Resulting in Blocks' table shows that logs are reviewed to determine which application endpoints are under attack.\n*   **WAF Action Tracking:** The 'WAF Action Distribution' pie chart provides insights into the actions taken by the WAF, with a breakdown of 'AnomalyScoring' and 'Log' actions.\n*   **Rule Trigger Analysis:** The 'Top Triggered WAF Rules' and 'Top Triggering Rules Cause' pie charts demonstrate that logs are analyzed to understand which WAF rules are being triggered and why.\n*   **Time Range:** The dashboard covers a 7-day period, suggesting regular, ongoing review of log data.\n\nIn summary, the dashboard provides a comprehensive overview of WAF activity, demonstrating regular review and analysis of logs to identify, block, and understand security threats. The specific data points (attack types, blocked IPs, targeted URIs, triggered rules) provide concrete evidence that the 'Regularly review and audit logs' control is being implemented effectively.\n\n",
        "Test Instructions":"Review log review procedures, audit schedules, and recent log analysis reports to confirm regular review and auditing of events.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-MLA-02, SSP-1",
        "Linked Evidence":"MLA-02-Sentinel Workbook Screenshot.png,MLA-02-sentinel_workbooks_inventory.json,MLA-02-Service Ticket 45_ SIEM and Sentinel Log review week 32_2025.pdf"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-MLA-03",
        "Control ID":"KSI-MLA-03",
        "Control Description":"Rapidly detect and remediate or mitigate vulnerabilities",
        "Testing Notes":"PIY-03-Policy and Inventory Vulnerability Reporting.PNG:\nTesting Notes: The presence of a dedicated email address (`Vulnerabilities@intelligrc.com`) for vulnerability reporting on the IntelliGRC Contact Us page demonstrates a formal channel for external parties to report potential vulnerabilities. This capability directly supports the rapidly detect aspect of the control, establishing a mechanism for receiving intelligence that enables subsequent remediation or mitigation efforts.\n\nPIY-04-Code Scanning.png:\nThe provided evidence, a screenshot of Azure DevOps Advanced Security code scanning results, demonstrates the organization's capability to rapidly detect vulnerabilities. The scan results for the `develop` branch of the `IntelliGRC` repository show High severity alerts, including Log Forging and Missing Function Level Access Control, which were recently detected (first detected on Wednesday). The system identifies specific files and line numbers where these vulnerabilities exist, providing actionable intelligence for remediation. The alerts being in an Open state confirms their recent detection and readiness for remediation or mitigation efforts by the development team.\n\nPIY-04-code-scan.yml.txt:\nThe provided Azure DevOps YAML pipeline significantly contributes to the rapid detection of vulnerabilities. The pipeline is designed to automatically execute security scans, specifically Static Application Security Testing (SAST) using GitHub Advanced Security for Azure DevOps (CodeQL) and Software Composition Analysis (SCA) using Grype. This automation ensures that vulnerability detection is integrated into the continuous integration (CI) process, running early and frequently in the development lifecycle on pull requests and non-master branches. This proactive and automated scanning approach enables rapid identification of security flaws in both custom code and third-party dependencies across multiple programming languages (C#, JavaScript, Python). The consolidated SARIF reports are published as pipeline artifacts, making the detected vulnerabilities immediately accessible. This immediate availability of detailed reports facilitates the rapid remediation or mitigation of identified vulnerabilities by providing developers with the necessary information to address issues promptly.\n\nPIY-04-Vulnerabilities.png:\nThe organization utilizes Microsoft Defender for Cloud to rapidly detect vulnerabilities within their Kubernetes service (`aks-intelli-prod`). The evidence shows active scanning, identifying 42 vulnerabilities, categorized by severity (e.g., 37 medium). The system provides a prioritized list of affected resources, pods, namespaces, and images, enabling focused remediation efforts. All identified vulnerabilities are assigned to an owner (`matthew.duval@intelligrc.com`), indicating clear responsibility for addressing them. Furthermore, the tracking of vulnerability status as On time or Overdue demonstrates a mechanism for monitoring and enforcing the rapid remediation or mitigation of identified vulnerabilities. The presence of Overdue items, while highlighting areas for process improvement, confirms that remediation is a tracked and managed activity within the environment.  Overdue item is identified is directly related to the glibc CVE that is part of the Chainguard Base Wolfi Container Image, which is currently disputed by glibc and thus marked as a vendor dependency.\n\nMLA-03-Sentinel Analytic Rules.json:\nControl Testing Notes:\n\n**Control:** Rapidly detect and remediate or mitigate vulnerabilities\n\n**Testing Note:**\n\nThe Azure Resource Manager (ARM) template evidence demonstrates the deployment of a comprehensive set of automated detection capabilities within Microsoft Sentinel, directly supporting the rapidly detect aspect of the control. The template includes numerous scheduled alert rules, many of which are configured to run frequently (e.g., every 10 minutes, hourly, daily), enabling near real-time identification of suspicious activities, potential vulnerabilities, and indicators of compromise (IOCs). Examples include the detection of suspicious application consent for offline access, various threat intelligence (TI) mappings (IP, URL, Email, Domain, File Hash) to identify known malicious entities, and alerts for privileged account abuses like sign-in failure spikes or authentication method changes.\n\nFurthermore, the deployment of the Fusion Rule significantly enhances rapid detection by leveraging machine learning to correlate low-fidelity alerts and anomalous events across multiple Microsoft security products. This capability is designed to identify high-fidelity, multistage attacks that might otherwise go unnoticed, thereby accelerating the identification of sophisticated threats.\n\nWhile the evidence primarily focuses on the detection mechanisms, the rapid and broad scope of threat and vulnerability detection provided by these Sentinel rules directly enables the subsequent remediation or mitigation activities. By quickly identifying anomalous behavior, credential access attempts, lateral movement indicators (e.g., PsExec usage, service accounts performing remote PS), and changes to privileged configurations, security teams are provided with timely alerts necessary to investigate, contain, and remediate or mitigate the identified vulnerabilities or ongoing attacks. For instance, an alert for Suspicious application consent for offline access or Authentication Methods Changed for Privileged Account provides the critical information needed to revoke access or revert unauthorized changes, thus mitigating the associated vulnerability.\n\nMLA-03-Analytic Rules used for detection.png:\nTesting Notes: The provided evidence, a screenshot of Microsoft Sentinel's Analytics 'Active rules' page, demonstrates the organization's capability for rapid detection of vulnerabilities and their exploitation. The presence of 36 active security detection rules, including both 'Scheduled' and 'Near-Real-Time (NRT)' rules, indicates continuous and timely monitoring for suspicious activities. These rules are categorized by severity (High, Medium, Low, Informational), with a significant focus on High and Medium severity threats (19 High, 17 Medium), allowing for prioritization of response. Furthermore, the rules are mapped to MITRE ATT&CK tactics and techniques, showing that they are designed to detect specific adversarial behaviors often associated with vulnerability exploitation. The diverse 'Source names' for these rules (e.g., Threat Intelligence, Microsoft Defender) confirm a comprehensive approach to threat detection. While the evidence directly shows the detection capability, the rapid and granular detection provided by these analytics rules is a critical prerequisite for enabling timely remediation or mitigation of identified vulnerabilities or their associated threats. The system's ability to quickly identify anomalous or malicious activity allows security teams to respond promptly, thereby contributing to the control's objective.\n\nMLA-03-Threat Intelligence - log-management - Microsoft Azure.pdf:\nThe Threat Intelligence dashboard within the Microsoft Azure portal provides strong evidence of the organization's capability to rapidly detect vulnerabilities. The dashboard demonstrates continuous and high-volume ingestion of threat indicators (e.g., IP addresses, domains) from multiple reputable sources, including Microsoft Defender Threat Intelligence and Alienvault OTX. Specifically, the Indicators Ingestion (Last 24 Hours) section shows thousands of indicators imported daily, with a significant spike around 4 AM on August 6, 2025, confirming ongoing and near real-time updates of threat intelligence into Microsoft Sentinel, a SIEM solution. The presence of Active Indicators further confirms that these ingested indicators are actively being used to detect known threat activities such as phishing, botnets, and malware. The ability to categorize active indicators by confidence score (e.g., Confidence 100.0, 75.0) allows for prioritized response to identified threats. While the evidence focuses primarily on the detection mechanism, the rapid and continuous feeding of relevant threat intelligence into a SIEM solution is foundational for enabling timely remediation or mitigation of detected vulnerabilities by providing immediate actionable insights.\n\nAzureBastionJumpBoxConfiguration.tf:\nTesting Notes: The provided Terraform configuration demonstrates robust mechanisms for remediating and mitigating vulnerabilities, with implied capabilities for detection.\n\n**Remediation and Mitigation:**\n\n*   **Automated Daily Patching:** The `azurerm_maintenance_configuration` resource is configured for InGuestPatch with a daily recurrence (`recur_every = 1Day`) and installs Critical, Security, and Other classified patches, ensuring rapid application of security updates and critical fixes. The `reboot = IfRequired` setting ensures full patch application.\n*   **Hardened Base Images:** The virtual machines are deployed using a CIS-hardened Ubuntu image (`0001-com-ubuntu-pro-minimal-cis-focal`), which significantly reduces the initial attack surface by starting with a secure baseline configuration.\n*   **Automated Key Rotation and Disk Encryption:** The `azurerm_key_vault_key` has an automatic rotation policy (expires in 90 days, rotates 30 days before expiry), and the `azurerm_disk_encryption_set` has `auto_key_rotation_enabled = true`. This ensures that encryption keys are regularly refreshed, mitigating the risk of long-term exposure if a key is compromised.\n*   **Advanced VM Security Features:** The VMs are configured with `encryption_at_host_enabled = true`, `secure_boot_enabled = true`, and `vtpm_enabled = true`. These features provide enhanced protection against data exfiltration, boot-level malware, and ensure cryptographic integrity, respectively.\n*   **Strong Authentication and Access Control:** SSH key-based authentication (`disable_password_authentication = true`), integration with Microsoft Entra ID via the `AADSSHLoginForLinux` extension, and granular `azurerm_role_assignment` (Virtual Machine AdministratorUser Login) enforce robust access controls and reduce the risk of unauthorized access due to weak credentials or compromised accounts.\n*   **Ephemeral OS Disk:** The use of an ephemeral OS disk (`diff_disk_settings { option = Local }`) facilitates faster re-imaging, enabling quicker recovery and remediation in the event of a compromise.\n\n**Detection:**\n\n*   While not explicitly detailing vulnerability *scanning* tools, the implementation of InGuestPatch and the use of a pro Ubuntu image (which typically includes security update services) imply a mechanism for identifying necessary patches, serving as a form of vulnerability detection to drive the daily remediation process.\n\nMLA-03-Security Operations Efficiency - log-management - Microsoft Azure.pdf:\n**Testing Notes:**\n\n**Control:** Rapidly detect and remediate or mitigate vulnerabilities.\n\n**Evidence Reviewed:** Security Operations Efficiency report from Microsoft Azure, dated August 6, 2025, covering the last 30 days.\n\n**Assessment:**\nThe provided evidence demonstrates that the organization has established processes and utilizes tools to rapidly detect security incidents and subsequently remediate or mitigate them.\n\n**Detection:** The report confirms the detection of **20 security incidents** within the 30-day period, all originating from **Azure Sentinel**. This indicates an active and effective detection mechanism, covering various severities (High, Medium, Low, Informational) and MITRE ATT&CK tactics. The detection of incidents across these categories signifies a comprehensive approach to identifying potential vulnerabilities or security events.\n\n**RemediationMitigation:** Of the 20 detected incidents, **17 have been closed**, indicating successful remediation or mitigation actions. This is direct evidence of the control's objective being met in terms of addressing identified issues.\n\n**Rapidity:**\n*   **Rapid Detection & Triage:** The **Mean Time to Triage** for these incidents is **1.838 days**. This metric indicates that detected security events are quickly acknowledged and moved into the response process, supporting the rapidly detect aspect of the control.\n*   **Rapid Remediation & Closure:** The **Mean Time to Closure** for the incidents is **2.252 days**. This directly supports the rapidly remediate or mitigate aspect, showing that detected vulnerabilities or security events are being resolved or mitigated in an efficient timeframe. The report further notes that most incidents are moved from New to Closed status relatively quickly, reinforcing the timeliness of resolution.\n\n**Conclusion:** Based on the Security Operations Efficiency report, the organization effectively and rapidly detects security incidentsvulnerabilities via Azure Sentinel and demonstrates a timely response through a mean time to triage of 1.838 days and a mean time to closure of 2.252 days, leading to the successful closure of 17 out of 20 incidents within the reporting period.\n\nMLA-03-Sentinel Analytic Rules.json:\nThe provided Azure Resource Manager (ARM) template, designed to deploy security analytics rules into a Microsoft Sentinel workspace, demonstrates a robust framework for rapidly detecting vulnerabilities and malicious activities.Rapid Detection:Comprehensive Coverage: The template includes 40 distinct analytics rules covering a wide array of potential threats and vulnerabilities. These range from suspicious application consents, authentication method changes for privileged accounts, and unauthorized access to critical infrastructure (Bastion host), to various threat intelligence mappings (IP, URL, Email, Domain) against diverse log sources (SigninLogs, DeviceNetworkEvents, AuditLogs, Key Vault logs). This broad coverage ensures that numerous attack vectors and indicators of compromise are actively monitored.Timeliness: Many rules are configured to run frequently, with several operating hourly, every 10 minutes (e.g., Audit Logging Failure), or even in Near-Real-Time (NRT) mode (e.g., NRT PIM Elevation Request Rejected). This high frequency of execution ensures that alerts are generated promptly upon detection of suspicious or malicious activity, supporting the rapid identification of issues.Advanced Threat Detection (Fusion ML): The enabled built-in Fusion (machine learning) rule significantly enhances rapid detection capabilities. By correlating lower-fidelity alerts and anomalous events from various Microsoft security products (e.g., Microsoft Entra ID Protection, Microsoft 365 Defender, Microsoft Defender for Endpoint) and Sentinel's own analytics rules, Fusion can identify complex, multi-stage attacks that might otherwise be difficult or time-consuming to piece together manually. This proactive correlation enables earlier detection of sophisticated threats.Support for Remediation and Mitigation:Incident Creation: The majority of the analytics rules are configured to create incidents upon alert generation. This automated incident creation is a critical step towards rapid response, enabling security teams to promptly investigate, remediate, or mitigate the identified vulnerabilities or ongoing attacks. The detailed descriptions within the rules, including query logic and MITRE ATT&CK mappings, provide valuable context for efficient incident response.Actionable Intelligence: By detecting specific vulnerable configurations (e.g., privileged account changes) or indicators of compromise (e.g., known bad IPs), the system provides actionable intelligence that directly informs remediation efforts. For example, detecting suspicious application consent allows for immediate investigation and potential revocation of permissions, while identifying unauthorized Bastion host access facilitates prompt lockout and review of access controls.In summary, the deployed Microsoft Sentinel analytics rules, combined with the Fusion ML capability, establish a strong foundation for the rapid detection of vulnerabilities and threats, which is a prerequisite for effective remediation and mitigation.",
        "Test Instructions":"Examine vulnerability management procedures, incident response plans, and recent remediation reports to assess the rapid detection and remediation\/mitigation of vulnerabilities.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-MLA-03, SSP-1",
        "Linked Evidence":"AzureBastionJumpBoxConfiguration.tf,KSI-MLA-03-DefenderForCloud_VulnTracking.png,KSI-MLA-03-GrypeContainerVulnScanResults.pdf,MLA-03-Analytic Rules used for detection.png,MLA-03-Security Operations Efficiency - log-management - Microsoft Azure.pdf,MLA-03-Sentinel Analytic Rules.json,MLA-03-Sentinel Analytic Rules.json,MLA-03-Threat Intelligence - log-management - Microsoft Azure.pdf,MLA-03-Vulnerability Remediation Timeline.PNG,MLA-04-DefenderForCloud_JumpHostDailyPatching.png,MLA-06-POAM Enhanced_Report.xlsx,PIY-03-Policy and Inventory Vulnerability Reporting.PNG,PIY-03-Vulnerability Report (intelliacr.azurecr.io_actionplan_v0.30.5).pdf,PIY-04-Code Scanning.png,PIY-04-code-scan.yml.txt,PIY-04-Vulnerabilities.png"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-MLA-04",
        "Control ID":"KSI-MLA-04",
        "Control Description":"Perform authenticated vulnerability scanning on information resources",
        "Testing Notes":"\nMLA-04-Burp-Scan-Authenticated.png:\nTesting Notes: The provided Burp Suite Professional screenshot confirms that an authenticated vulnerability scan was performed on the dev.intelligrc.app resource. The evidence shows that the Application login section within the scan configuration was set up with credentials for a Default User for `https:dev.intelligrc.app`, explicitly indicating that the scan was executed in an authenticated context. This directly addresses the requirement for authenticated vulnerability scanning. The Crawl and audit task successfully identified various vulnerabilities across different severity levels (High, Medium, Low, Informational), demonstrating that the scanning process was effective in identifying security weaknesses on the information resource.\n\nMLA-04-DefenderForCloud_JumpHostDailyPatching.png:\nThe provided evidence details patch management activities, specifically update installations and periodic assessments related to system updates. While patch management is crucial for addressing vulnerabilities, the evidence does not directly demonstrate authenticated vulnerability scanning of information resources. The Assessment operations noted are for determining update applicability rather than identifying security weaknesses through vulnerability scans. Therefore, this evidence does not meet the requirements for demonstrating authenticated vulnerability scanning.\n\nMLA-04-AzureBastionJumpHost_DailyScan&PatchingTerraformConfiguration.png:\nThe provided evidence describes an Azure Maintenance Configuration using Terraform, specifically for automated guest OS patching (e.g., Critical, Security, Other patches for Linux systems). While automated patching is a crucial aspect of information security and often follows vulnerability identification, this evidence does not directly demonstrate authenticated vulnerability scanning of information resources. The Terraform configuration focuses on the application of patches based on a defined schedule and patch classifications, rather than the process of scanning for vulnerabilities with authenticated access.\n\nMLA-04-Last red team test snippet - test notes.png:\nTesting Notes:\n\nAuthenticated vulnerability scanning was performed on the information resources as evidenced by the Test Notes.txt file. Specifically:\n\n1.  A Default user authenticated Crawl and Audit was initiated in Deep Scan Mode (around 9:57 AM), confirming that the scanning tool was configured to use authenticated sessions for more comprehensive coverage.\n2.  Subsequent authenticated scans were conducted using an administrator-level user (`ufccslqu@guerrillamail.org` with the role of License Admin) around 1:22 PM. This demonstrates the use of privileged accounts for scanning, which is crucial for identifying vulnerabilities that may only be accessible to authenticated users with higher permissions.\n\nThese activities directly support the control requirement to Perform authenticated vulnerability scanning on information resources, indicating that the system's internal components and authenticated user pathways were subject to vulnerability analysis.\n\nMLA-04-red_team_exercise_report.json:\nTesting Notes: The control Perform authenticated vulnerability scanning on information resources is met. The IntelliGRC Red Team Exercise Report confirms that vulnerability scanning was performed using Automated vulnerability scanners and a combination of automated scanning and manual penetration testing techniques. Crucially, the report explicitly states that authenticated vulnerability scans were conducted: Started an authenticated 'Crawl and Audit' using the Default User context and Started authenticated scans using the Admin User context. These scans were performed on the listed In-Scope Assets, which are IntelliGRC's information resources such as API gateways and application interfaces (e.g., `dev-admin-apigw.intelligrc.app`, `dev-api.intelligrc.app`). This demonstrates that authenticated vulnerability scanning was successfully performed on relevant information resources.\n\nMLA-04-Sample of Burp Suite Authenticated application test results.png:\nThe Burp Scanner Report for the `dev-admin` application provides evidence of vulnerability scanning performed on an information resource. The report, generated by Burp Suite Professional, details various identified vulnerabilities, such as SQL injection and strict transport security not enforced, indicating a comprehensive scan of the target application. Burp Suite Professional is capable of performing authenticated vulnerability scans, a standard practice for in-depth assessments of web applications to discover vulnerabilities that might only be accessible post-authentication. The nature and depth of the findings within the report suggest that an authenticated scan was conducted, fulfilling the control requirement to perform authenticated vulnerability scanning on information resources.\n\nMLA-04-Last red team test snippet methodology.png:\nThe evidence provided demonstrates authenticated vulnerability scanning on information resources through the Gray-Box Simulation stage. Specifically: \n\n*   **Scenario A** outlines the use of standard user credentials compromised from M365 to test and identify privilege boundaries within the system. This directly indicates an authenticated approach to assess security controls and potential vulnerabilities related to privilege escalation. \n*   **Scenario B** details the attempt to escalate access to IntelliGRC test applications and API endpoints using default user credentials to gain access to privileged functions or potentially access other tenants' data. This also confirms authenticated testing, aiming to uncover weaknesses that could lead to unauthorized access or data breaches.\n\nFurthermore, the Tools & Capabilities section lists Burp Suite Pro and Postman under WebApp Testing. These tools are commonly used for performing authenticated vulnerability scanning and testing on web applications and APIs, supporting the methodologies described in the Gray-Box Simulation. The activities described in the Gray-Box Simulation, performed with legitimate (albeit compromised or default) credentials, align with the definition of authenticated vulnerability scanning.\n\nMLA-04-red_team_exercise_report.json:\nThe Red Team Exercise Report provides evidence of authenticated vulnerability scanning performed on information resources. The report details a comprehensive security assessment of IntelliGRC's development environment, which included 9 in-scope assets such as API Gateways, Administrative Interfaces, and Core Services. Automated vulnerability scanners and Burp Suite Professional were utilized as part of the assessment methodology. Specifically, authenticated Crawl and Audit deep scans were conducted using both a Default User context and an Admin User context on July 29, 2025. The results, summarized in the report and available in vulnerability scan reports, indicate that no critical, high, medium, or low severity vulnerabilities were identified, demonstrating that authenticated vulnerability scanning was performed as required.\n\nAzureBastionJumpBoxConfiguration.tf:\nTesting Notes:\n\nThe evidence provided demonstrates a strong foundation and capability for performing authenticated vulnerability scanning on the deployed jumpbox information resources. While the Terraform configuration focuses on resource deployment and security hardening, it establishes crucial prerequisites for effective authenticated scanning and ongoing vulnerability management.\n\n*   **Authenticated Access:** The Terraform configuration explicitly enables robust authenticated access mechanisms critical for performing authenticated vulnerability scans. This includes:\n    *   **SSH key-based authentication** with password authentication disabled, enhancing security.\n    *   **Integration with Microsoft Entra ID** through the `AADSSHLoginForLinux` VM extension and associated role assignments (`VM Administrator Login`, `VM User Login`). These configurations provide the necessary credentialed access for a vulnerability scanner to log into the jumpboxes. This allows for deeper, authenticated checks of the operating system, installed software, and configurations, providing more comprehensive insights into the system's security posture than unauthenticated scans.\n\n*   **Vulnerability Management Foundation:** While the configuration does not explicitly deploy a dedicated vulnerability scanning agent or service, it lays a secure groundwork and defines a remediation process that complements vulnerability identification:\n    *   **CIS-Hardened Image:** The deployment utilizes a `CIS-hardened Ubuntu Pro Minimal` image. This inherently reduces the initial attack surface by implementing industry-recognized security benchmarks, addressing many common configuration vulnerabilities from the outset.\n    *   **Automated Patching:** A daily maintenance schedule is configured for in-guest OS patching, targeting `Critical`, `Security`, and `Other` updates. This demonstrates an active process for remediating vulnerabilities, which is a key component of a mature vulnerability management program, ideally following the identification of vulnerabilities through scanning.\n\n",
        "Test Instructions":"Request recent authenticated vulnerability scan reports for information resources and confirm regular scanning.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-MLA-04, SSP-1",
        "Linked Evidence":"AzureBastionJumpBoxConfiguration.tf,MLA-04-AzureBastionJumpHost_DailyScan&PatchingTerraformConfiguration.png,MLA-04-Burp-Scan-Authenticated.png,MLA-04-DefenderForCloud_JumpHostDailyPatching.png,MLA-04-Last red team test snippet methodology.png,MLA-04-Last red team test snippet - test notes.png,MLA-04-red_team_exercise_report.json,MLA-04-red_team_exercise_report.json,MLA-04-Sample of Burp Suite Authenticated application test results.png"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-MLA-05",
        "Control ID":"KSI-MLA-05",
        "Control Description":"Perform Infrastructure as Code and configuration evaluation and testing",
        "Testing Notes":"\nMLA-05-Terraform Formatting.txt:\nThe evidence demonstrates that Terraform code is automatically formatted as part of the CICD pipeline. The Terraform Format Check step in the pipeline executes a PowerShell script that validates the formatting of the Terraform code. This ensures that the infrastructure as code is consistently formatted, which improves readability and reduces the risk of errors.\n\nMLA-05-Checkov Scan.txt:\nThe Microsoft Security DevOps task within the CICD pipeline performs static security analysis, demonstrating Infrastructure as Code (IaC) evaluation and testing. Specifically, the pipeline executes IaC File Scanner and Checkov, verifying configurations against security best practices. The successful completion of the task, with no breaking results and the artifact upload, confirms the control's effectiveness.\n\nCNA-04-alz-mgmt terraform configuration identities.tf.png:\nBased on the evidence provided in `identities.tf`, the control objective of performing Infrastructure as Code (IaC) and configuration evaluation and testing is met. The file defines Azure resources, specifically managed identities, using Terraform, demonstrating IaC principles. The configuration is well-structured, with resources grouped logically within a dedicated resource group (`connectivity-mi-infra-rg`). Naming conventions are consistent, and the code includes comments explaining the purpose of each identity (storage_account_mi, acr_account_mi, fw_policy_mi), indicating a thoughtful configuration. The use of variables (var.default_location) allows for flexibility and reusability. The presence of a repository with other Terraform files (`main.tf`, `variables.tf`, etc.) and directories (`.pipelines`, `modules`) suggests a broader IaC implementation with CICD practices, supporting ongoing evaluation and testing.\n\n",
        "Test Instructions":"Review Infrastructure as Code (IaC) repositories and CI\/CD pipelines to confirm automated evaluation and testing of IaC and configurations.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-MLA-05, SSP-1",
        "Linked Evidence":"CNA-04-alz-mgmt terraform configuration identities.tf.png,MLA-05-Checkov Scan.txt,MLA-05-Terraform Formatting.txt"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-MLA-06",
        "Control ID":"KSI-MLA-06",
        "Control Description":"Centrally track and prioritize the mitigation and\/or remediation of identified vulnerabilities",
        "Testing Notes":"PIY-06-IntelliGRC FedRAMP RBAC Matrix.xlsx:\nTesting Notes:\n\nThe provided evidence primarily details the Role-Based Access Control (RBAC) framework for the IntelliGRC system and its underlying Azure infrastructure, outlining high-level duty assignments, Azure RBAC mappings, and application-level roles. While the document defines roles and responsibilities for teams such as the Security Team (e.g., Reviews Backend Logs in Microsoft Sentinel, Performs Security Impact Analysis on requested changes) and the CloudOps and Development Teams (e.g., Implements Approved System Changes), it does not provide direct evidence of a centralized process for tracking and prioritizing identified vulnerabilities. The evidence focuses on access governance and operational roles, rather than the specific workflow for vulnerability management, remediation planning, or prioritization criteria. Therefore, the evidence does not fully meet the control requirement to Centrally track and prioritize the mitigation and\/or remediation of identified vulnerabilities. \n\nMLA-06-POAM Enhanced_Report.xlsx\n\nEvidence provided reflects the centralized tracking of vulnerabilities in a single document (e.g. POAM Enhanced_Report.xlsx) and allows entries to be filtered by Resources Required, Original Detection Date, and Risk Rate which would facilitate prioritization efforts.\n\n",
        "Test Instructions":"Inspect the vulnerability tracking system or risk register to confirm central tracking and prioritization of identified vulnerabilities for mitigation\/remediation.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-MLA-06, SSP-1",
        "Linked Evidence":"MLA-06-POAM Enhanced_Report.xlsx,PIY-06-IntelliGRC FedRAMP RBAC Matrix.xlsx"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-PIY-01",
        "Control ID":"KSI-PIY-01",
        "Control Description":"Have an up-to-date information resource inventory or code defining all deployed assets, software, and services",
        "Testing Notes":"\nPIY-01-prod-packages.csv:\nThe provided Software Bill of Materials (SBOM) serves as an up-to-date information resource inventory, detailing all deployed assets, software, and services within the IntelliGRC suite. The SBOM comprehensively lists software components, libraries, applications, and operating system packages, fulfilling the control requirement. The detailed inventory includes key applications, technology stack components (e.g., .NET Core, Node.js, Python), cloud integrations (Azure), and underlying operating system packages, demonstrating a thorough understanding and documentation of the system's constituents.\n\nPIY-01-Q3 2025 SBOM Generation and Review.pdf:\nBased on service ticket #437, IntelliGRC successfully generated and reviewed Software Bill of Materials (SBOM) for Q3 2025. The ticket documents the collaboration between the security and cloud operations teams in creating these SBOMs. Attached to the ticket are `prod-sboms.zip` containing individual SBOM reports, and `prod-packages.csv`, a deduplicated list of software libraries used across IntelliGRC's custom applications. This evidence demonstrates an up-to-date inventory of software resources for custom-developed services. Note, the SBOMs do not cover 3rd party services.\n\nPIY-01-SSP-Appendix-M-Integrated-Inventory-Workbook.xlsx:\nThe FedRAMP System Security Plan (SSP) Appendix M: FedRAMP Integrated Inventory Workbook Template, Version 3.1 provides a detailed inventory of all hardware, software, and services for the system. The workbook includes a comprehensive list of assets, with unique asset identifiers, IP addresses or container image hashes, and virtualpublic designations. It also specifies the operating system, asset type, hardware, and baseline configuration for each asset. Furthermore, the workbook details software and database inventories, including vendors, names, versions, and patch levels. The function, diagram label, and comments sections provide context for each asset, and the end-of-life section tracks EOL dates for software and services.\n\n",
        "Test Instructions":"Request access to the information resource inventory or code defining all deployed assets, software, and services, and confirm its up-to-dateness.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-PIY-01, SSP-1",
        "Linked Evidence":"PIY-01-prod-packages.csv,PIY-01-prod-sboms.zip,PIY-01-Q3 2025 SBOM Generation and Review.pdf,PIY-01-SSP-Appendix-M-Integrated-Inventory-Workbook.xlsx"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-PIY-02",
        "Control ID":"KSI-PIY-02",
        "Control Description":"Have policies outlining the security objectives of all information resources",
        "Testing Notes":"\nPIY-02-PolicyReview-Rules of Behavior 2025-07-11.csv:\nThe training status report for Policy - Rules of Behavior 2025-07-11 indicates that 21 out of 23 employees have completed the training. This demonstrates that employees are being trained on security policies, indicating the organization has communicated and reinforced policies outlining the security objectives of information resources.\n\nPIY-02-Q3 2025 Training report (July 2025).csv:\nThe training report demonstrates that Intelligrc employees are required to complete security training modules covering Insider Threats, Unintentional Insider Threat, and Smishing. Completion of these modules indicates the company has communicated security objectives related to these topics to its employees.\n\nPIY-02-List of Policies 1.PNG:\nThe evidence shows a 'Policy List' folder containing multiple documents related to FedRAMP Moderate policies. The file names follow a consistent naming convention: 'FedRAMP - Moderate - [Acronym] - [Full Name].docx'. Each document corresponds to a specific FedRAMP control family, such as 'Awareness Training', 'Audit and Accountability', and 'Risk Assessment'. This indicates that policies are in place that address the security objectives of information resources.\n\nPIY-02-Annual Security and Awareness Training v2025-08.xlsx:\nBased on the training report, all employees are required to take Annual Se training. The report indicates which employees have been assigned and\/or completed the training. Completion of security training demonstrates the organization's commitment to ensuring employees are aware of their security responsibilities. T\n\nPIY-02-List of Policies 2.PNG:\nThe evidence provided includes a list of policy documents related to FedRAMP Moderate controls. The naming convention of the documents (e.g., 'FedRAMP - Moderate - MA - Maintenance.docx') indicates that the policies cover various security objectives, aligning with the control requirement to have policies outlining the security objectives of all information resources. The presence of policies for different control families (Access Control, Configuration Management, Identification and Authentication, etc.) further demonstrates coverage across a range of information resources.\n\nPIY-02-Rules of Behavior.pdf:\nThe 'Rules of Behavior' document (also referred to as the Acceptable Use Policy) outlines the security objectives for IntelliGRC's information resources. It establishes rules for authorized users of IntelliGRC's systems, data, devices, and networks to protect the confidentiality, integrity, and availability of company assets. The policy applies to all IntelliGRC employees, contractors, consultants, vendors, and third-party partners, demonstrating a broad scope of coverage. The document explicitly states its goal to ensure adherence to organizational and regulatory standards. The policy is reviewed annually and requires formal acknowledgement from all personnel, confirming they have read, understood, and agree to abide by the rules.\n\n",
        "Test Instructions":"Obtain and review policies outlining the security objectives for all information resources.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-PIY-02, SSP-1",
        "Linked Evidence":"PIY-02-Annual Security and Awareness Training v2025-08.xlsx,PIY-02-List of Policies 1.PNG,PIY-02-List of Policies 2.PNG,PIY-02-List of Policies.json,PIY-02-PolicyReview-Rules of Behavior 2025-07-11.csv,PIY-02-Q3 2025 Training report (July 2025).csv,PIY-02-Rules of Behavior.pdf"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-PIY-03",
        "Control ID":"KSI-PIY-03",
        "Control Description":"Maintain a vulnerability disclosure program",
        "Testing Notes":"\nPIY-03-Vulnerability Report (intelliacr.azurecr.io_actionplan_v0.30.5).pdf:\nBased on the provided Grype vulnerability scan report, the document indicates the existence of a vulnerability report, which contributes to maintaining a vulnerability disclosure program. The report details vulnerabilities found in a container image, including the image name, checksum, and a summary of the vulnerabilities identified. The report also provides details on specific vulnerabilities, including CVE IDs, severity levels, and descriptions.\n\nPIY-03-Policy and Inventory Vulnerability Reporting.PNG:\nBased on the evidence provided in the webpage image, IntelliGRC maintains a vulnerability disclosure program. The Contact Us page prominently displays a dedicated email address (Vulnerabilities@intelligrc.com) for reporting security vulnerabilities. This demonstrates a clear channel for external parties to disclose potential vulnerabilities, supporting the existence of a vulnerability disclosure program.\n\nPIY-03-CISA Vulnerability.pdf:\nThe CISA advisory demonstrates a vulnerability disclosure program by proactively identifying and publishing details about actively exploited vulnerabilities. The advisory lists specific vulnerabilities (CVEs) affecting D-Link products, indicating that CISA is actively monitoring and disclosing vulnerabilities that pose a risk. The document urges organizations to remediate these vulnerabilities, further supporting the existence of a vulnerability disclosure program.\n\nPIY-03-Krebs Vulnerability.pdf:\nThe evidence demonstrates active monitoring of vulnerability disclosures through a subscription to a security-related mailing list (KrebsOnSecurity). The email details a critical zero-day vulnerability in Microsoft SharePoint, including the affected product, severity, and potential victims. This shows a proactive approach to staying informed about emerging threats, which is a key component of maintaining a vulnerability disclosure program. The inclusion of a webinar advertisement related to ITOps and improving patchingcompliance visibility further supports efforts to remediate vulnerabilities.\n\n",
        "Test Instructions":"Request documentation or public-facing information about the vulnerability disclosure program.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-PIY-03, SSP-1",
        "Linked Evidence":"PIY-03-CISA Vulnerability.pdf,PIY-03-Krebs Vulnerability.pdf,PIY-03-Policy and Inventory Vulnerability Reporting.PNG,PIY-03-Vulnerability Report (intelliacr.azurecr.io_actionplan_v0.30.5).pdf"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-PIY-04",
        "Control ID":"KSI-PIY-04",
        "Control Description":"Build security considerations into the Software Development Lifecycle and align with CISA Secure By Design principles",
        "Testing Notes":"\nPIY-04-actionplan-ci.yml.txt:\nThe pipeline incorporates security considerations through static code analysis in the 'Code Scan' stage, utilizing CodeQL. This stage checks for vulnerabilities in both the application and its database migrator. The pipeline also uses templates from a separate repository, 'IntelliGRCintelli-app-configs', promoting code reuse and standardization. In addition, the pipeline triggers on the develop branch and performs unit tests\n\nPIY-04-Minimum Reviewer Policy.png:\nThe 'Require a minimum number of reviewers' policy is enabled for the 'develop' branch, mandating at least one reviewer for pull requests. This aligns with secure development practices by ensuring code changes undergo peer review before integration. The branch policy prevents direct commits to the develop branch. This enforces code review and prevents accidental or malicious code changes.\n\nPIY-04-ci.yaml:\nEvidence shows an Azure DevOps pipeline configured to trigger on the `main` branch, using an Ubuntu-based agent. The pipeline is structured into three stages (`detect`, `check`, and `release`) defined in separate template files. A variable `isMaster` is defined to check if the build is running on the `main` branch. This demonstrates security considerations are built into the Software Development Lifecycle through automated checks and deployments triggered by code changes. The pipeline structure allows for incorporating security scans, validation, and automated testing in the `check` stage, aligning with Secure By Design principles.\n\nPIY-04-code-scan.yml.txt:\nBased on the provided evidence, the Azure DevOps YAML pipeline demonstrates a strong implementation of security considerations within the Software Development Lifecycle (SDLC), aligning with CISA Secure By Design principles. The pipeline incorporates static application security testing (SAST) using GitHub Advanced Security (CodeQL) and software composition analysis (SCA) with Grype. These tools are integrated into the build process to identify vulnerabilities early in the development cycle. The pipeline is configurable, allowing for scanning of multiple languages and optional inclusion of a 'migrator' project. Conditional execution ensures scans run on relevant branches, and all findings are consolidated into a single artifact for review. The use of CodeQL and Grype, combined with automated scanning within the CICD pipeline, reflects a proactive approach to security, embedding security checks throughout the SDLC.\n\nPIY-04-Vulnerabilities.png:\nThe Microsoft Defender for Cloud dashboard provides a centralized view of security findings for the aks-intelli-prod Kubernetes service. The presence of vulnerability scan results, categorized by risk level (Medium: 37, Low: 5), demonstrates a proactive approach to identifying and addressing security weaknesses in container images. The listing of vulnerabilities by resource, pod, namespace, and image, with assigned owners (matthew.duval@intelligrc.com) and statuses (On timeOverdue), indicates a process for tracking and managing identified vulnerabilities. The ability to download a CSV report enables further analysis and documentation of security findings. The integration of security scanning into the Azure DevOps pipeline, as evidenced by the Microsoft Defender for Cloud findings, aligns with the Secure By Design principle of building security into the SDLC.\n\nPIY-04-Code Scanning.png:\nThe presence of the Advanced Security section in Azure DevOps, specifically the Code Scanning tool, demonstrates that security considerations are integrated into the Software Development Lifecycle (SDLC). The Code Scanning tool, which is actively used on the `develop` branch of the `IntelliGRC` repository, aligns with CISA Secure By Design principles by proactively identifying and flagging potential security vulnerabilities such as Log Forging and Missing Function Level Access Control. The fact that these high-severity alerts are being detected early in the development process (on the `develop` branch) indicates a commitment to addressing security issues before they reach production. This proactive approach supports the principle of building security in from the start, rather than bolting it on later. The detailed reporting, including affected files and line numbers, enables developers to address these vulnerabilities effectively.\n\nPIY-04-check.yaml:\nThe Azure DevOps pipeline incorporates security considerations into the Software Development Lifecycle (SDLC) by automating security checks on Terraform code before it is merged. This aligns with Secure By Design principles by proactively identifying and addressing potential vulnerabilities early in the development process.\n\nEvidence of meeting the control:\n\n*   **Automated Security Scanning:** The `scan` job utilizes the Microsoft Security DevOps task to perform security scans on the Infrastructure as Code (IaC). The `break: true` setting ensures that the pipeline fails if vulnerabilities are found, preventing insecure code from being merged.\n*   **Terraform Linting and Formatting:** The `lint` job uses `tflint` to enforce code quality and standards. The `validate` job checks for correct Terraform formatting and syntax, ensuring consistency and reducing potential errors.\n*   **Targeted Module Checks:** The pipeline dynamically adjusts based on the changed modules. The jobs are configured to run specifically on the directories of the changed modules, optimizing efficiency.\n*   **Non-Master Branch Execution:** The pipeline is configured to run only on non-master branches, preventing direct changes to the main branch without undergoing security checks.  The condition `isMaster` is `false` enforces this.\n*   **Override Prevention:** The pipeline has logic to prevent running the checks, via the `labelOutput` variable from the `detect` stage. This allows for manual overrides.\n\n\nPIY-04-Alerts.png:\nBased on the Azure DevOps Advanced Security Dashboard for the IntelliGRC project, the evidence demonstrates that security considerations are integrated into the Software Development Lifecycle (SDLC), aligning with CISA Secure By Design principles, specifically:\n\n*   **Alert Monitoring and Management:** The dashboard provides a centralized view of security alerts, including dependencies, code scanning, and secrets, with a total of 524 alerts identified. This centralized monitoring enables proactive identification and management of potential security vulnerabilities throughout the SDLC.\n*   **Trend Analysis:** The alerts trend analysis visualizes the number of alerts over time for dependencies and code scanning. The dependency alerts show a slow, steady increase from approximately 120 alerts in February to around 180 in late July, with a sharp increase between July 22 and August 5, 2025. Code scanning alerts remained very low and stable (around 25) until early July 2025. A dramatic spike occurred after July 8, with the number of alerts soaring to over 250 by August 5, surpassing the number of dependency alerts. This enables teams to identify patterns, prioritize remediation efforts, and continuously improve security practices.\n*   **Severity Breakdown:** The breakdown of alerts by severity level for both dependencies and code scanning, enabling prioritization of remediation efforts based on the potential impact. Dependency alerts consist of Medium (141), High (99), Low (18), and Critical (8). Code scanning alerts consist of High (227) and Medium (31).\n*   **Secrets Scanning:** The dashboard indicates that zero secrets have been identified. This suggests the implementation of secrets scanning during the SDLC.\n*   **Project Scope:** The dashboard provides security insights across 14 repositories within the IntelliGRC project. This indicates that security is being managed and monitored across the entire project.\n\n\nPIY-04-buildandtag.yml.txt:\nThe Azure DevOps pipeline incorporates security considerations into the Software Development Lifecycle (SDLC) by automating security scans and compliance checks at various stages.\n\n*   **Secure Build Process:** The pipeline builds containerized applications using Docker, ensuring consistent and repeatable builds. The use of configurable parameters allows for flexibility and reuse across different modules.\n*   **Static Code Analysis:** The `obtainVersions` stage includes a code scan using a reusable template `code-scan-main.yml` to perform static code analysis.\n*   **Image Security Scanning:** The `scapscan` stage performs security scans on the built application image using tools like OpenSCAP, Trivy, and Grype. These scans include compliance checks, SBOM generation, and vulnerability scanning.\n*   **Artifact Management:** The pipeline publishes the results of the security scans as pipeline artifacts, providing a record of the security checks performed.\n*   **Secure Release Tagging:** The `tagAndDocument` stage creates a Git tag for the release, providing a versioned record of the release. The tag is annotated with a message containing the date and PR title.\n*   **Documentation and Changelog:** The `tagAndDocument` stage updates the project's documentation in the Azure DevOps Wiki, including a changelog entry for the new version. The script prevents duplicate changelog entries.\n\nThese security considerations align with CISA's Secure By Design principles by:\n\n*   **Taking Ownership of Security Outcomes:** The automated security scans and compliance checks ensure that security is integrated into the development process.\n*   **Embracing Radical Transparency and Accountability:** The pipeline publishes the results of the security scans as pipeline artifacts, providing transparency into the security checks performed.\n*   **Leading From the Top:** The pipeline automates the security checks and compliance checks.\n\n\nPIY-05-IntelliGRC - Systems Development Life Cycle (SDLC).pdf:\nThe Secure Systems Development Lifecycle (SDLC) Overview document demonstrates that IntelliGRC builds security considerations into their Software Development Lifecycle and aligns with CISA Secure By Design principles through the following: \n\n*   **Integration of Security Throughout the SDLC:** The document details a formal SDLC process that incorporates security, privacy, and compliance into every stage, from requirements definition to decommissioning, aligning with NIST SP 800-53 Rev. 5, SP 800-218, SP 800-160 Vol. 1, and SP 800-37 Rev. 2.\n*   **Defined Roles and Responsibilities:** Clear roles and responsibilities are assigned to various teams, including the CISO, System Owner, Security Team, Development Team, CloudOps Team, ProcurementContracts Team, and Legal Counsel, ensuring accountability for security-related tasks.\n*   **Secure Development Practices:** The SDLC incorporates secure coding practices aligned with OWASP Top 10 and CWESANS Top 25, utilizing static code analysis and linting. Code is managed in Azure DevOps Git with enforced branch protections, signed commits, and mandatory peer reviews.\n*   **Third-Party Component Management:** The SDLC includes processes for approving and tracking third-party components via CycloneDX SBOMs. Unsupported components are flagged for remediation per SA-22, and components are verified via cryptographic hash and repository integrity.\n*   **Testing and Security Validation:** The SDLC incorporates automated testing (unit, integration), SAST, DAST, SCA, and manual reviews. Test results and scan reports are version-controlled and archived.\n*   **CICD and IaC Security:** Azure DevOps pipelines enforce gating policies, secrets are managed in Azure Key Vault, and Terraform is used for IaC. Container images and IaC modules are versioned and scanned for tampering.\n*   **Operational Monitoring and Threat Detection:** Azure Sentinel (SIEM) and Microsoft Defender for Cloud are used for real-time monitoring, and Microsoft threat intelligence and other feeds are ingested.\n*   **Maintenance and Continuous Improvement:** Monthly patch cycles are executed, and automated tools are used to notify developers of updates and CVEs. After-action reports are used to improve design and coding practices.\n*   **Alignment with FedRAMP Controls:** The document maps to key FedRAMP Moderate controls, including SA-3, SA-4, SA-10, SA-11, SA-22, and SR-11.\n*   **Review, Versioning, and Audit Readiness:** The SDLC document is reviewed at least annually and updated as needed. Evidence of SDLC control execution is retained and made available for audits. The document is stored in SharePoint Online with version tracking and access control.\n\n",
        "Test Instructions":"Review SDLC documentation, development processes, and security testing integration points to confirm security considerations are built-in and align with CISA Secure By Design principles.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-PIY-04, SSP-1",
        "Linked Evidence":"PIY-04-actionplan-ci.yml.txt,PIY-04-Alerts.png,PIY-04-buildandtag.yml.txt,PIY-04-check.yaml,PIY-04-ci.yaml,PIY-04-Code Scanning and Vulnerabilities.json,PIY-04-Code Scanning.png,PIY-04-code-scan.yml.txt,PIY-04-Minimum Reviewer Policy.json,PIY-04-Minimum Reviewer Policy.png,PIY-04-Vulnerabilities.png,PIY-05-IntelliGRC - Systems Development Life Cycle (SDLC).pdf"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-PIY-05",
        "Control ID":"KSI-PIY-05",
        "Control Description":"Document methods used to automatically evaluate information resource implementations",
        "Testing Notes":"\nPIY-05_IntelliGRC_ConMonEvidence.pdf:\nThe evidence provided demonstrates automated evaluation of information resource implementations through several key mechanisms:\n\n*   **Static Code Analysis:** Azure DevOps is configured to perform static code analysis on the IntelliGRC project. The \n\nPIY-05-IntelliGRC - Systems Development Life Cycle (SDLC).pdf:\nThe Secure Systems Development Lifecycle (SDLC) Overview document describes the methods used to automatically evaluate information resource implementations. Specifically, the document mentions the use of SAST (Static Application Security Testing) and DAST (Dynamic Application Security Testing) integrated into the CI pipelines to find insecure coding patterns and vulnerabilities. Additionally, Software Composition Analysis (SCA) is used to verify third-party libraries against vulnerability databases. The document also states that unit and integration tests are required for all new code, with coverage thresholds enforced by Azure DevOps pipeline gating.\n\n",
        "Test Instructions":"Request documentation detailing methods used to automatically evaluate information resource implementations (e.g., security static analysis, dynamic analysis, compliance checks).",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-PIY-05, SSP-1",
        "Linked Evidence":"PIY-05_IntelliGRC_ConMonEvidence.pdf,PIY-05-IntelliGRC - Systems Development Life Cycle (SDLC).pdf"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-PIY-06",
        "Control ID":"KSI-PIY-06",
        "Control Description":"Have a dedicated staff and budget for security with executive support, commensurate with the size, complexity, scope, and risk of the service offering",
        "Testing Notes":"\nPIY-06-FedRAMPProjectManagementGanttChart.png:\nBased on the Archstone Security FedRAMP Moderate advisory project tracker, the presence of a detailed project plan with tasks related to FedRAMP Moderate authorization suggests a dedicated team working on security. The 'WORK DAYS' column indicates allocated time, implying a security budget. The executive support is demonstrated by detail project planning and active project management as seen by the active editing and collaborative features.\n\nPIY-06-security Allocation Budget.png:\nThe 2025 Expenses (projected) spreadsheet outlines a comprehensive budget that includes significant investments in security-related areas. Specifically, the $264,000 allocated to the 'FedRAMP Implementation Budget' demonstrates a commitment to security, with funds covering professional services, tools, solutions, and labor. Additionally, the budget includes costs for security-focused software and tools such as Office 365 E5, ZenDesk (Customer Support Portal), and LinkerD Enterprise, further supporting the control objective of having a dedicated budget for security.\n\nPIY-06-IntelliGRC FedRAMP RBAC Matrix.xlsx:\nBased on the evidence provided, testing notes for the control 'Have a dedicated staff and budget for security with executive support, commensurate with the size, complexity, scope, and risk of the service offering' can include the following: 1. Staff Dedication: The document clearly outlines dedicated teams and roles responsible for security-related activities, including the Security Team, CloudOps Team, and CISO. This demonstrates a commitment to having dedicated staff for security. 2. Defined Responsibilities: The responsibility matrix details specific security duties assigned to different roles, such as enforcing policies, reviewing logs, and performing security impact analysis. This indicates a structured approach to security responsibilities. 3. Access Controls: The detailed Azure RBAC section illustrates granular control over access to infrastructure resources, ensuring that teams have the necessary permissions to perform their security functions. 4. Executive Support: The inclusion of the System Owner and CISO in the Super Admin role within the IntelliGRC application and their responsibilities for policy review and approval suggests executive support for security initiatives. 5. Commensurate Resources: The breadth of security measures described, including RBAC, Sentinel monitoring, and defined roles, indicates a level of security investment commensurate with the size and complexity of the IntelliGRC system.\n\n",
        "Test Instructions":"Document evidence of a dedicated security staff (e.g., organizational charts, job descriptions, training records) and a commensurate budget (e.g., budget allocations, spending reports, executive approval for security investments) with executive support (e.g., meeting minutes, policy statements, communications) that aligns with the size, complexity, scope, and risk of the service offering.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-PIY-06, SSP-1",
        "Linked Evidence":"PIY-06-FedRAMPProjectManagementGanttChart.png,PIY-06-IntelliGRC FedRAMP RBAC Matrix.xlsx,PIY-06-security Allocation Budget.png"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-PIY-07",
        "Control ID":"KSI-PIY-07",
        "Control Description":"Document risk management decisions for software supply chain security",
        "Testing Notes":"\nPIY-07-IntelliGRC_Prod-SBOM_Summary-8.8.25.csv:\nBased on the provided Software Bill of Materials (SBOM), the document demonstrates documented risk management decisions for software supply chain security through detailed insight into software components, versions, and dependencies. The SBOM enables the identification of potential vulnerabilities, outdated software, and unauthorized components, informing risk assessment and mitigation strategies. The documentation of the software supply chain facilitates proactive management of risks associated with third-party software by knowing exactly what is included in the software. \n\nPIY-07-IntelliGRC - Supply Chain Risk Management (SCRM) Plan_v1.0.pdf:\nThe SCRM Plan V1.0 explicitly documents risk management decisions for software supply chain security. The plan outlines the strategic and procedural framework for identifying, assessing, mitigating, and monitoring risks associated with externally sourced products, services, and components. Key elements such as SBOM generation, supplier risk reviews, and anti-counterfeit measures demonstrate proactive risk management. The plan's alignment with NIST standards further supports the documented decision-making process.\n\nPIY-07-Supply Chain Risk Management Policy.docx:\nThe Supply Chain Risk Management Policies document outlines IntelliGRC's formal policies for SCRM and aligns with the FedRAMP Moderate baseline.\n\nThe document specifies that the Security Team develops and maintains a comprehensive SCRM plan, reviewed annually, protected from unauthorized access, and addresses risks across the full lifecycle of all system components.\n\nAdditionally, the document specifies that the Procurement Team uses standardized language, security clauses, and Section 889 compliance verification to mitigate risks during acquisition, and that the Procurement Team assesses and reviews supply chain risks from suppliers at least annually, demonstrating that risk management decisions are documented for software supply chain security.\n\n",
        "Test Instructions":"Obtain and review documentation of risk management decisions related to software supply chain security.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-PIY-07, SSP-1",
        "Linked Evidence":"IntelliGRC_SBOM_Package_8.8.25.zip,PIY-07-IntelliGRC_Prod-SBOM_Summary-8.8.25.csv,PIY-07-IntelliGRC - Supply Chain Risk Management (SCRM) Plan_v1.0.pdf,PIY-07-Supply Chain Risk Management Policy.docx"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-RPL-01",
        "Control ID":"KSI-RPL-01",
        "Control Description":"Define Recovery Time Objectives (RTO) and Recovery Point Objectives (RPO)",
        "Testing Notes":"\nRPL-01-RTO and RPO Definitions.PNG:\nBased on the provided FedRAMP System Security Plan (SSP) Appendix G excerpt, the document explicitly defines Recovery Time Objectives (RTOs) and Recovery Point Objectives (RPOs) for critical system components. The document outlines the RTO, RPO and Impact of Downtime for Azure DevOps  Terraform, Bastion Host, Microsoft Sentinel, Defender for Cloud, Web Application Firewall, and Defender for Endpoint. The defined RTOs range from 2 to 8 hours, while RPOs range from 30 minutes to 2 hours, demonstrating a clear definition of recovery objectives.\n\nINR-01-SSP-Appendix-G_InteliGRC-Information-System-Contingency-Plan-(ISCP).pdf:\nThe System Security Plan (SSP) Appendix G: Information System Contingency Plan (ISCP) clearly defines Recovery Time Objectives (RTO) and Recovery Point Objectives (RPO) for the IntelliGRC Information System (IGRC-IS). The document specifies an RTO of 24 hours and an RPO of 8 hours for the overall system. Furthermore, Appendix N (Business Impact Analysis) provides component-specific RTOs and RPOs for critical system functions, demonstrating a detailed approach to recovery planning. This level of detail confirms that the control requirement is met.\n\n",
        "Test Instructions":"Request documentation defining Recovery Time Objectives (RTO) and Recovery Point Objectives (RPO) for critical systems.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-RPL-01, SSP-1",
        "Linked Evidence":"INR-01-SSP-Appendix-G_InteliGRC-Information-System-Contingency-Plan-(ISCP).pdf,RPL-01-RTO and RPO Definitions.PNG"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-RPL-02",
        "Control ID":"KSI-RPL-02",
        "Control Description":"Develop and maintain a recovery plan that aligns with the defined recovery objectives",
        "Testing Notes":"\nINR-01-SSP-Appendix-G_InteliGRC-Information-System-Contingency-Plan-(ISCP).pdf:\nThe Information System Contingency Plan (ISCP) outlines a recovery plan that aligns with defined recovery objectives. The plan specifies a Recovery Time Objective (RTO) of 24 hours and a Recovery Point Objective (RPO) of 8 hours. The plan details a three-phased approach: Activation and Notification, Recovery, and Reconstitution. Appendix N (Business Impact Analysis) identifies critical system functions and component-specific RTOs and RPOs. The plan is scheduled to be tested at least annually, with the next test planned for Q3 2026. A post-recovery full system backup is performed to create a fresh baseline for future recoveries.\n\n",
        "Test Instructions":"Obtain and review the recovery plan, confirming its alignment with defined recovery objectives.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-RPL-02, SSP-1",
        "Linked Evidence":"INR-01-SSP-Appendix-G_InteliGRC-Information-System-Contingency-Plan-(ISCP).pdf"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-RPL-03",
        "Control ID":"KSI-RPL-03",
        "Control Description":"Perform system backups aligned with recovery objectives",
        "Testing Notes":"\nRPL-01-CP - Contingency Planning Policy.pdf:\nThe evidence file summary indicates that the CloudOps Team is responsible for conducting and protecting backups of user-level information, system-level information, and system documentation. Backups are performed frequently enough to meet recovery objectives. The CloudOps Team tests backup information annually to verify media reliability and information integrity. Backups are protected with cryptographic mechanisms to prevent unauthorized disclosure or modification, aligning with the control objective to perform system backups aligned with recovery objectives.\n\nRPL-03-Backup Responsibility.PNG:\nBased on the evidence provided, the CloudOps team is responsible for system and data backups, which aligns with the control requirement to perform system backups. The evidence specifically highlights system and data backups as a primary responsibility of the CloudOps team. Additionally, the CloudOps team supports recovery actions during plan execution, further demonstrating alignment with recovery objectives.\n\nRPL-03-Incident Response Roles 1.PNG:\nBased on the document Incident Response Team Relevant Roles and Responsibilities, there is no evidence of system backups aligned with recovery objectives. The document outlines the roles and responsibilities of the Incident Response Team (IRT), including the Incident Manager, Incident Coordinator, and Incident Responders. While the document details how the IRT responds to incidents, it does not provide information on system backups or recovery objectives.\n\nRPL-03-Backup Components.PNG:\nTesting Notes:\n\nThe provided evidence details the IntelliGRC backup system. Backups are performed daily and are cloud-based. The system retains data for 90 days in hot storage and 1 year in cold storage. The evidence demonstrates that system backups are performed, aligning with the recovery objectives as the backups are done daily and retained for a sufficient period.\n\nRPL-03-Incident Response Roles 2.PNG:\nTesting notes:\n\nThe CloudOps and Development Teams, as part of their technical response role, are responsible for implementing system and data backups. This aligns with the control objective to perform system backups. The teams also support recovery actions during the execution of a contingency plan, ensuring the recovery of application components and data models. The documented responsibilities of the Technical Response Role (CloudOps & Development) explicitly state the implementation of system and data backups, which directly addresses the control requirement.\n\nRPL-03-Backup Location.PNG:\nThe provided documentation confirms that IntelliGRC, Inc. performs system backups, aligning with recovery objectives. Evidence includes:Offsite backups are maintained in Azure Cloud, and on-site backups are kept in both online and offline formats, encompassing user-level, system-level, and documentation data.\n\nRPL-03-backup-vault.tf:\nBased on the evidence provided, the Terraform code snippet details the provisioning of Azure backup infrastructure, which aligns with the control objective of performing system backups. Specifically, the code configures a Backup Vault, a Resource Group for the vault, and a Resource Guard for added security. The Backup Vault module, sourced from a version-controlled repository, includes a configuration parameter for soft_delete_retention_days set to 90 days. This demonstrates consideration for recovery objectives by retaining deleted backup data for a defined period.\n\nRPL-03-Backup Definitions.PNG:\nBased on the evidence provided, the document outlines different data backup types, including Full, Differential, Incremental, and Mirror backups. Each backup type has a description of what data is backed up, as well as the benefits and disadvantages of each. This demonstrates that the system backups are aligned with recovery objectives, as different backup types can be used to meet different recovery objectives.\n\nINR-01-SSP-Appendix-G_InteliGRC-Information-System-Contingency-Plan-(ISCP).pdf:\nThe evidence provided in the FedRAMP System Security Plan (SSP) Appendix G: Information System Contingency Plan (ISCP) demonstrates that IntelliGRC performs system backups aligned with recovery objectives. Specifically, the plan details the use of Azure Backup, Azure Backup Vault, and Azure Blob Storage for daily, full, cloud-based backups with a retention period of 1 year. Backups are stored in a geo-redundant configuration across Azure's East-US and West-US regions. The backup scope includes usersystem-level information, security documentation, and Azure DevOps assets (Source Code, Product Management, Terraform state). The plan also defines a Recovery Time Objective (RTO) of 24 hours and a Recovery Point Objective (RPO) of 8 hours, with component-specific RTOs and RPOs detailed in Appendix N: Business Impact Analysis (BIA). Finally, Appendix P outlines that a new full system backup must be performed immediately after recovery is complete and validated. This evidence demonstrates a clear alignment of system backups with defined recovery objectives.\n\n",
        "Test Instructions":"Review backup schedules, backup logs, and storage configurations to confirm system backups are performed and aligned with recovery objectives.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-RPL-03, SSP-1",
        "Linked Evidence":"INR-01-SSP-Appendix-G_InteliGRC-Information-System-Contingency-Plan-(ISCP).pdf,RPL-01-CP - Contingency Planning Policy.pdf,RPL-03-Backup Components.PNG,RPL-03-Backup Definitions.PNG,RPL-03-Backup Location.PNG,RPL-03-Backup Responsibility.PNG,RPL-03-backup-vault.tf,RPL-03-Incident Response Roles 1.PNG,RPL-03-Incident Response Roles 2.PNG"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-RPL-04",
        "Control ID":"KSI-RPL-04",
        "Control Description":"Regularly test the capability to recover from incidents and contingencies",
        "Testing Notes":"\nRPL-04-Contingency Plan Test Requirement.PNG:\nEvidence confirms that the organization tests its contingency plan annually and documents the test results in a Contingency Plan Test Report. The template for this report is located in Appendix F.\n\nRPL-04-Incident Response Test Requirement.PNG:\nBased on the evidence provided, IntelliGRC conducts annual incident response testing designed to simulate real-world breaches. This testing ensures the Incident Response Team is prepared for actual incidents and validates their capability to recover from incidents and contingencies, as required by the control.\n\nRPL-04-Incident Response Evaluation.PNG:\nBased on the evidence provided, IntelliGRC validates an organization's ability to recover from disruptive cyber events through annual incident response testing and reviews. The testing involves relevant personnel, giving them the opportunity to review recovery plans, policies, and procedures related to their responsibilities. This approach allows personnel to provide feedback on the realism of expectations and voice concerns, with appropriate personnel then addressing those concerns. Furthermore, the document outlines key metrics, such as the percentage of IR tests completed annually, which are used to evaluate the effectiveness of the incident response and recovery capabilities.\n\nRPL-04-Tabletop_Exercise_Malicious_CustomerData_Deletion.pdf:\nThe tabletop exercise on August 8, 2025, simulated a targeted data deletion incident. While the exercise aimed to test incident response and contingency plan capabilities, it revealed significant deficiencies. The key finding related to the control is that the current Incident Response Plan (IRP) and Contingency Plan (CP) were found to be overly complex, lacked logical flow, and were not readily available or understood by the team, indicating that the organization's capability to recover from incidents and contingencies was not adequately tested or proven effective. The exercise did not demonstrate a regular and effective testing of recovery capabilities, but highlighted areas for improvement to achieve this control.\n\nINR-01-SSP-Appendix-G_InteliGRC-Information-System-Contingency-Plan-(ISCP).pdf:\nBased on the provided FedRAMP System Security Plan (SSP) Appendix G: Information System Contingency Plan (ISCP) for IntelliGRC, the evidence demonstrates a well-defined capability to recover from incidents and contingencies through several key elements:\n\n*   **Comprehensive Planning:** The ISCP outlines a three-phased approach (ActivationNotification, Recovery, Reconstitution) with detailed procedures for each phase.\n*   **Defined RTO and RPO:** The plan establishes clear Recovery Time Objectives (RTO) of 24 hours and Recovery Point Objectives (RPO) of 8 hours, providing measurable targets for recovery efforts.\n*   **Cloud-Native Recovery:** The plan leverages Azure's infrastructure and services for redundancy and recovery, utilizing features like Azure Backup, geo-redundant storage, and availability zones.\n*   **Data Backup and Retention:** Daily, full, cloud-based backups are performed with a retention period of 1 year, ensuring data can be restored from a recent point in time.\n*   **Alternate Site Strategy:** While not a traditional physical site, the plan relies on Azure's built-in regional redundancy for alternate site capabilities.\n*   **Clearly Defined Roles and Responsibilities:** The plan assigns specific roles and responsibilities to key personnel, ensuring a coordinated recovery effort.\n*   **Detailed Recovery Procedures:** A step-by-step sequence of recovery operations is provided, covering infrastructure, security services, and application components.\n*   **Validation and Testing:** Procedures for data and functional validation are included to ensure the recovered system is complete and operational.\n*   **Regular Testing:** The ISCP is scheduled to be tested at least annually, with a plan for future testing.\n*   **Business Impact Analysis (BIA):** Appendix N provides a BIA that identifies critical system functions and component-specific RTOs and RPOs, enabling prioritized recovery efforts.\n*   **Post-Recovery Procedures:** Appendix P defines the critical final step of performing a new full system backup immediately after recovery is complete and validated.\n\nThese elements, documented within the ISCP, demonstrate a proactive and structured approach to testing the capability to recover from incidents and contingencies.\n\n",
        "Test Instructions":"Request documentation of recent recovery tests, including scenarios, outcomes, and lessons learned, to confirm regular testing of recovery capabilities.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-RPL-04, SSP-1",
        "Linked Evidence":"INR-01-SSP-Appendix-G_InteliGRC-Information-System-Contingency-Plan-(ISCP).pdf,RPL-04-Contingency Plan Test Requirement.PNG,RPL-04-Incident Response Evaluation.PNG,RPL-04-Incident Response Test Requirement.PNG,RPL-04-Tabletop_Exercise_Malicious_CustomerData_Deletion.pdf"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-SVC-01",
        "Control ID":"KSI-SVC-01",
        "Control Description":"Harden and review network and system configurations",
        "Testing Notes":"\nSVC-01 policy_assignment_fedramp_moderate.json:\nThe provided Azure Policy assignment enforces configuration standards aligned with FedRAMP Moderate controls. Specifically, it hardens Kubernetes configurations by restricting container image sources to 'intelliacr', limiting service ports, setting CPU and memory limits, and restricting security profiles and capabilities. The policy assignment uses a system-assigned managed identity, ensuring necessary permissions for enforcement. These configurations contribute to hardening the system and network configurations.\n\nSVC-01 jumpbox-config.conf:\nThe provided `cloud-config` file automates the hardening of a cloud server instance based on DISA STIG and CIS benchmarks. The script configures networking, SSH, package management (including installing `squid` and `ufw`), and removes unnecessary packages. It implements extensive security controls via a custom OSCAP tailoring file, including login banners, password policies, account lockout, session timeout, and SSH hardening. Auditing is enabled with `auditd`, and the system is configured to halt if audit disk space is full. Filesystem and kernel security measures are implemented, such as disabling core dumps and enabling ASLR. The script automates compliance checks with a weekly OSCAP scan and includes fixes for CIS benchmarks, such as PAM configuration, file permissions, and password aging. Finally, it configures a Squid proxy and system-wide proxy settings.\n\nSVC-01-AzureSecurityCenterFedRAMPModerateBaselineScan.pdf:\nBased on the Microsoft Defender for Cloud report, the majority of FedRAMP M controls related to network and system configurations are passing. Specifically, within 'CM. Configuration Management', 20 controls have passed their assessments. However, 'SC. System And Communications Protection' has one failing control (SC.12.* Additional assessments for SC-12 - Cryptographic Key Establishment And Management), with 3 failed assessments. The remaining controls in the report related to hardening and reviewing configurations are passing, indicating a generally well-hardened environment with a specific weakness in cryptographic key management.\n\nSVC-01 Dockerfile.txt:\nEvidence confirms hardening of system configurations by detailing a multi-stage Dockerfile that builds a secure, minimal container image with a FIPS-compliant OpenSSL setup. The build process involves compiling OpenSSL from source, specifically incorporating a FIPS-validated module from an older version (3.0.9) into a newer version (3.4.0). This ensures that cryptographic operations adhere to FIPS standards. Furthermore, the final image includes a meticulously crafted OpenSSL configuration file (`openssl.cnf`) that enforces FIPS mode by default, ensuring applications utilize FIPS-approved algorithms. The configuration also explicitly defines the paths for the OpenSSL binary, libraries, and configuration file through environment variables (PATH, LD_LIBRARY_PATH, OPENSSL_CONF), ensuring proper operation. Lastly, the Dockerfile switches to a non-privileged user (`nonroot`) for enhanced security. This demonstrates a comprehensive approach to hardening the system configuration in compliance with security best practices.\n\nSVC-01 message-scheduler-v0.1.3-results.xml:\nBased on the provided OpenSCAP report, the evidence indicates that the container image `intelliacr.azurecr.iomessage-scheduler:v0.1.3` is hardened and its configurations are regularly reviewed. Specifically, the scan, conducted on August 5, 2025, using the 'Datastream XCCDF Checklist Beta' benchmark and the 'xccdf_basic_profile_.check' profile, resulted in a 100% compliance score. The report highlights that the container image follows a minimalist approach (Chainguard), containing only the necessary software, which reduces the attack surface. Additionally, the absence of remote access services (ssh, telnet, etc.) and the enforcement of strong password policies further contribute to the hardening of the system. The implementation of ASLR and proper library permissions also demonstrate adherence to secure configuration practices. While many network and system configurations are inherited from the host OS, the container image demonstrates appropriate hardening measures within its scope of responsibility.\n\n",
        "Test Instructions":"Review network device configurations, operating system security baselines, and application settings against hardening guides and recent audit reports.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-SVC-01, SSP-1",
        "Linked Evidence":"SVC-01-AzureSecurityCenterFedRAMPModerateBaselineScan.pdf,SVC-01 Dockerfile.txt,SVC-01 jumpbox-config.conf,SVC-01 message-scheduler-v0.1.3-results.xml,SVC-01 policy_assignment_fedramp_moderate.json"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-SVC-02",
        "Control ID":"KSI-SVC-02",
        "Control Description":"Encrypt or otherwise secure network traffic",
        "Testing Notes":"\nSVC-02-encryption on psqlfs.png:\nThe evidence demonstrates that TLSSSL encryption is enforced by default for the Azure Database for PostgreSQL flexible server named intelli-prod-shared-psqlfs. The evidence also shows that the SSL certificate can be downloaded. Disabling SSL requires a manual configuration change to the server parameter require_secure_transport. TLS versions can be controlled using the ssl_min_protocol_version and ssl_max_protocol_version parameters.\n\nSVC-02-encryption on psqlfs 2.png:\nBased on the evidence provided, the Azure Database for PostgreSQL flexible server `intelli-prod-shared-psqlfs` has the `ssl` parameter enabled. The parameter description states that this parameter `Enables SSL connections`. The value of the `ssl` parameter is set to `ON` and is read-only, ensuring that all network traffic to the PostgreSQL server is encrypted using SSL.\n\nSVC-02-deployment.yaml:\nBased on the provided Helm template file, the configuration uses Linkerd service mesh sidecar injection when `.Values.linkerd.enabled` is set to `true`. This enables mutual TLS (mTLS) between services, encrypting network traffic within the cluster. The configuration also allows for the definition of network policies to further control and secure network traffic. The presence of security context settings at both the pod and container level indicates an effort to configure security-related settings, though their specific contribution to network traffic encryption would depend on the details of the applied configuration. The probes (liveness, readiness, startup) help ensure the application is running correctly and securely. Resources are allocated and access is controlled.\n\nSVC-02-values.yaml:\nTesting Notes:\n\nThe provided `values.yaml` file for the `intellicore-actionplanapi` Helm chart demonstrates several configurations that contribute to securing network traffic:\n\n*   **Service Mesh (Linkerd)**: The `linkerd.enabled` is set to `true`. This enables the Linkerd service mesh, which automatically encrypts all traffic between pods within the cluster using mutual TLS (mTLS).\n*   **Ingress Configuration**: Although `ingress.enabled` is set to `false` by default, the commented-out examples demonstrate how to configure TLSSSL encryption for external access using `kubernetes.iotls-acme: true` and a `secretName` for TLS termination. This provides a template for securing external network traffic.\n\n\n\n\n",
        "Test Instructions":"Verify the use of encryption protocols (e.g., TLS 1.2+, IPsec VPNs) for all network traffic, especially for sensitive data, through configuration review or traffic capture analysis.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-SVC-02, SSP-1",
        "Linked Evidence":"SVC-02-deployment.yaml,SVC-02-encryption on psqlfs 2.png,SVC-02-encryption on psqlfs.png,SVC-02-values.yaml"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-SVC-03",
        "Control ID":"KSI-SVC-03",
        "Control Description":"Encrypt all federal and sensitive information at rest",
        "Testing Notes":"\nSVC-03-blob-storage.tf:\nThe Terraform configuration encrypts federal and sensitive information at rest by enabling infrastructure encryption and utilizing a Customer Managed Key (CMK) stored in Azure Key Vault, as specified by `var.customer_managed_key_id`. The configuration also enforces modern security standards, such as OAuth authentication, disabling local user access, and setting the minimum TLS version to 'TLS1_2', further protecting data at rest.\n\nSVC-03-blob storage encryption.png:\nThe storage account 'uploadsprodintelli0' encrypts data at rest using Customer-Managed Keys (CMK) for blobs and files.  Infrastructure encryption is enabled.  The CMK is stored in Azure Key Vault 'kv-intelli-prod-1' with URI 'https:kv-intelli-prod-1.vault.azure.netkeysstorage-cert' and automatic key rotation is enabled. Soft delete and purge protection are enabled on the key vault.\n\n",
        "Test Instructions":"Confirm that all federal and sensitive information at rest is encrypted, by reviewing storage configurations (e.g., disk encryption, database encryption, S3 bucket encryption).",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-SVC-03, SSP-1",
        "Linked Evidence":"SVC-03-blob storage encryption.png,SVC-03-blob storage encryption.tf,SVC-03-blob-storage.tf"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-SVC-04",
        "Control ID":"KSI-SVC-04",
        "Control Description":"Manage configuration centrally",
        "Testing Notes":"\nSVC-04-Pipeline Repo.png:\nBased on the evidence provided in the `identities.tf` file summary, the control 'Manage configuration centrally' is effectively implemented. The Terraform configuration file (`identities.tf`) defines the creation of a dedicated resource group (`connectivity-mi-infra-rg`) to centrally manage multiple user-assigned managed identities. This centralized approach ensures consistent configuration and management of identities used by various Azure services, including storage accounts, container registries, and firewall policies. The use of a consistent naming convention and a variable-driven location (`var.default_location`) further supports the central management and standardization of configurations. The IaC approach ensures that the configuration is defined and applied in a repeatable and auditable manner.\n\nSVC-04-intelli-appset.yml.txt:\nThe provided ApplicationSet manifest demonstrates centralized configuration management in several ways:\n\n*   **Dynamic Application Generation:** The ApplicationSet dynamically generates Argo CD Application resources based on the contents of the `apps` list in the Helm values. This allows for managing multiple applications from a single configuration file.\n*   **Templating:** The `template` section defines a common structure for all generated Applications, ensuring consistency across deployments.  Variables within the template, such as `appName` and `environment`, are populated from the generator's elements and Helm values, allowing for customization while maintaining a standardized base configuration.\n*   **Centralized Repository:** The `repoURL` is defined in the Helm values, pointing to a central Git repository where application manifests are stored. This ensures that all applications are deployed from a single source of truth.\n*   **Environment-Specific Overrides:** The use of multiple Helm `valueFiles`, including environment-specific overrides, allows for tailoring application configurations to different environments while still maintaining a central base configuration.  The files are applied in a specific order, with later files overriding values from earlier ones, providing a clear precedence for configuration settings.\n*   **Automated Synchronization:** The `syncPolicy` with `automated` settings enables automated synchronization of application deployments, ensuring that the deployed state matches the desired state defined in the Git repository. The `prune` and `selfHeal` options further enhance this by automatically removing resources that are no longer defined in the repository and reverting manual changes made to the live resources, respectively.\n*   **Namespace Management:** The `CreateNamespace=true` sync option allows Argo CD to automatically create the destination namespace if it doesn't already exist, simplifying the deployment process and ensuring that applications are deployed to the correct namespaces.\n*   **Helm Chart Management**: Uses Helm charts to define, install, and upgrade Kubernetes applications. This allows managing application configurations and dependencies as code.\n\nThese aspects collectively demonstrate that the configuration is managed centrally through the ApplicationSet, Helm values, and Git repository, promoting consistency, repeatability, and ease of management across multiple applications and environments.\n\n",
        "Test Instructions":"Examine configuration management systems (e.g., Ansible, Puppet, Chef, GitOps) to confirm central management and enforcement of system configurations.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-SVC-04, SSP-1",
        "Linked Evidence":"SVC-04-Azure DevOps Pipelines.json,SVC-04-intelli-appset.yml.txt,SVC-04-Pipeline Repo.png"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-SVC-05",
        "Control ID":"KSI-SVC-05",
        "Control Description":"Enforce system and information resource integrity through cryptographic means",
        "Testing Notes":"\nSVC-05-policy_assignment_fedramp_moderate.json:\nThe FedRAMP Moderate policy assignment enforces cryptographic integrity by restricting container images to a specific Azure Container Registry (ACR) using the `allowedContainerImagesRegex-febd0533-8e55-448f-b837-bd0e06f16469` parameter, ensuring only trusted images are deployed. This control helps prevent the execution of unauthorized or malicious code within the environment.\n\nSVC-05-blob storage encryption.png:\nBased on the evidence provided, the Azure Storage Account `uploadsprodintelli0` enforces system and information resource integrity through cryptographic means. Specifically, the storage account utilizes customer-managed keys stored in Azure Key Vault (`kv-intelli-prod-1`) with the key name `storage-cert`.  Encryption is enabled for blobs and files, and infrastructure encryption is also enabled. Automated key rotation is configured to use the latest key version, ensuring ongoing protection with updated cryptographic keys. The configuration mandates soft delete and purge protection on the key vault, adding a layer of protection against accidental or malicious key deletion.\n\nSVC-05-encryption on psqlfs 2.png:\nBased on the provided evidence, the 'ssl' parameter is enabled for the 'intelli-prod-shared-psqlfs' Azure Database for PostgreSQL flexible server. The value of the 'ssl' parameter is set to 'ON', which enforces SSL connections to the database server. While the parameter is displayed as a toggle switch, it is 'Read-Only', indicating that SSL is enforced at a higher level and cannot be disabled through this interface. This configuration ensures that all connections to the PostgreSQL server are encrypted, thus enforcing system and information resource integrity through cryptographic means, as per the control description.\n\nSVC-05-encryption on psqlfs.png:\nBased on the provided evidence, the Azure Database for PostgreSQL flexible server `intelli-prod-shared-psqlfs` enforces system and information resource integrity through cryptographic means. Specifically, TLSSSL encryption is enforced by default, ensuring secure connections to the database server. The evidence also shows that users can download the public SSL certificate for establishing secure connections. Furthermore, the option to configure TLS versions via `ssl_min_protocol_version` and `ssl_max_protocol_version` server parameters provides granular control over cryptographic protocols, meeting the control objective of enforcing system and information resource integrity through cryptographic means.\n\nSVC-05-blob-storage.tf:\nThe Terraform code configures an Azure Storage Account with multiple security features that enforce system and information resource integrity through cryptographic means. Specifically, the code enables infrastructure encryption (`infrastructure_encryption_enabled = true`) which provides double encryption at rest. It also allows for the configuration of Customer Managed Keys (CMK) using keys from Azure Key Vault, further enhancing encryption capabilities. The configuration enforces a minimum TLS version of 1.2 (`min_tls_version = TLS1_2`) for secure data transfer. The use of a User-Assigned Managed Identity for the storage account allows other services to interact with it securely, such as for CMK. Furthermore, the configuration has the option to enable point-in-time restore, change feed and versioning and soft delete which can protect the integrity of the data. Finally, local user and shared access keys are disabled by default to promote modern authentication methods.\n\n",
        "Test Instructions":"Request evidence of cryptographic integrity checks (e.g., file integrity monitoring, code signing, secure boot) for system and information resources.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-SVC-05, SSP-1",
        "Linked Evidence":"SVC-03-blob storage encryption.tf,SVC-05-blob storage encryption.png,SVC-05-blob-storage.tf,SVC-05-encryption on psqlfs 2.png,SVC-05-encryption on psqlfs.json,SVC-05-encryption on psqlfs.png,SVC-05-policy_assignment_fedramp_moderate.json"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-SVC-06",
        "Control ID":"KSI-SVC-06",
        "Control Description":"Use automated key management systems to manage, protect, and regularly rotate digital keys and certificates",
        "Testing Notes":"\nSVC-06-aks-cluster.tf:\nThe Terraform configuration file demonstrates several key aspects of automated key management and certificate rotation within the AKS cluster:\n\n*   **CSI Secrets Store Driver:** The configuration enables the `key_vault_secrets_provider` with `secret_rotation_enabled = true`. This shows that the cluster is configured to use the CSI Secrets Store driver to fetch secrets from Azure Key Vault and automatically rotate them.\n*   **Disk Encryption:** The cluster uses a customer-managed `disk_encryption_set_id` for encrypting OS disks.\n\nThese configurations, managed through Terraform, provide an automated approach to managing and protecting keys and certificates, as well as disk encryption, aligning with the control objective.\n\nSVC-06-keyvault.tf:\nBased on the provided Terraform configuration, the evidence supports the control objective of using automated key management systems to manage, protect, and regularly rotate digital keys and certificates. Specifically, the configuration defines a private Azure Key Vault (`kv-connectivity-igrc`) and configures two keys (`acr-certificate` and `storage-cert`) with automatic key rotation policies. The `expire_after`, `automatic.time_before_expiry`, and `notify_before_expiry` settings demonstrate that the keys are set to automatically rotate, with the Key Vault generating new versions and providing notifications before expiration.  The use of a dedicated Key Vault and role-based access control (RBAC) further supports the protection of digital keys and certificates by restricting access to authorized services (ACR, Storage Accounts, Disk Encryption Set, Azure Firewall Policy) via managed identities assigned specific roles (Key Vault Crypto Officer, Key Vault Crypto Service Encryption User, Key Vault Certificate User).\n\n",
        "Test Instructions":"Review key management system (KMS) configurations, policies, and logs to ensure automated key management, protection, and regular rotation of digital keys and certificates.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-SVC-06, SSP-1",
        "Linked Evidence":"SVC-06-aks-cluster.tf,SVC-06-keyvault.tf"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-SVC-07",
        "Control ID":"KSI-SVC-07",
        "Control Description":"Use a consistent, risk-informed approach for applying security patches",
        "Testing Notes":"\nSVC-07-kubernetes node image shceduled updates.png:\nBased on the provided evidence, the AKS cluster 'intelli-prod' is configured to automatically upgrade the node image. This ensures that the underlying operating system of the nodes is kept up-to-date with the latest security patches. A weekly maintenance schedule is configured to minimize workload impact during these updates. The cluster is running Kubernetes version 1.31.9, and while node images are automatically updated, Kubernetes version upgrades are not scheduled. This demonstrates a risk-informed approach by prioritizing node image updates, likely focusing on OS-level vulnerabilities. The 'Node Image' automatic upgrade type aligns with applying security patches consistently. The weekly schedule further supports consistent application with minimal disruption.\n\nSVC-07-jumpbox.tf:\nEvidence indicates a consistent, risk-informed approach for applying security patches through the following: 1. Security-hardened OS Image: VMs use a security-hardened Ubuntu Pro image, ensuring a baseline level of security. 2. Maintenance Configuration: A daily maintenance window is configured for applying Critical, Security, and Other patches, with reboots only occurring when required. 3. Patch Scope: The maintenance configuration is set to InGuestPatch, focusing on OS-level patching. 4. Automated Patching Schedule: Patches are applied daily during a defined maintenance window, ensuring timely updates. 5. Key Rotation: Disk Encryption uses key rotation. 6. Ephemeral OS Disk: OS disk is ephemeral.\n\nSVC-07-Automated VM Patching.png:\nThe evidence demonstrates a consistent approach to applying security patches. The Azure VM update history shows a 100% success rate for update deployments over the last 30 days. Updates are applied via a customer-managed schedule ('intelli-jumphost-mc') and include both update installations and periodic assessments. The logs show that updates are consistently applied, with some installations including a large number of updates (e.g., 116 out of 116) and others showing that no updates were needed, indicating a risk-informed approach where patches are applied when necessary. The system also performs periodic assessments to identify needed updates.\n\n",
        "Test Instructions":"Examine patch management policies, vulnerability scan reports, and system update logs to confirm a consistent, risk-informed approach to applying security patches.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-SVC-07, SSP-1",
        "Linked Evidence":"SVC-07-Automated VM Patching.png,SVC-07-Automated VM Patching.tf,SVC-07-jumpbox.tf,SVC-07-kubernetes node image scheduled updates.tf,SVC-07-kubernetes node image shceduled updates.png"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-TPR-01",
        "Control ID":"KSI-TPR-01",
        "Control Description":"Identify all third-party information resources",
        "Testing Notes":"\nKSI-TPR-01_IntelliGRC-Leveraged FedRAMPAuthorizedServices.pdf:\nThe provided document, Comprehensive and detailed summary of the provided document, serves as evidence that all third-party information resources have been identified. The document clearly lists and describes key third-party Cloud Service Provider (CSP)  Cloud Service Offering (CSO) platforms in use, specifically Microsoft Azure, Microsoft Azure DevOps, and Microsoft 365. For each identified third-party resource, the document details their respective services and features, authorization status (e.g., FedRAMP JAB P-ATO with package IDs), nature of agreement (EULA, SLA), impact levels, data types, and authorized user groups. This comprehensive detailing of external services and their characteristics directly fulfills the control's objective to identify all third-party information resources.\n\nPIY-01-SSP-Appendix-M-Integrated-Inventory-Workbook.xlsx:\nThe **FedRAMP\u00ae System Security Plan (SSP) Appendix M: FedRAMP Integrated Inventory Workbook Template, Version 3.1** was reviewed. This document provides a comprehensive inventory of all system components, including specific sections dedicated to identifying third-party information resources. The workbook lists numerous Third-Party & Open-Source Containers such as `intelliacr.azurecr.ioargoprojargocd:v3.0.11` and `intelliacr.azurecr.iobusybox:1.36.1-glibc`. Additionally, the Software and Database Inventories section details third-party vendors including Apprise, Argo, buoyant (Linkerd), Redis, Docker, Cloud Native Computing Foundation (CNCF), Kubernetes SIG-Network, JetstackCNCF, and Kestra, along with their respective software names, versions, and patch levels. The Comments section further clarifies the origin of certain components, distinguishing between internally managed and Microsoft-provided elements. The detailed identification of unique asset identifiers, IP addresseshashes, asset types, functions, and associated vendors demonstrates a thorough effort to identify all third-party information resources utilized by the system.\n\nIntelliGRC_Production_Authorization Boundary.png:\nTesting Notes:  \n**Control:** Identify all third-party information resources.  \n\n**Evidence:** Detailed summary of the Azure architecture diagram for IntelliGRC.  \n\n**Testing Performed:** Reviewed the provided summary of the Azure architecture diagram to identify all explicit and implicit third-party information resources utilized by the IntelliGRC platform.  \n\n**Findings:** The evidence provided comprehensively identifies third-party information resources integrated into the IntelliGRC architecture.  \n\nSpecifically, the following third-party information resources are clearly identified within the architecture summary:  \n\n*   **Microsoft Azure:** The entire IntelliGRC platform is explicitly stated to be hosted on Microsoft Azure, serving as the foundational third-party cloud provider and infrastructure.  \n*   **PostgreSQL:** The summary details the use of PostgreSQL for database services, identifying this open-source database technology as a third-party resource.  \n*   **Redis:** Azure Redis Cache is listed for in-memory caching, indicating the use and identification of Redis as a third-party technology.  \n*   **OpenAI:** The architecture explicitly includes Cognitive services  OpenAI for AI capabilities, directly identifying OpenAI as a significant third-party information resource integrated into the application.  \n\n**Conclusion:** The detailed Azure architecture diagram summary effectively identifies all critical third-party information resources, thereby meeting the control requirement. The comprehensive nature of the provided architectural documentation ensures that these third-party integrations are clearly outlined and understood.\n\n",
        "Test Instructions":"Request a list or inventory of all identified third-party information resources.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-TPR-01, SSP-1",
        "Linked Evidence":"IntelliGRC_Production_Authorization Boundary.png,KSI-TPR-01_IntelliGRC-Leveraged FedRAMPAuthorizedServices.pdf,PIY-01-SSP-Appendix-M-Integrated-Inventory-Workbook.xlsx"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-TPR-02",
        "Control ID":"KSI-TPR-02",
        "Control Description":"Regularly confirm that services handling federal information or are likely to impact the confidentiality, integrity, or availability of federal information are FedRAMP authorized and securely configured",
        "Testing Notes":"TPR-03-Azure Commercial Cloud _ FedRAMP Marketplace.png:\nTesting Notes:\n\n1.  **Service Identification and Impact:** The evidence confirms that AZURE COMMERCIAL CLOUD is the service in question, provided by Microsoft. Its High impact level, as indicated on the FedRAMP Marketplace page, signifies that it handles federal information and is critical to maintaining the confidentiality, integrity, and availability of that information, aligning with the control's scope.\n\n2.  **FedRAMP Authorization Confirmation:** The FedRAMP Marketplace page clearly shows that Azure Commercial Cloud achieved Authorized status on 05032019. This directly verifies that the service is FedRAMP authorized, meeting a core requirement of the control.\n\n3.  **Secure Configuration Assurance (Implied by FedRAMP):** While specific configuration details are not provided, FedRAMP authorization inherently confirms that the service has undergone a rigorous security assessment by an independent assessor (Kratos in this case) and meets the comprehensive security requirements outlined by FedRAMP. The Annual Assessment date of 0503 further indicates ongoing oversight and confirmation of the secure posture, demonstrating that the service is not only authorized but subject to regular review to ensure continued secure configuration as required by the control.\n\nTPR-03-Service Ticket_452_Externalsystems Authorization_Q3.pdf:\nTesting Notes:\n\n**Control:** Regularly confirm that services handling federal information or are likely to impact the confidentiality, integrity, or availability of federal information are FedRAMP authorized and securely configured.\n\n**Evidence Reviewed:** Service Ticket #452, External Systems Authorization [Quarterly Review] - Q3, dated August 7, 2025.\n\n\nThe review of Service Ticket #452 confirms that the organization regularly verifies that services handling federal information are FedRAMP authorized and securely configured, as per the control objective. \n\n1.  **Regular Confirmation:** The ticket is explicitly labeled as a Q3 quarterly review, indicating that these confirmations are conducted on a regular, periodic basis.\n2.  **FedRAMP Authorization:** The Key Findings section of the ticket clearly states, All systems in use were confirmed to be FedRAMP authorized. This includes specific federal information handling components such as Azure Cosmos DB for Postgres, Azure PostgreSQL flexible server, Azure Key Vault, and Azure managed identities.\n3.  **Secure Configuration:** The review also validates secure configuration practices. The ticket details that access to customer data is highly restricted to only backend administrators via a secure jump post. Furthermore, system configurations are managed securely using Terraform (Infrastructure as Code), with all code changes undergoing review and authorization via a robust DevOps and pipeline process. These methods demonstrate that the services are securely configured to protect federal information.\n\nKSI-TPR-01_IntelliGRC-Leveraged FedRAMPAuthorizedServices.pdf:\n**Testing Notes:**\n\n**Control:** Regularly confirm that services handling federal information or are likely to impact the confidentiality, integrity, or availability of federal information are FedRAMP authorized and securely configured.\n\n**Evidence Review:**\n\n1.  **FedRAMP Authorization:**\n    *   **Microsoft Azure:** The evidence confirms that Microsoft Azure services (including Azure Cosmos DB, Blob Storage, WAF, Firewall, Sentinel, etc.) are FedRAMP authorized with a JAB P-ATO, package ID F1209051525, and an Impact Level of High. This directly addresses the FedRAMP authorization requirement for these services.\n    *   **Microsoft 365:** The evidence confirms that Microsoft 365 (E5) services (including Exchange Online, Teams, SharePoint, OneDrive, Intune, Defender for Endpoint) are FedRAMP authorized with a JAB P-ATO, package ID MSO365MT, and an Impact Level of Moderate. This directly addresses the FedRAMP authorization requirement for these services.\n    *   **Microsoft Azure DevOps:** The evidence states NA for Authorization Type for Microsoft Azure DevOps. This indicates that Azure DevOps, which includes services like Git Repository and Build Pipelines, is *not* currently FedRAMP authorized according to this documentation. If Azure DevOps handles federal information or impacts its confidentiality, integrity, or availability, this presents a finding as it does not meet the FedRAMP authorization requirement of the control.\n\n2.  **Secure Configuration:**\n    *   While the evidence does not provide explicit configuration details, the inclusion of security-focused services within the listed CSOs (e.g., Azure WAF, Azure Firewall, Azure Bastion, Azure Defender for Cloud, Azure Sentinel, Azure Key Vault for Azure; Microsoft Defender for Endpoint, Microsoft Defender for Cloud, and Intune for Microsoft 365) indicates that the organization utilizes capabilities designed to enhance the security posture of these environments. The categorization of Impact Level and Data Types also demonstrates an understanding of data sensitivity and associated security considerations. The specified Authorized UsersAuthentication for each CSO further indicates controlled access to these services.\n\n**Conclusion:**\n\nThe evidence demonstrates that critical services like Microsoft Azure and Microsoft 365 are FedRAMP authorized as required by the control. However, the lack of FedRAMP authorization for Microsoft Azure DevOps, coupled with its use in development and build processes (which can impact the integrity and availability of federal information, even if not directly handling it), represents a gap against the control requirements. The utilization of security features within the authorized CSOs partially addresses the securely configured aspect, but further evidence would be needed to fully confirm specific secure configuration baselines and their implementation.\n\nIntelliGRC_Production_Authorization Boundary.png:\nThe provided Azure architecture diagram for IntelliGRC details a comprehensive and securely configured cloud environment, directly supporting the securely configured aspect of the control. While the diagram showcases an architecture built upon Azure services, which are themselves FedRAMP authorized at various levels, it does not explicitly state the FedRAMP authorization status of the IntelliGRC application or system as a whole. For the purpose of this audit, it is assumed that the underlying Azure cloud services utilized possess the necessary FedRAMP authorization to handle federal information. ",
        "Test Instructions":"For services handling federal information or impacting C-I-A, request FedRAMP authorization documentation and evidence of secure configuration.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"PARTIAL",
        "Finding":"Microsoft Azure DevOps:** The evidence states NA for Authorization Type for Microsoft Azure DevOps. This indicates that Azure DevOps, which includes services like Git Repository and Build Pipelines, is *not* currently FedRAMP authorized according to this documentation. If Azure DevOps handles federal information or impacts its confidentiality, integrity, or availability, this presents a finding as it does not meet the FedRAMP authorization requirement of the control.",
        "Finding Status":"Unresolved",
        "Linked Requests":"KSI-TPR-02, SSP-1",
        "Linked Evidence":"IntelliGRC_Production_Authorization Boundary.png,KSI-TPR-01_IntelliGRC-Leveraged FedRAMPAuthorizedServices.pdf,TPR-02-AzureFedRAMPSSP.pdf,TPR-03-Azure Commercial Cloud _ FedRAMP Marketplace.png,TPR-03-Service Ticket_452_Externalsystems Authorization_Q3.pdf"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-TPR-03",
        "Control ID":"KSI-TPR-03",
        "Control Description":"Identify and prioritize mitigation of potential supply chain risks",
        "Testing Notes":"\nPIY-07-IntelliGRC_Prod-SBOM_Summary-8.8.25.csv:\nThe provided Software Bill of Materials (SBOM) demonstrates an inventory of software components which contributes to the identification of supply chain risks. The SBOM details the application's dependencies, including versions and origins, enabling the organization to understand potential vulnerabilities and prioritize mitigation efforts. The document includes the identification of both first and third party software. The SBOM uses the SPDX standard, which is a recognized format for SBOMs, allowing for interoperability and standardization in risk management processes. The detailed architecture breakdown further aids in identifying potential risk areas within specific components and services, allowing for focused mitigation strategies.\n\nPIY-07-IntelliGRC - Supply Chain Risk Management (SCRM) Plan_v1.0.pdf:\nEvidence indicates that IntelliGRC has implemented a comprehensive SCRM plan that identifies and prioritizes the mitigation of potential supply chain risks. The plan outlines the roles and responsibilities of a cross-functional SCRM team, defines core controls and processes for risk identification and evaluation, and establishes technical, contractual, and procedural controls. The plan is aligned with NIST SP 800-53 Rev. 5 (SR control family), NIST SP 800-218, NIST SP 800-161 Rev. 1 Upd1, NIST SP 800-37 Rev. 2, NIST SP 800-88 Rev. 1, and Section 889 Compliance.\n\n",
        "Test Instructions":"Review supply chain risk assessment documentation and mitigation plans to confirm identification and prioritization of potential risks.",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-TPR-03, SSP-1",
        "Linked Evidence":"IntelliGRC_SBOM_Package_8.8.25.zip,PIY-07-IntelliGRC_Prod-SBOM_Summary-8.8.25.csv,PIY-07-IntelliGRC - Supply Chain Risk Management (SCRM) Plan_v1.0.pdf"
    },
    {
        "Service":"FedRAMP: Low 20x",
        "Criteria ID":"KSI-TPR-04",
        "Control ID":"KSI-TPR-04",
        "Control Description":"Monitor third party software information resources for upstream vulnerabilities, with contractual notification requirements or active monitoring services",
        "Testing Notes":"\nPIY-03-Krebs Vulnerability.pdf:\nThe evidence demonstrates monitoring of third-party software (SharePoint Server) for upstream vulnerabilities (zero-day). The email from KrebsOnSecurity, a known security information source, notifies of a Microsoft SharePoint vulnerability actively exploited. This aligns with the control requirement to monitor third-party software for vulnerabilities.\n\nPIY-03-CISA Vulnerability.pdf:\nBased on the provided CISA advisory, third-party software (D-Link) vulnerabilities are actively monitored. The advisory serves as evidence of active monitoring for upstream vulnerabilities. The listed CVEs and affected products demonstrate the identification of specific vulnerabilities. While contractual notification requirements aren't explicitly detailed, the advisory itself acts as a notification of vulnerabilities. The regular publication of such advisories indicates an active monitoring service.\n\nTPR-04-Vulnerability Report (intelliacr.azurecr.io_actionplan_v0.30.5).pdf:\nThe provided vulnerability report from Grype, dated August 5, 2025, demonstrates active monitoring of third-party software (specifically, the intelliacr.azurecr.ioactionplan:v0.30.5 container image) for upstream vulnerabilities. The report identifies vulnerabilities in the 'busybox' and 'glibc' packages, providing CVEGHSA identifiers, severity levels, and related URLs for further investigation. The presence of the 'fixed' state for two vulnerabilities in 'glibc' suggests that remediation actions, such as patching, are being tracked. This evidence supports the control objective of monitoring third-party software for vulnerabilities.\n\nPIY-07-Supply Chain Risk Management Policy.docx:\nBased on the Supply Chain Risk Management Policies document provided by IntelliGRC, here are testing notes focusing on how the evidence meets the control:\n\n*   **Notification Agreements (SR-8):** The policy explicitly states that the Procurement Team, along with Legal and Security, establishes agreements requiring suppliers to notify IntelliGRC of compromises, audit results, or relevant threat intelligence. This demonstrates a contractual mechanism for receiving vulnerability information from third-party software providers.\n*   **Supplier Assessments (SR-6):** The Procurement Team assesses and reviews supply chain risks from suppliers at least annually, indicating a proactive approach to identifying potential vulnerabilities in third-party software.\n*   **SR-3: Supply Chain Controls and Processes:** Establishes processes to find and fix weaknesses in the supply chain. All teams are collectively responsible for using controls like supplier onboarding, SBOM verification, and contract enforcement.\n*   **SR-10: Inspection of Systems:** The CloudOps Team inspects deployed components randomly, quarterly, or upon indicators of compromise to detect tampering. This could include third party software.\n\n\nTPR-04-System and Services Acquisition Policy.pdf:\nBased on the System and Services Acquisition Policies document, IntelliGRC addresses monitoring third-party software for vulnerabilities through several key mechanisms:\n\n*   **SA-4: Acquisition Process:** The System Owner ensures acquired products are FedRAMP-accredited and that acquisition contracts include securityprivacy requirements.\n*   **SA-9: External System Services:** The CISO ensures external service providers comply with securityprivacy requirements, defines organizational oversight, and monitors their compliance. The System Owner conducts risk assessments before using external services, ensuring data processing and storage resides on approved FedRAMP-accredited systems. The Security Team ensures external providers identify their FPPS.\n*   **SA-22: Unsupported System Components:** The System Owner is responsible for ensuring unsupported components are replaced and that external providers offer alternative support for any unsupported components they use.\n\nThese controls demonstrate a focus on incorporating security considerations into contracts with third parties and ongoing monitoring of their compliance, which aligns with the control objective of monitoring third-party software information resources for upstream vulnerabilities.\n\n",
        "Test Instructions":"Request evidence of monitoring for upstream vulnerabilities in third-party software (e.g., vulnerability alerts, contractual notification agreements, active monitoring service reports).",
        "Consultant":"Eddie Bath, Pete Dudek, Michael McClelland",
        "Test Results":"TRUE",
        "Finding":null,
        "Finding Status":null,
        "Linked Requests":"KSI-TPR-04, SSP-1",
        "Linked Evidence":"PIY-03-CISA Vulnerability.pdf,PIY-03-Krebs Vulnerability.pdf,PIY-07-Supply Chain Risk Management Policy.docx,TPR-04-System and Services Acquisition Policy.pdf,TPR-04-Vulnerability Report (intelliacr.azurecr.io_actionplan_v0.30.5).pdf"
    }
]